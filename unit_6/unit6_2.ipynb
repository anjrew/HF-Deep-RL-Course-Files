{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "-PTReiOw-RAN"
      },
      "source": [
        "# Unit 6: Advantage Actor Critic (A2C) using Robotics Simulations with PyBullet and Panda-Gym 🤖\n",
        "\n",
        "[Panda-Gym](https://github.com/qgallouedec/panda-gym), you're going **to train a robotic arm** (Franka Emika Panda robot) to perform a task:\n",
        "- `Reach`: the robot must place its end-effector at a target position.\n",
        "\n",
        "After that, you'll be able **to train in other robotics environments**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VGL_0ncoAJI"
      },
      "source": [
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit8/environments.gif\" alt=\"Robotics environments\"/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "jV6wjQ7Be7p5"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!apt install python-opengl\n",
        "!apt install ffmpeg\n",
        "!apt install xvfb\n",
        "!pip3 install pyvirtualdisplay"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ww5PQH1gNLI4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<pyvirtualdisplay.display.Display at 0x7fad946f70d0>"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Virtual display\n",
        "from pyvirtualdisplay.display import Display\n",
        "\n",
        "virtual_display = Display(visible=False, size=(1400, 900))\n",
        "virtual_display.start()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "2yZRi_0bQGPM"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting stable-baselines3[extra]\n",
            "  Downloading stable_baselines3-1.7.0-py3-none-any.whl (171 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m171.8/171.8 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hCollecting huggingface_sb3\n",
            "  Downloading huggingface_sb3-2.2.4-py3-none-any.whl (9.4 kB)\n",
            "Collecting panda_gym==2.0.0\n",
            "  Downloading panda_gym-2.0.0-py3-none-any.whl (26 kB)\n",
            "Collecting pyglet==1.5.1\n",
            "  Downloading pyglet-1.5.1-py2.py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting scipy\n",
            "  Downloading scipy-1.10.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.5/34.5 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /home/aj/anaconda3/envs/HF_DRL/lib/python3.8/site-packages (from panda_gym==2.0.0->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit6/requirements-unit6.txt (line 3)) (1.21.6)\n",
            "Requirement already satisfied: gym in /home/aj/anaconda3/envs/HF_DRL/lib/python3.8/site-packages (from panda_gym==2.0.0->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit6/requirements-unit6.txt (line 3)) (0.25.2)\n",
            "Collecting pybullet\n",
            "  Downloading pybullet-3.2.5-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (91.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.7/91.7 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting matplotlib\n",
            "  Downloading matplotlib-3.6.3-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (9.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting pandas\n",
            "  Downloading pandas-1.5.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting importlib-metadata~=4.13\n",
            "  Downloading importlib_metadata-4.13.0-py3-none-any.whl (23 kB)\n",
            "Collecting gym\n",
            "  Downloading gym-0.21.0.tar.gz (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.11 in /home/aj/anaconda3/envs/HF_DRL/lib/python3.8/site-packages (from stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit6/requirements-unit6.txt (line 1)) (1.13.1+cu116)\n",
            "Requirement already satisfied: cloudpickle in /home/aj/anaconda3/envs/HF_DRL/lib/python3.8/site-packages (from stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit6/requirements-unit6.txt (line 1)) (2.2.1)\n",
            "Collecting rich\n",
            "  Downloading rich-13.3.1-py3-none-any.whl (239 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.0/239.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /home/aj/anaconda3/envs/HF_DRL/lib/python3.8/site-packages (from stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit6/requirements-unit6.txt (line 1)) (4.64.1)\n",
            "Collecting ale-py==0.7.4\n",
            "  Downloading ale_py-0.7.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow in /home/aj/anaconda3/envs/HF_DRL/lib/python3.8/site-packages (from stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit6/requirements-unit6.txt (line 1)) (9.4.0)\n",
            "Collecting psutil\n",
            "  Downloading psutil-5.9.4-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (280 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.2/280.2 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting opencv-python\n",
            "  Downloading opencv_python-4.7.0.68-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (61.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.8/61.8 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting tensorboard>=2.9.1\n",
            "  Downloading tensorboard-2.11.2-py3-none-any.whl (6.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting autorom[accept-rom-license]~=0.4.2\n",
            "  Downloading AutoROM-0.4.2-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: importlib-resources in /home/aj/anaconda3/envs/HF_DRL/lib/python3.8/site-packages (from ale-py==0.7.4->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit6/requirements-unit6.txt (line 1)) (5.10.2)\n",
            "Collecting huggingface-hub~=0.8\n",
            "  Downloading huggingface_hub-0.12.0-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hCollecting wasabi\n",
            "  Downloading wasabi-1.1.1-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: pyyaml~=6.0 in /home/aj/anaconda3/envs/HF_DRL/lib/python3.8/site-packages (from huggingface_sb3->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit6/requirements-unit6.txt (line 2)) (6.0)\n",
            "Requirement already satisfied: requests in /home/aj/anaconda3/envs/HF_DRL/lib/python3.8/site-packages (from autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit6/requirements-unit6.txt (line 1)) (2.28.2)\n",
            "Requirement already satisfied: click in /home/aj/anaconda3/envs/HF_DRL/lib/python3.8/site-packages (from autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit6/requirements-unit6.txt (line 1)) (8.1.3)\n",
            "Collecting AutoROM.accept-rom-license\n",
            "  Downloading AutoROM.accept-rom-license-0.5.4.tar.gz (12 kB)\n",
            "  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting filelock\n",
            "  Downloading filelock-3.9.0-py3-none-any.whl (9.7 kB)\n",
            "Requirement already satisfied: packaging>=20.9 in /home/aj/anaconda3/envs/HF_DRL/lib/python3.8/site-packages (from huggingface-hub~=0.8->huggingface_sb3->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit6/requirements-unit6.txt (line 2)) (23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/aj/anaconda3/envs/HF_DRL/lib/python3.8/site-packages (from huggingface-hub~=0.8->huggingface_sb3->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit6/requirements-unit6.txt (line 2)) (4.4.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /home/aj/anaconda3/envs/HF_DRL/lib/python3.8/site-packages (from importlib-metadata~=4.13->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit6/requirements-unit6.txt (line 1)) (3.12.0)\n",
            "Collecting tensorboard-plugin-wit>=1.6.0\n",
            "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hCollecting absl-py>=0.4\n",
            "  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.5/126.5 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools>=41.0.0 in /home/aj/anaconda3/envs/HF_DRL/lib/python3.8/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit6/requirements-unit6.txt (line 1)) (65.6.3)\n",
            "Collecting grpcio>=1.24.3\n",
            "  Downloading grpcio-1.51.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /home/aj/anaconda3/envs/HF_DRL/lib/python3.8/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit6/requirements-unit6.txt (line 1)) (0.37.1)\n",
            "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
            "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting protobuf<4,>=3.9.2\n",
            "  Downloading protobuf-3.20.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting markdown>=2.6.8\n",
            "  Downloading Markdown-3.4.1-py3-none-any.whl (93 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.3/93.3 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting werkzeug>=1.0.1\n",
            "  Downloading Werkzeug-2.2.2-py3-none-any.whl (232 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.7/232.7 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hCollecting google-auth<3,>=1.6.3\n",
            "  Downloading google_auth-2.16.0-py2.py3-none-any.whl (177 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.8/177.8 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hCollecting google-auth-oauthlib<0.5,>=0.4.1\n",
            "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
            "Collecting fonttools>=4.22.0\n",
            "  Downloading fonttools-4.38.0-py3-none-any.whl (965 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m965.4/965.4 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting cycler>=0.10\n",
            "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
            "Collecting pyparsing>=2.2.1\n",
            "  Downloading pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.3/98.3 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7 in /home/aj/anaconda3/envs/HF_DRL/lib/python3.8/site-packages (from matplotlib->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit6/requirements-unit6.txt (line 1)) (2.8.2)\n",
            "Collecting contourpy>=1.0.1\n",
            "  Downloading contourpy-1.0.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (300 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.0/300.0 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hCollecting kiwisolver>=1.0.1\n",
            "  Downloading kiwisolver-1.4.4-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
            "\u001b[?25hCollecting pytz>=2020.1\n",
            "  Downloading pytz-2022.7.1-py2.py3-none-any.whl (499 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m499.4/499.4 kB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pygments<3.0.0,>=2.14.0 in /home/aj/anaconda3/envs/HF_DRL/lib/python3.8/site-packages (from rich->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit6/requirements-unit6.txt (line 1)) (2.14.0)\n",
            "Collecting markdown-it-py<3.0.0,>=2.1.0\n",
            "  Downloading markdown_it_py-2.1.0-py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hCollecting pyasn1-modules>=0.2.1\n",
            "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.3/155.3 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rsa<5,>=3.1.4\n",
            "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
            "Collecting cachetools<6.0,>=2.0.0\n",
            "  Downloading cachetools-5.3.0-py3-none-any.whl (9.3 kB)\n",
            "Requirement already satisfied: six>=1.9.0 in /home/aj/anaconda3/envs/HF_DRL/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit6/requirements-unit6.txt (line 1)) (1.16.0)\n",
            "Collecting requests-oauthlib>=0.7.0\n",
            "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
            "Collecting mdurl~=0.1\n",
            "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/aj/anaconda3/envs/HF_DRL/lib/python3.8/site-packages (from requests->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit6/requirements-unit6.txt (line 1)) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/aj/anaconda3/envs/HF_DRL/lib/python3.8/site-packages (from requests->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit6/requirements-unit6.txt (line 1)) (1.26.14)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/aj/anaconda3/envs/HF_DRL/lib/python3.8/site-packages (from requests->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit6/requirements-unit6.txt (line 1)) (3.0.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/aj/anaconda3/envs/HF_DRL/lib/python3.8/site-packages (from requests->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit6/requirements-unit6.txt (line 1)) (2022.12.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/aj/anaconda3/envs/HF_DRL/lib/python3.8/site-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit6/requirements-unit6.txt (line 1)) (2.1.2)\n",
            "Collecting libtorrent\n",
            "  Using cached libtorrent-2.0.7-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (8.6 MB)\n",
            "Collecting pyasn1<0.5.0,>=0.4.6\n",
            "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hCollecting oauthlib>=3.0.0\n",
            "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.7/151.7 kB\u001b[0m \u001b[31m902.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: gym, AutoROM.accept-rom-license\n",
            "  Building wheel for gym (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for gym: filename=gym-0.21.0-py3-none-any.whl size=1616801 sha256=ae890110766820da68b6c3f7c23fae0aa9010b3d4aa95bcee9eb3a3079f25794\n",
            "  Stored in directory: /home/aj/.cache/pip/wheels/7a/2e/15/b9642e5913560f946cf8b27f8654e095437c17cada3d5b809e\n",
            "  Building wheel for AutoROM.accept-rom-license (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for AutoROM.accept-rom-license: filename=AutoROM.accept_rom_license-0.5.4-py3-none-any.whl size=448700 sha256=8afcbf3cf0abf2d4868f11bb0c7083ef011bcd364d9bed04d396fda4967200ee\n",
            "  Stored in directory: /home/aj/.cache/pip/wheels/2f/35/17/b76a589b8a072146d8100dce0521f6ac9945f54b4011264297\n",
            "Successfully built gym AutoROM.accept-rom-license\n",
            "Installing collected packages: tensorboard-plugin-wit, pytz, pyglet, pybullet, pyasn1, libtorrent, werkzeug, wasabi, tensorboard-data-server, scipy, rsa, pyparsing, pyasn1-modules, psutil, protobuf, opencv-python, oauthlib, mdurl, kiwisolver, importlib-metadata, gym, grpcio, fonttools, filelock, cycler, contourpy, cachetools, absl-py, requests-oauthlib, pandas, panda_gym, matplotlib, markdown-it-py, markdown, huggingface-hub, google-auth, AutoROM.accept-rom-license, autorom, ale-py, stable-baselines3, rich, huggingface_sb3, google-auth-oauthlib, tensorboard\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib-metadata 6.0.0\n",
            "    Uninstalling importlib-metadata-6.0.0:\n",
            "      Successfully uninstalled importlib-metadata-6.0.0\n",
            "  Attempting uninstall: gym\n",
            "    Found existing installation: gym 0.25.2\n",
            "    Uninstalling gym-0.25.2:\n",
            "      Successfully uninstalled gym-0.25.2\n",
            "Successfully installed AutoROM.accept-rom-license-0.5.4 absl-py-1.4.0 ale-py-0.7.4 autorom-0.4.2 cachetools-5.3.0 contourpy-1.0.7 cycler-0.11.0 filelock-3.9.0 fonttools-4.38.0 google-auth-2.16.0 google-auth-oauthlib-0.4.6 grpcio-1.51.1 gym-0.21.0 huggingface-hub-0.12.0 huggingface_sb3-2.2.4 importlib-metadata-4.13.0 kiwisolver-1.4.4 libtorrent-2.0.7 markdown-3.4.1 markdown-it-py-2.1.0 matplotlib-3.6.3 mdurl-0.1.2 oauthlib-3.2.2 opencv-python-4.7.0.68 panda_gym-2.0.0 pandas-1.5.3 protobuf-3.20.3 psutil-5.9.4 pyasn1-0.4.8 pyasn1-modules-0.2.8 pybullet-3.2.5 pyglet-1.5.1 pyparsing-3.0.9 pytz-2022.7.1 requests-oauthlib-1.3.1 rich-13.3.1 rsa-4.9 scipy-1.10.0 stable-baselines3-1.7.0 tensorboard-2.11.2 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 wasabi-1.1.1 werkzeug-2.2.2\n"
          ]
        }
      ],
      "source": [
        "!pip install -r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit6/requirements-unit6.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTep3PQQABLr"
      },
      "source": [
        "## Import the packages 📦"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "HpiB8VdnQ7Bk"
      },
      "outputs": [],
      "source": [
        "import pybullet_envs\n",
        "import panda_gym\n",
        "import gym\n",
        "\n",
        "import os\n",
        "\n",
        "from huggingface_sb3 import load_from_hub, package_to_hub\n",
        "\n",
        "from stable_baselines3 import A2C\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "\n",
        "from huggingface_hub._login import notebook_login"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "JquRrWytA6eo"
      },
      "source": [
        "To be able to share your model with the community there are three more steps to follow:\n",
        "\n",
        "1️⃣ (If it's not already done) create an account to HF ➡ https://huggingface.co/join\n",
        "\n",
        "2️⃣ Sign in and then, you need to store your authentication token from the Hugging Face website.\n",
        "- Create a new token (https://huggingface.co/settings/tokens) **with write role**\n",
        "\n",
        "\n",
        "- Copy the token \n",
        "- Run the cell below and paste the token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "90a9eafba1db4d1dae9559fbfe563965",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "notebook_login()\n",
        "!git config --global credential.helper store"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qk9ykOk9D6Qh"
      },
      "source": [
        "## Take a coffee break ☕\n",
        "- You already trained your first robot that learned to move congratutlations 🥳!\n",
        "- It's **time to take a break**. Don't hesitate to **save this notebook** `File > Save a copy to Drive` to work on this second part later.\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "5VWfwAA7EJg7"
      },
      "source": [
        "## Environment 2: PandaReachDense-v2 🦾"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZ7FyDEi7G3T"
      },
      "source": [
        "\n",
        "\n",
        "In `PandaReachDense-v2` the robotic arm must place its end-effector at a target position (green ball).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "zXzAu3HYF1WD"
      },
      "outputs": [],
      "source": [
        "import gym\n",
        "\n",
        "env_id = \"PandaReachDense-v2\"\n",
        "\n",
        "# Create the env\n",
        "env = gym.make(env_id)\n",
        "\n",
        "# Get the state space and action space\n",
        "s_size = env.observation_space.shape\n",
        "a_size = env.action_space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "E-U9dexcF-FB"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "_____OBSERVATION SPACE_____ \n",
            "\n",
            "The State Space is:  None\n",
            "Sample observation OrderedDict([('achieved_goal', array([ 4.713226 , -6.9045396, -6.3523774], dtype=float32)), ('desired_goal', array([-7.820072 ,  7.540053 ,  0.8092736], dtype=float32)), ('observation', array([-7.079901 ,  8.978062 , -8.94482  ,  9.782823 , -4.969291 ,\n",
            "       -2.3774803], dtype=float32))])\n"
          ]
        }
      ],
      "source": [
        "print(\"_____OBSERVATION SPACE_____ \\n\")\n",
        "print(\"The State Space is: \", s_size)\n",
        "print(\"Sample observation\", env.observation_space.sample()) # Get a random observation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_JClfElGFnF"
      },
      "source": [
        "The observation space **is a dictionary with 3 different elements**:\n",
        "- `achieved_goal`: (x,y,z) position of the goal.\n",
        "- `desired_goal`: (x,y,z) distance between the goal position and the current object position.\n",
        "- `observation`: position (x,y,z) and velocity of the end-effector (vx, vy, vz).\n",
        "\n",
        "Given it's a dictionary as observation, **we will need to use a MultiInputPolicy policy instead of MlpPolicy**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "ib1Kxy4AF-FC"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " _____ACTION SPACE_____ \n",
            "\n",
            "The Action Space is:  Box([-1. -1. -1.], [1. 1. 1.], (3,), float32)\n",
            "Action Space Sample [-0.95349777  0.6345164  -0.3105311 ]\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n _____ACTION SPACE_____ \\n\")\n",
        "print(\"The Action Space is: \", a_size)\n",
        "print(\"Action Space Sample\", env.action_space.sample()) # Take a random action"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5MHTHEHZS4yp"
      },
      "source": [
        "The action space is a vector with 3 values:\n",
        "- Control x, y, z movement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nIhPoc5t9HjG"
      },
      "source": [
        "Now it's your turn:\n",
        "\n",
        "1. Define the environment called \"PandaReachDense-v2\"\n",
        "2. Make a vectorized environment\n",
        "3. Add a wrapper to normalize the observations and rewards. [Check the documentation](https://stable-baselines3.readthedocs.io/en/master/guide/vec_envs.html#vecnormalize)\n",
        "4. Create the A2C Model (don't forget verbose=1 to print the training logs).\n",
        "5. Train it for 1M Timesteps\n",
        "6. Save the model and  VecNormalize statistics when saving the agent\n",
        "7. Evaluate your agent\n",
        "8. Publish your trained model on the Hub 🔥 with `package_to_hub`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKGbFXZq9ikN"
      },
      "source": [
        "### Solution (fill the todo)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "J-cC-Feg9iMm"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cpu device\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 50       |\n",
            "|    ep_rew_mean        | -10.4    |\n",
            "| time/                 |          |\n",
            "|    fps                | 672      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 2000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -4.28    |\n",
            "|    explained_variance | 0.977    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 99       |\n",
            "|    policy_loss        | -2.25    |\n",
            "|    std                | 1.01     |\n",
            "|    value_loss         | 0.578    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 50       |\n",
            "|    ep_rew_mean        | -11.3    |\n",
            "| time/                 |          |\n",
            "|    fps                | 669      |\n",
            "|    iterations         | 200      |\n",
            "|    time_elapsed       | 5        |\n",
            "|    total_timesteps    | 4000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -4.29    |\n",
            "|    explained_variance | 0.991    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 199      |\n",
            "|    policy_loss        | -1.1     |\n",
            "|    std                | 1.01     |\n",
            "|    value_loss         | 0.297    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 50       |\n",
            "|    ep_rew_mean        | -12.2    |\n",
            "| time/                 |          |\n",
            "|    fps                | 658      |\n",
            "|    iterations         | 300      |\n",
            "|    time_elapsed       | 9        |\n",
            "|    total_timesteps    | 6000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -4.29    |\n",
            "|    explained_variance | 0.512    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 299      |\n",
            "|    policy_loss        | -9.08    |\n",
            "|    std                | 1.01     |\n",
            "|    value_loss         | 6.4      |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 50       |\n",
            "|    ep_rew_mean        | -15.2    |\n",
            "| time/                 |          |\n",
            "|    fps                | 647      |\n",
            "|    iterations         | 400      |\n",
            "|    time_elapsed       | 12       |\n",
            "|    total_timesteps    | 8000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -4.31    |\n",
            "|    explained_variance | -0.0279  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 399      |\n",
            "|    policy_loss        | -6.79    |\n",
            "|    std                | 1.02     |\n",
            "|    value_loss         | 4.34     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 50       |\n",
            "|    ep_rew_mean        | -15.5    |\n",
            "| time/                 |          |\n",
            "|    fps                | 642      |\n",
            "|    iterations         | 500      |\n",
            "|    time_elapsed       | 15       |\n",
            "|    total_timesteps    | 10000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -4.33    |\n",
            "|    explained_variance | 0.978    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 499      |\n",
            "|    policy_loss        | 0.0608   |\n",
            "|    std                | 1.02     |\n",
            "|    value_loss         | 0.276    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 50       |\n",
            "|    ep_rew_mean        | -13.6    |\n",
            "| time/                 |          |\n",
            "|    fps                | 645      |\n",
            "|    iterations         | 600      |\n",
            "|    time_elapsed       | 18       |\n",
            "|    total_timesteps    | 12000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -4.32    |\n",
            "|    explained_variance | 0.572    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 599      |\n",
            "|    policy_loss        | 0.657    |\n",
            "|    std                | 1.02     |\n",
            "|    value_loss         | 0.214    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 50       |\n",
            "|    ep_rew_mean        | -11.9    |\n",
            "| time/                 |          |\n",
            "|    fps                | 649      |\n",
            "|    iterations         | 700      |\n",
            "|    time_elapsed       | 21       |\n",
            "|    total_timesteps    | 14000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -4.33    |\n",
            "|    explained_variance | 0.815    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 699      |\n",
            "|    policy_loss        | -2.29    |\n",
            "|    std                | 1.02     |\n",
            "|    value_loss         | 0.698    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 50       |\n",
            "|    ep_rew_mean        | -12      |\n",
            "| time/                 |          |\n",
            "|    fps                | 656      |\n",
            "|    iterations         | 800      |\n",
            "|    time_elapsed       | 24       |\n",
            "|    total_timesteps    | 16000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -4.32    |\n",
            "|    explained_variance | 0.982    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 799      |\n",
            "|    policy_loss        | 0.109    |\n",
            "|    std                | 1.02     |\n",
            "|    value_loss         | 0.315    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 50       |\n",
            "|    ep_rew_mean        | -11      |\n",
            "| time/                 |          |\n",
            "|    fps                | 659      |\n",
            "|    iterations         | 900      |\n",
            "|    time_elapsed       | 27       |\n",
            "|    total_timesteps    | 18000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -4.32    |\n",
            "|    explained_variance | 0.998    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 899      |\n",
            "|    policy_loss        | -0.209   |\n",
            "|    std                | 1.02     |\n",
            "|    value_loss         | 0.0516   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 50       |\n",
            "|    ep_rew_mean        | -9.5     |\n",
            "| time/                 |          |\n",
            "|    fps                | 663      |\n",
            "|    iterations         | 1000     |\n",
            "|    time_elapsed       | 30       |\n",
            "|    total_timesteps    | 20000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -4.31    |\n",
            "|    explained_variance | 0.955    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 999      |\n",
            "|    policy_loss        | 0.426    |\n",
            "|    std                | 1.02     |\n",
            "|    value_loss         | 0.0812   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 50       |\n",
            "|    ep_rew_mean        | -8.74    |\n",
            "| time/                 |          |\n",
            "|    fps                | 664      |\n",
            "|    iterations         | 1100     |\n",
            "|    time_elapsed       | 33       |\n",
            "|    total_timesteps    | 22000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -4.3     |\n",
            "|    explained_variance | 0.986    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1099     |\n",
            "|    policy_loss        | 0.779    |\n",
            "|    std                | 1.01     |\n",
            "|    value_loss         | 0.244    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 50       |\n",
            "|    ep_rew_mean        | -9.01    |\n",
            "| time/                 |          |\n",
            "|    fps                | 661      |\n",
            "|    iterations         | 1200     |\n",
            "|    time_elapsed       | 36       |\n",
            "|    total_timesteps    | 24000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -4.28    |\n",
            "|    explained_variance | 0.95     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1199     |\n",
            "|    policy_loss        | -1.09    |\n",
            "|    std                | 1.01     |\n",
            "|    value_loss         | 0.195    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 50       |\n",
            "|    ep_rew_mean        | -8.5     |\n",
            "| time/                 |          |\n",
            "|    fps                | 663      |\n",
            "|    iterations         | 1300     |\n",
            "|    time_elapsed       | 39       |\n",
            "|    total_timesteps    | 26000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -4.26    |\n",
            "|    explained_variance | 0.995    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1299     |\n",
            "|    policy_loss        | -0.0923  |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 0.0628   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 50       |\n",
            "|    ep_rew_mean        | -7.44    |\n",
            "| time/                 |          |\n",
            "|    fps                | 664      |\n",
            "|    iterations         | 1400     |\n",
            "|    time_elapsed       | 42       |\n",
            "|    total_timesteps    | 28000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -4.24    |\n",
            "|    explained_variance | 0.995    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1399     |\n",
            "|    policy_loss        | -0.379   |\n",
            "|    std                | 0.993    |\n",
            "|    value_loss         | 0.0599   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 50       |\n",
            "|    ep_rew_mean        | -6.78    |\n",
            "| time/                 |          |\n",
            "|    fps                | 665      |\n",
            "|    iterations         | 1500     |\n",
            "|    time_elapsed       | 45       |\n",
            "|    total_timesteps    | 30000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -4.23    |\n",
            "|    explained_variance | 0.902    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1499     |\n",
            "|    policy_loss        | -0.781   |\n",
            "|    std                | 0.989    |\n",
            "|    value_loss         | 0.193    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 50       |\n",
            "|    ep_rew_mean        | -6.68    |\n",
            "| time/                 |          |\n",
            "|    fps                | 667      |\n",
            "|    iterations         | 1600     |\n",
            "|    time_elapsed       | 47       |\n",
            "|    total_timesteps    | 32000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -4.21    |\n",
            "|    explained_variance | 0.979    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1599     |\n",
            "|    policy_loss        | 0.316    |\n",
            "|    std                | 0.986    |\n",
            "|    value_loss         | 0.035    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 50       |\n",
            "|    ep_rew_mean        | -6.55    |\n",
            "| time/                 |          |\n",
            "|    fps                | 667      |\n",
            "|    iterations         | 1700     |\n",
            "|    time_elapsed       | 50       |\n",
            "|    total_timesteps    | 34000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -4.19    |\n",
            "|    explained_variance | 0.98     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1699     |\n",
            "|    policy_loss        | 0.126    |\n",
            "|    std                | 0.976    |\n",
            "|    value_loss         | 0.0472   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 50       |\n",
            "|    ep_rew_mean        | -5.93    |\n",
            "| time/                 |          |\n",
            "|    fps                | 666      |\n",
            "|    iterations         | 1800     |\n",
            "|    time_elapsed       | 53       |\n",
            "|    total_timesteps    | 36000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -4.18    |\n",
            "|    explained_variance | 0.887    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1799     |\n",
            "|    policy_loss        | 0.703    |\n",
            "|    std                | 0.974    |\n",
            "|    value_loss         | 0.161    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 50       |\n",
            "|    ep_rew_mean        | -5.59    |\n",
            "| time/                 |          |\n",
            "|    fps                | 664      |\n",
            "|    iterations         | 1900     |\n",
            "|    time_elapsed       | 57       |\n",
            "|    total_timesteps    | 38000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -4.16    |\n",
            "|    explained_variance | 0.996    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1899     |\n",
            "|    policy_loss        | -0.0241  |\n",
            "|    std                | 0.968    |\n",
            "|    value_loss         | 0.0328   |\n",
            "------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# 1 - 2\n",
        "env_id = \"PandaReachDense-v2\"\n",
        "env = make_vec_env(env_id, n_envs=4)\n",
        "\n",
        "# 3\n",
        "env = VecNormalize(env, norm_obs=True, norm_reward=False, \n",
        "clip_obs=10.)\n",
        "\n",
        "# 4\n",
        "model = A2C(policy = \"MultiInputPolicy\",\n",
        "            env = env,\n",
        "            verbose=1)\n",
        "# 5\n",
        "model.learn(1_000_000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-UnlKLmpg80p"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/aj/anaconda3/envs/HF_DRL/lib/python3.8/site-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean reward = -5.74 +/- 0.86\n",
            "\u001b[38;5;4mℹ This function will save, evaluate, generate a video of your agent,\n",
            "create a model card and push everything to the hub. It might take up to 1min.\n",
            "This is a work in progress: if you encounter a bug, please open an issue.\u001b[0m\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Token is required (write-access action) but no token found. You need to provide a token or be logged in to Hugging Face with `huggingface-cli login` or `huggingface_hub.login`. See https://huggingface.co/settings/tokens.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-da34eedc559c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# 8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m package_to_hub(\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"a2c-{env_id}\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/HF_DRL/lib/python3.8/site-packages/huggingface_sb3/push_to_hub.py\u001b[0m in \u001b[0;36mpackage_to_hub\u001b[0;34m(model, model_name, model_architecture, env_id, eval_env, repo_id, commit_message, is_deterministic, n_eval_episodes, token, video_length, logs)\u001b[0m\n\u001b[1;32m    331\u001b[0m     )\n\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m     repo_url = HfApi().create_repo(\n\u001b[0m\u001b[1;32m    334\u001b[0m         \u001b[0mrepo_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrepo_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m         \u001b[0mtoken\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/HF_DRL/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    122\u001b[0m             )\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_inner_fn\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/HF_DRL/lib/python3.8/site-packages/huggingface_hub/hf_api.py\u001b[0m in \u001b[0;36mcreate_repo\u001b[0;34m(self, repo_id, token, private, repo_type, exist_ok, space_sdk, space_hardware)\u001b[0m\n\u001b[1;32m   2004\u001b[0m             \u001b[0;31m# See https://github.com/huggingface/huggingface_hub/pull/733/files#r820604472\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2005\u001b[0m             \u001b[0mjson\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"lfsmultipartthresh\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lfsmultipartthresh\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2006\u001b[0;31m         \u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_hf_headers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_write_action\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2007\u001b[0m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/HF_DRL/lib/python3.8/site-packages/huggingface_hub/hf_api.py\u001b[0m in \u001b[0;36m_build_hf_headers\u001b[0;34m(self, token, is_write_action, library_name, library_version, user_agent)\u001b[0m\n\u001b[1;32m   3996\u001b[0m             \u001b[0;31m# Cannot do `token = token or self.token` as token can be `False`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3997\u001b[0m             \u001b[0mtoken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3998\u001b[0;31m         return build_hf_headers(\n\u001b[0m\u001b[1;32m   3999\u001b[0m             \u001b[0mtoken\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4000\u001b[0m             \u001b[0mis_write_action\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_write_action\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/HF_DRL/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    122\u001b[0m             )\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_inner_fn\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/HF_DRL/lib/python3.8/site-packages/huggingface_hub/utils/_headers.py\u001b[0m in \u001b[0;36mbuild_hf_headers\u001b[0;34m(token, is_write_action, library_name, library_version, user_agent)\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;31m# Get auth token to send\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0mtoken_to_send\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_token_to_send\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m     \u001b[0m_validate_token_to_send\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_to_send\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_write_action\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_write_action\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;31m# Combine headers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/HF_DRL/lib/python3.8/site-packages/huggingface_hub/utils/_headers.py\u001b[0m in \u001b[0;36m_validate_token_to_send\u001b[0;34m(token, is_write_action)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_write_action\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    169\u001b[0m                 \u001b[0;34m\"Token is required (write-access action) but no token found. You need\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0;34m\" to provide a token or be logged in to Hugging Face with\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Token is required (write-access action) but no token found. You need to provide a token or be logged in to Hugging Face with `huggingface-cli login` or `huggingface_hub.login`. See https://huggingface.co/settings/tokens."
          ]
        }
      ],
      "source": [
        "# 6\n",
        "model_name = \"a2c-PandaReachDense-v2\"; \n",
        "model.save(model_name)\n",
        "env.save(\"vec_normalize.pkl\")\n",
        "\n",
        "# 7\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize\n",
        "\n",
        "# Load the saved statistics\n",
        "eval_env = DummyVecEnv([lambda: gym.make(\"PandaReachDense-v2\")])\n",
        "eval_env = VecNormalize.load(\"vec_normalize.pkl\", eval_env)\n",
        "\n",
        "#  do not update them at test time\n",
        "eval_env.training = False\n",
        "# reward normalization is not needed at test time\n",
        "eval_env.norm_reward = False\n",
        "\n",
        "# Load the agent\n",
        "model = A2C.load(model_name)\n",
        "\n",
        "mean_reward, std_reward = evaluate_policy(model, eval_env)\n",
        "\n",
        "print(f\"Mean reward = {mean_reward:.2f} +/- {std_reward:.2f}\")\n",
        "\n",
        "# 8\n",
        "package_to_hub(\n",
        "    model=model,\n",
        "    model_name=f\"a2c-{env_id}\",\n",
        "    model_architecture=\"A2C\",\n",
        "    env_id=env_id,\n",
        "    eval_env=eval_env,\n",
        "    repo_id=f\"aj555/a2c-{env_id}\",\n",
        "    commit_message=\"Initial commit\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3xy3Nf3c2O1"
      },
      "source": [
        "## Some additional challenges 🏆\n",
        "The best way to learn **is to try things by your own**! Why not trying  `HalfCheetahBulletEnv-v0` for PyBullet and `PandaPickAndPlace-v1` for Panda-Gym?\n",
        "\n",
        "If you want to try more advanced tasks for panda-gym, you need to check what was done using **TQC or SAC** (a more sample-efficient algorithm suited for robotics tasks). In real robotics, you'll use a more sample-efficient algorithm for a simple reason: contrary to a simulation **if you move your robotic arm too much, you have a risk of breaking it**.\n",
        "\n",
        "PandaPickAndPlace-v1: https://huggingface.co/sb3/tqc-PandaPickAndPlace-v1\n",
        "\n",
        "And don't hesitate to check panda-gym documentation here: https://panda-gym.readthedocs.io/en/latest/usage/train_with_sb3.html\n",
        "\n",
        "Here are some ideas to achieve so:\n",
        "* Train more steps\n",
        "* Try different hyperparameters by looking at what your classmates have done 👉 https://huggingface.co/models?other=https://huggingface.co/models?other=AntBulletEnv-v0\n",
        "* **Push your new trained model** on the Hub 🔥\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "HF_DRL",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    },
    "vscode": {
      "interpreter": {
        "hash": "b1089e4da3f7a38888587a387f67039009d38b8ad345f7a22dd1961070ac9117"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
