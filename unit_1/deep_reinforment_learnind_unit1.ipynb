{"cells":[{"cell_type":"markdown","metadata":{"id":"njb_ProuHiOe"},"source":["# Unit 1: Train your first Deep Reinforcement Learning Agent ü§ñ\n","![Cover](https://github.com/huggingface/deep-rl-class/blob/main/unit1/assets/img/thumbnail.png?raw=true)\n","\n","In this notebook, you'll train your **first Deep Reinforcement Learning agent** a Lunar Lander agent that will learn to **land correctly on the Moon üåï**. Using [Stable-Baselines3](https://stable-baselines3.readthedocs.io/en/master/) a Deep Reinforcement Learning library, share them with the community, and experiment with different configurations\n","\n","‚¨áÔ∏è Here is an example of what **you will achieve in just a couple of minutes.** ‚¨áÔ∏è\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":421},"executionInfo":{"elapsed":212,"status":"ok","timestamp":1673287029086,"user":{"displayName":"Andrew Johnson (earyzhe)","userId":"17854936619688322601"},"user_tz":-60},"id":"PF46MwbZD00b","outputId":"82024216-5318-4236-ec6a-e482434d2ddb"},"outputs":[{"data":{"text/html":["<video controls autoplay><source src=\"https://huggingface.co/ThomasSimonini/ppo-LunarLander-v2/resolve/main/replay.mp4\" type=\"video/mp4\"></video>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["%%html\n","<video controls autoplay><source src=\"https://huggingface.co/ThomasSimonini/ppo-LunarLander-v2/resolve/main/replay.mp4\" type=\"video/mp4\"></video>"]},{"cell_type":"markdown","metadata":{"id":"x7oR6R-ZIbeS"},"source":["### The environment üéÆ\n","- [LunarLander-v2](https://www.gymlibrary.dev/environments/box2d/lunar_lander/)\n","\n","### The library used üìö\n","- [Stable-Baselines3](https://stable-baselines3.readthedocs.io/en/master/)"]},{"cell_type":"markdown","metadata":{"id":"OwEcFHe9RRZW"},"source":["We're constantly trying to improve our tutorials, so **if you find some issues in this notebook**, please [open an issue on the Github Repo](https://github.com/huggingface/deep-rl-class/issues)."]},{"cell_type":"markdown","metadata":{"id":"4i6tjI2tHQ8j"},"source":["## Objectives of this notebook üèÜ\n","At the end of the notebook, you will:\n","- Be able to use **Gym**, the environment library.\n","- Be able to use **Stable-Baselines3**, the deep reinforcement learning library.\n","- Be able to **push your trained agent to the Hub** with a nice video replay and an evaluation score üî•.\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Ff-nyJdzJPND"},"source":["## This notebook is from Deep Reinforcement Learning Course\n","<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/deep-rl-course-illustration.jpg\" alt=\"Deep RL Course illustration\"/>"]},{"cell_type":"markdown","metadata":{"id":"6p5HnEefISCB"},"source":["In this free course, you will:\n","\n","- üìñ Study Deep Reinforcement Learning in **theory and practice**.\n","- üßë‚Äçüíª Learn to **use famous Deep RL libraries** such as Stable Baselines3, RL Baselines3 Zoo, CleanRL and Sample Factory 2.0.\n","- ü§ñ Train **agents in unique environments** \n","\n","And more check üìö the syllabus üëâ https://simoninithomas.github.io/deep-rl-course\n","\n","Don‚Äôt forget to **<a href=\"http://eepurl.com/ic5ZUD\">sign up to the course</a>** (we are collecting your email to be able to¬†**send you the links when each Unit is published and give you information about the challenges and updates).**\n","\n","\n","The best way to keep in touch and ask questions is to join our discord server to exchange with the community and with us üëâüèª https://discord.gg/ydHrjt3WP5"]},{"cell_type":"markdown","metadata":{"id":"Y-mo_6rXIjRi"},"source":["## Prerequisites üèóÔ∏è\n","Before diving into the notebook, you need to:\n","\n","üî≤ üìù **[Read Unit 0](https://huggingface.co/deep-rl-course/unit0/introduction)** that gives you all the **information about the course and help you to onboard** ü§ó\n","\n","üî≤ üìö **Develop an understanding of the foundations of Reinforcement learning** (MC, TD, Rewards hypothesis...) by [reading Unit 1](https://huggingface.co/deep-rl-course/unit1/introduction)."]},{"cell_type":"markdown","metadata":{"id":"HoeqMnr5LuYE"},"source":["## A small recap of what is Deep Reinforcement Learning üìö\n","<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit1/RL_process_game.jpg\" alt=\"The RL process\" width=\"100%\">"]},{"cell_type":"markdown","metadata":{"id":"xcQYx9ynaFMD"},"source":["Let's do a small recap on what we learned in the first Unit:\n","- Reinforcement Learning is a **computational approach to learning from action**. We build an agent that learns from the environment by **interacting with it through trial and error** and receiving rewards (negative or positive) as feedback.\n","\n","- The goal of any RL agent is to **maximize its expected cumulative reward** (also called expected return) because RL is based on the _reward hypothesis_, which is that all goals can be described as the maximization of the expected cumulative reward.\n","\n","- The RL process is a **loop that outputs a sequence of state, action, reward, and next state**.\n","\n","- To calculate the expected cumulative reward (expected return), **we discount the rewards**: the rewards that come sooner (at the beginning of the game) are more probable to happen since they are more predictable than the long-term future reward.\n","\n","- To solve an RL problem, you want to **find an optimal policy**; the policy is the \"brain\" of your AI that will tell us what action to take given a state. The optimal one is the one that gives you the actions that max the expected return.\n"]},{"cell_type":"markdown","metadata":{"id":"8X2WN2X99BEz"},"source":["There are **two** ways to find your optimal policy:\n","- By **training your policy directly**: policy-based methods.\n","- By **training a value function** that tells us the expected return the agent will get at each state and use this function to define our policy: value-based methods."]},{"cell_type":"markdown","metadata":{"id":"BPy6dfcm8_WT"},"source":["- Finally, we spoke about Deep RL because **we introduce deep neural networks to estimate the action to take (policy-based) or to estimate the value of a state (value-based) hence the name \"deep.\"**"]},{"cell_type":"markdown","metadata":{"id":"LzGDDOTSKaF8"},"source":["# Let's train our first Deep Reinforcement Learning agent and upload it to the Hub üöÄ\n"]},{"cell_type":"markdown","metadata":{"id":"qDploC3jSH99"},"source":["## Get a certificate\n","To validate this hands-on for the [certification process](https://huggingface.co/deep-rl-course/en/unit0/introduction#certification-process), you need to push your trained model to the Hub and **get a result of >= 200**.\n","\n","To find your result, go to the [leaderboard](https://huggingface.co/spaces/huggingface-projects/Deep-Reinforcement-Learning-Leaderboard) and find your model, **the result = mean_reward - std of reward**\n","\n","For more information about the certification process, check this section üëâ https://huggingface.co/deep-rl-course/en/unit0/introduction#certification-process"]},{"cell_type":"markdown","metadata":{"id":"HqzznTzhNfAC"},"source":["## Set the GPU üí™\n","- To **accelerate the agent's training, we'll use a GPU**. To do that, go to `Runtime > Change Runtime type`\n","\n","<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/gpu-step1.jpg\" alt=\"GPU Step 1\">"]},{"cell_type":"markdown","metadata":{"id":"38HBd3t1SHJ8"},"source":["- `Hardware Accelerator > GPU`\n","\n","<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/gpu-step2.jpg\" alt=\"GPU Step 2\">"]},{"cell_type":"markdown","metadata":{"id":"jeDAH0h0EBiG"},"source":["## Install dependencies and create a virtual screen üîΩ\n","The first step is to install the dependencies, we‚Äôll install multiple ones.\n","\n","- `gym[box2D]`: Contains the LunarLander-v2 environment üåõ (we use `gym==0.21`)\n","- `stable-baselines3[extra]`: The deep reinforcement learning library.\n","- `huggingface_sb3`: Additional code for Stable-baselines3 to load and upload models from the Hugging Face ü§ó Hub.\n","\n","To make things easier, we created a script to install all these dependencies."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6884,"status":"ok","timestamp":1673287043605,"user":{"displayName":"Andrew Johnson (earyzhe)","userId":"17854936619688322601"},"user_tz":-60},"id":"yQIGLPDkGhgG","outputId":"3f5d2801-5aa4-4d65-de22-c09fec18bf57"},"outputs":[{"name":"stdout","output_type":"stream","text":["Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","cmake is already the newest version (3.10.2-1ubuntu2.18.04.2).\n","The following package was automatically installed and is no longer required:\n","  libnvidia-common-460\n","Use 'apt autoremove' to remove it.\n","Suggested packages:\n","  swig-doc swig-examples swig3.0-examples swig3.0-doc\n","The following NEW packages will be installed:\n","  swig swig3.0\n","0 upgraded, 2 newly installed, 0 to remove and 21 not upgraded.\n","Need to get 1,100 kB of archives.\n","After this operation, 5,822 kB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 swig3.0 amd64 3.0.12-1 [1,094 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 swig amd64 3.0.12-1 [6,460 B]\n","Fetched 1,100 kB in 1s (1,203 kB/s)\n","Selecting previously unselected package swig3.0.\n","(Reading database ... 124016 files and directories currently installed.)\n","Preparing to unpack .../swig3.0_3.0.12-1_amd64.deb ...\n","Unpacking swig3.0 (3.0.12-1) ...\n","Selecting previously unselected package swig.\n","Preparing to unpack .../swig_3.0.12-1_amd64.deb ...\n","Unpacking swig (3.0.12-1) ...\n","Setting up swig3.0 (3.0.12-1) ...\n","Setting up swig (3.0.12-1) ...\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"]}],"source":["!apt install swig cmake"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":54319,"status":"ok","timestamp":1673287097917,"user":{"displayName":"Andrew Johnson (earyzhe)","userId":"17854936619688322601"},"user_tz":-60},"id":"9XaULfDZDvrC","outputId":"bac50f06-96bf-41d9-aad9-0630619783ce"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting stable-baselines3[extra]\n","  Downloading stable_baselines3-1.6.2-py3-none-any.whl (170 kB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m170.0/170.0 KB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting box2d\n","  Downloading Box2D-2.3.10-cp38-cp38-manylinux1_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting box2d-kengz\n","  Downloading Box2D-kengz-2.3.3.tar.gz (425 kB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m425.4/425.4 KB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting huggingface_sb3\n","  Downloading huggingface_sb3-2.2.4-py3-none-any.whl (9.4 kB)\n","Collecting pyglet==1.5.1\n","  Downloading pyglet-1.5.1-py2.py3-none-any.whl (1.0 MB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m61.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: cloudpickle in /usr/local/lib/python3.8/dist-packages (from stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (1.5.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (1.3.5)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (3.2.2)\n","Collecting importlib-metadata~=4.13\n","  Downloading importlib_metadata-4.13.0-py3-none-any.whl (23 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (1.21.6)\n","Collecting gym==0.21\n","  Downloading gym-0.21.0.tar.gz (1.5 MB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m83.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: torch>=1.11 in /usr/local/lib/python3.8/dist-packages (from stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (1.13.0+cu116)\n","Collecting ale-py==0.7.4\n","  Downloading ale_py-0.7.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m81.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tensorboard>=2.9.1 in /usr/local/lib/python3.8/dist-packages (from stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (2.9.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (4.64.1)\n","Collecting rich\n","  Downloading rich-13.0.1-py3-none-any.whl (238 kB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m238.1/238.1 KB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting autorom[accept-rom-license]~=0.4.2\n","  Downloading AutoROM-0.4.2-py3-none-any.whl (16 kB)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.8/dist-packages (from stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (7.1.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (from stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (5.4.8)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.8/dist-packages (from stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (4.6.0.66)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.8/dist-packages (from ale-py==0.7.4->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (5.10.1)\n","Requirement already satisfied: wasabi in /usr/local/lib/python3.8/dist-packages (from huggingface_sb3->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 4)) (0.10.1)\n","Collecting huggingface-hub~=0.8\n","  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m182.4/182.4 KB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting cloudpickle\n","  Downloading cloudpickle-2.2.0-py3-none-any.whl (25 kB)\n","Requirement already satisfied: pyyaml~=6.0 in /usr/local/lib/python3.8/dist-packages (from huggingface_sb3->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 4)) (6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (2.25.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (7.1.2)\n","Collecting AutoROM.accept-rom-license\n","  Downloading AutoROM.accept-rom-license-0.5.0.tar.gz (10 kB)\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub~=0.8->huggingface_sb3->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 4)) (4.4.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub~=0.8->huggingface_sb3->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 4)) (3.8.2)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub~=0.8->huggingface_sb3->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 4)) (21.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata~=4.13->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (3.11.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (0.38.4)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (0.6.1)\n","Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (3.19.6)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (1.3.0)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (1.51.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (3.4.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (1.0.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (1.8.1)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (57.4.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (2.15.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (0.4.6)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (1.4.4)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (2.8.2)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (3.0.9)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (0.11.0)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (2022.7)\n","Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.8/dist-packages (from rich->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (2.6.1)\n","Collecting commonmark<0.10.0,>=0.9.0\n","  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m51.1/51.1 KB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (5.2.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (4.9)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (0.2.8)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (1.15.0)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.9.1->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (1.3.1)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (4.0.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (2022.12.7)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (2.10)\n","Collecting libtorrent\n","  Using cached libtorrent-2.0.7-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (8.6 MB)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.9.1->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (3.2.2)\n","Building wheels for collected packages: gym, box2d-kengz, AutoROM.accept-rom-license\n","  Building wheel for gym (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gym: filename=gym-0.21.0-py3-none-any.whl size=1616822 sha256=61504d8afdf4ace213c9d65f2499be66a538b2ca9e576b4a7b1555e0c1d796ae\n","  Stored in directory: /root/.cache/pip/wheels/27/6d/b3/a3a6e10704795c9b9000f1ab2dc480dfe7bed42f5972806e73\n","  Building wheel for box2d-kengz (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for box2d-kengz: filename=Box2D_kengz-2.3.3-cp38-cp38-linux_x86_64.whl size=2084461 sha256=aebf05238b5dcc5356c58108a145b00e9ff531ad05a5048ba94e39837dba42ad\n","  Stored in directory: /root/.cache/pip/wheels/87/3a/ed/260cc09ed176c5b06aed67364b2387a3a62e7351396a979555\n","  Building wheel for AutoROM.accept-rom-license (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for AutoROM.accept-rom-license: filename=AutoROM.accept_rom_license-0.5.0-py3-none-any.whl size=440868 sha256=b78bc9da916c1b5a7c0bd1767c4e428fba76eee375802e181034d5316de5f85d\n","  Stored in directory: /root/.cache/pip/wheels/bf/c9/25/578470ae932b494c313dc22e6c57afff192140fb3cd5acf185\n","Successfully built gym box2d-kengz AutoROM.accept-rom-license\n","Installing collected packages: pyglet, libtorrent, commonmark, box2d-kengz, box2d, rich, importlib-metadata, cloudpickle, huggingface-hub, gym, AutoROM.accept-rom-license, autorom, ale-py, stable-baselines3, huggingface_sb3\n","  Attempting uninstall: importlib-metadata\n","    Found existing installation: importlib-metadata 5.2.0\n","    Uninstalling importlib-metadata-5.2.0:\n","      Successfully uninstalled importlib-metadata-5.2.0\n","  Attempting uninstall: cloudpickle\n","    Found existing installation: cloudpickle 1.5.0\n","    Uninstalling cloudpickle-1.5.0:\n","      Successfully uninstalled cloudpickle-1.5.0\n","  Attempting uninstall: gym\n","    Found existing installation: gym 0.25.2\n","    Uninstalling gym-0.25.2:\n","      Successfully uninstalled gym-0.25.2\n","Successfully installed AutoROM.accept-rom-license-0.5.0 ale-py-0.7.4 autorom-0.4.2 box2d-2.3.10 box2d-kengz-2.3.3 cloudpickle-2.2.0 commonmark-0.9.1 gym-0.21.0 huggingface-hub-0.11.1 huggingface_sb3-2.2.4 importlib-metadata-4.13.0 libtorrent-2.0.7 pyglet-1.5.1 rich-13.0.1 stable-baselines3-1.6.2\n"]}],"source":["!pip install -r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt"]},{"cell_type":"markdown","metadata":{"id":"BEKeXQJsQCYm"},"source":["During the notebook, we'll need to generate a replay video. To do so, with colab, **we need to have a virtual screen to be able to render the environment** (and thus record the frames). \n","\n","Hence the following cell will install virtual screen libraries and create and run a virtual screen üñ•"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25214,"status":"ok","timestamp":1673287123353,"user":{"displayName":"Andrew Johnson (earyzhe)","userId":"17854936619688322601"},"user_tz":-60},"id":"j5f2cGkdP-mb","outputId":"a98b60d6-8f00-4ffe-871f-911fc7f26909"},"outputs":[{"name":"stdout","output_type":"stream","text":["\r0% [Working]\r            \rGet:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n","\r0% [Connecting to archive.ubuntu.com] [1 InRelease 14.2 kB/88.7 kB 16%] [Connec\r                                                                               \rGet:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n","\r0% [Connecting to archive.ubuntu.com (185.125.190.39)] [1 InRelease 37.3 kB/88.\r0% [Connecting to archive.ubuntu.com (185.125.190.39)] [1 InRelease 43.1 kB/88.\r0% [2 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (185.125.190.39\r0% [2 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (185.125.190.39\r                                                                               \rGet:3 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n","\r0% [2 InRelease gpgv 3,626 B] [Waiting for headers] [Waiting for headers] [3 In\r                                                                               \rIgn:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n","\r0% [2 InRelease gpgv 3,626 B] [Waiting for headers] [Waiting for headers] [3 In\r                                                                               \rHit:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n","\r0% [2 InRelease gpgv 3,626 B] [Waiting for headers] [3 InRelease 14.2 kB/15.9 k\r                                                                               \rHit:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n","Hit:7 http://archive.ubuntu.com/ubuntu bionic InRelease\n","Get:8 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n","Get:9 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [1,349 kB]\n","Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n","Get:11 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,573 kB]\n","Hit:13 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n","Get:14 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [3,127 kB]\n","Get:15 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [83.3 kB]\n","Get:16 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n","Get:17 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [2,240 kB]\n","Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [1,389 kB]\n","Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,348 kB]\n","Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [30.8 kB]\n","Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,550 kB]\n","Get:22 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [1,145 kB]\n","Get:23 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [43.2 kB]\n","Fetched 17.1 MB in 3s (5,608 kB/s)\n","Reading package lists... Done\n","Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","The following package was automatically installed and is no longer required:\n","  libnvidia-common-460\n","Use 'apt autoremove' to remove it.\n","The following additional packages will be installed:\n","  freeglut3\n","Suggested packages:\n","  libgle3\n","The following NEW packages will be installed:\n","  freeglut3 python-opengl\n","0 upgraded, 2 newly installed, 0 to remove and 26 not upgraded.\n","Need to get 570 kB of archives.\n","After this operation, 5,733 kB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 freeglut3 amd64 2.8.1-3 [73.6 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python-opengl all 3.1.0+dfsg-1 [496 kB]\n","Fetched 570 kB in 1s (709 kB/s)\n","Selecting previously unselected package freeglut3:amd64.\n","(Reading database ... 124807 files and directories currently installed.)\n","Preparing to unpack .../freeglut3_2.8.1-3_amd64.deb ...\n","Unpacking freeglut3:amd64 (2.8.1-3) ...\n","Selecting previously unselected package python-opengl.\n","Preparing to unpack .../python-opengl_3.1.0+dfsg-1_all.deb ...\n","Unpacking python-opengl (3.1.0+dfsg-1) ...\n","Setting up freeglut3:amd64 (2.8.1-3) ...\n","Setting up python-opengl (3.1.0+dfsg-1) ...\n","Processing triggers for libc-bin (2.27-3ubuntu1.6) ...\n","Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","ffmpeg is already the newest version (7:3.4.11-0ubuntu0.1).\n","The following package was automatically installed and is no longer required:\n","  libnvidia-common-460\n","Use 'apt autoremove' to remove it.\n","0 upgraded, 0 newly installed, 0 to remove and 26 not upgraded.\n","Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","The following package was automatically installed and is no longer required:\n","  libnvidia-common-460\n","Use 'apt autoremove' to remove it.\n","The following NEW packages will be installed:\n","  xvfb\n","0 upgraded, 1 newly installed, 0 to remove and 26 not upgraded.\n","Need to get 785 kB of archives.\n","After this operation, 2,271 kB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 xvfb amd64 2:1.19.6-1ubuntu4.13 [785 kB]\n","Fetched 785 kB in 1s (1,050 kB/s)\n","Selecting previously unselected package xvfb.\n","(Reading database ... 127167 files and directories currently installed.)\n","Preparing to unpack .../xvfb_2%3a1.19.6-1ubuntu4.13_amd64.deb ...\n","Unpacking xvfb (2:1.19.6-1ubuntu4.13) ...\n","Setting up xvfb (2:1.19.6-1ubuntu4.13) ...\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pyvirtualdisplay\n","  Downloading PyVirtualDisplay-3.0-py3-none-any.whl (15 kB)\n","Installing collected packages: pyvirtualdisplay\n","Successfully installed pyvirtualdisplay-3.0\n"]}],"source":["!sudo apt-get update\n","!apt install python-opengl\n","!apt install ffmpeg\n","!apt install xvfb\n","!pip3 install pyvirtualdisplay"]},{"cell_type":"markdown","metadata":{"id":"TCwBTAwAW9JJ"},"source":["To make sure the new installed libraries are used, **sometimes it's required to restart the notebook runtime**. The next cell will force the **runtime to crash, so you'll need to connect again and run the code starting from here**. Thanks for this trick, **we will be able to run our virtual screen.**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cYvkbef7XEMi"},"outputs":[],"source":["import os\n","\n","os.kill(os.getpid(), 9)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":377,"status":"ok","timestamp":1673287652340,"user":{"displayName":"Andrew Johnson (earyzhe)","userId":"17854936619688322601"},"user_tz":-60},"id":"BE5JWP5rQIKf","outputId":"3bc90504-6132-4a5a-89ce-8861284b2a18"},"outputs":[{"data":{"text/plain":["<pyvirtualdisplay.display.Display at 0x7f9e2e5d37c0>"]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["\n","# Virtual display\n","from pyvirtualdisplay import Display\n","\n","virtual_display = Display(visible=0, size=(1400, 900))\n","virtual_display.start()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cygWLPGsEQ0m"},"outputs":[],"source":["import gym\n","\n","from huggingface_sb3 import load_from_hub, package_to_hub, push_to_hub\n","from huggingface_hub import notebook_login # To log to our Hugging Face account to be able to upload models to the Hub.\n","\n","from stable_baselines3 import PPO\n","from stable_baselines3.common.evaluation import evaluate_policy\n","from stable_baselines3.common.env_util import make_vec_env"]},{"cell_type":"markdown","metadata":{"id":"wrgpVFqyENVf"},"source":["## Import the packages üì¶\n","\n","One additional library we import is huggingface_hub **to be able to upload and download trained models from the hub**.\n","\n","\n","The Hugging Face Hub ü§ó works as a central place where anyone can share and explore models and datasets. It has versioning, metrics, visualizations and other features that will allow you to easily collaborate with others.\n","\n","You can see here all the Deep reinforcement Learning models available üëâ https://huggingface.co/models?pipeline_tag=reinforcement-learning&sort=downloads\n","\n"]},{"cell_type":"markdown","metadata":{"id":"MRqRuRUl8CsB"},"source":["## Understand what is Gym and how it works ü§ñ\n","\n","üèã The library containing our environment is called Gym.\n","**You'll use Gym a lot in Deep Reinforcement Learning.**\n","\n","The Gym library provides two things:\n","- An interface that allows you to **create RL environments**.\n","- A **collection of environments** (gym-control, atari, box2D...).\n","\n","Let's look at an example, but first let's remember what's the RL Loop.\n","\n","<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit1/RL_process_game.jpg\" alt=\"The RL process\" width=\"100%\">"]},{"cell_type":"markdown","metadata":{"id":"-TzNN0bQ_j-3"},"source":["At each step:\n","- Our Agent receives¬†**state S0**¬†from the¬†**Environment**¬†‚Äî we receive the first frame of our game (Environment).\n","- Based on that¬†**state S0,**¬†the Agent takes¬†**action A0**¬†‚Äî our Agent will move to the right.\n","- Environment to a¬†**new**¬†**state S1**¬†‚Äî new frame.\n","- The environment gives some¬†**reward R1**¬†to the Agent ‚Äî we‚Äôre not dead¬†*(Positive Reward +1)*.\n","\n","\n","With Gym:\n","\n","1Ô∏è‚É£ We create our environment using `gym.make()`\n","\n","2Ô∏è‚É£ We reset the environment to its initial state with `observation = env.reset()`\n","\n","At each step:\n","\n","3Ô∏è‚É£ Get an action using our model (in our example we take a random action)\n","\n","4Ô∏è‚É£ Using `env.step(action)`, we perform this action in the environment and get\n","- `observation`: The new state (st+1)\n","- `reward`: The reward we get after executing the action\n","- `done`: Indicates if the episode terminated\n","- `info`: A dictionary that provides additional information (depends on the environment).\n","\n","If the episode is done:\n","- We reset the environment to its initial state with `observation = env.reset()`\n","\n","**Let's look at an example!** Make sure to read the code\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1673287666440,"user":{"displayName":"Andrew Johnson (earyzhe)","userId":"17854936619688322601"},"user_tz":-60},"id":"w7vOFlpA_ONz","outputId":"6170dc0f-0a8f-4cd0-ba45-388c37b22bff"},"outputs":[{"name":"stdout","output_type":"stream","text":["Action taken: 1\n","Action taken: 1\n","Action taken: 3\n","Action taken: 1\n","Action taken: 1\n","Action taken: 2\n","Action taken: 0\n","Action taken: 2\n","Action taken: 2\n","Action taken: 2\n","Action taken: 2\n","Action taken: 2\n","Action taken: 3\n","Action taken: 1\n","Action taken: 1\n","Action taken: 0\n","Action taken: 3\n","Action taken: 0\n","Action taken: 0\n","Action taken: 0\n"]}],"source":["import gym\n","\n","# First, we create our environment called LunarLander-v2\n","env = gym.make(\"LunarLander-v2\")\n","\n","# Then we reset this environment\n","observation = env.reset()\n","\n","for _ in range(20):\n","  # Take a random action\n","  action = env.action_space.sample()\n","  print(\"Action taken:\", action)\n","\n","  # Do this action in the environment and get\n","  # next_state, reward, done and info\n","  observation, reward, done, info = env.step(action)\n","  \n","  # If the game is done (in our case we land, crashed or timeout)\n","  if done:\n","      # Reset the environment\n","      print(\"Environment is reset\")\n","      observation = env.reset()"]},{"cell_type":"markdown","metadata":{"id":"XIrKGGSlENZB"},"source":["## Create the LunarLander environment üåõ and understand how it works\n","### [The environment üéÆ](https://www.gymlibrary.dev/environments/box2d/lunar_lander/)\n","In this first tutorial, we‚Äôre going to train our agent, a [Lunar Lander](https://www.gymlibrary.dev/environments/box2d/lunar_lander/), **to land correctly on the moon**. To do that, the agent needs to learn **to adapt its speed and position(horizontal, vertical, and angular) to land correctly.**\n","\n","\n","---\n","\n","\n","üí° A good habit when you start to use an environment is to check its documentation \n","\n","üëâ https://www.gymlibrary.dev/environments/box2d/lunar_lander/\n","\n","---\n"]},{"cell_type":"markdown","metadata":{"id":"poLBgRocF9aT"},"source":["Let's see what the Environment looks like:\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1673287666441,"user":{"displayName":"Andrew Johnson (earyzhe)","userId":"17854936619688322601"},"user_tz":-60},"id":"ZNPG0g_UGCfh","outputId":"116bf964-4b79-4ea9-96ab-359bd70bde4a"},"outputs":[{"name":"stdout","output_type":"stream","text":["_____OBSERVATION SPACE_____ \n","\n","Observation Space Shape (8,)\n","Sample observation [ 0.18690892 -0.2470334  -0.00544471  1.8720821  -1.2937819   1.6531628\n"," -0.5140588  -1.9109979 ]\n"]}],"source":["# We create our environment with gym.make(\"<name_of_the_environment>\")\n","env = gym.make(\"LunarLander-v2\")\n","env.reset()\n","print(\"_____OBSERVATION SPACE_____ \\n\")\n","print(\"Observation Space Shape\", env.observation_space.shape)\n","print(\"Sample observation\", env.observation_space.sample()) # Get a random observation"]},{"cell_type":"markdown","metadata":{"id":"2MXc15qFE0M9"},"source":["We see with `Observation Space Shape (8,)` that the observation is a vector of size 8, where each value contains different information about the lander:\n","- Horizontal pad coordinate (x)\n","- Vertical pad coordinate (y)\n","- Horizontal speed (x)\n","- Vertical speed (y)\n","- Angle\n","- Angular speed\n","- If the left leg has contact point touched the land\n","- If the right leg has contact point touched the land\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1673287666442,"user":{"displayName":"Andrew Johnson (earyzhe)","userId":"17854936619688322601"},"user_tz":-60},"id":"We5WqOBGLoSm","outputId":"b62707d0-205e-40c6-cdc2-dbdf803a93fa"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n"," _____ACTION SPACE_____ \n","\n","Action Space Shape 4\n","Action Space Sample 1\n"]}],"source":["print(\"\\n _____ACTION SPACE_____ \\n\")\n","print(\"Action Space Shape\", env.action_space.n)\n","print(\"Action Space Sample\", env.action_space.sample()) # Take a random action"]},{"cell_type":"markdown","metadata":{"id":"MyxXwkI2Magx"},"source":["The action space (the set of possible actions the agent can take) is discrete with 4 actions available üéÆ: \n","\n","- Do nothing,\n","- Fire left orientation engine,\n","- Fire the main engine,\n","- Fire right orientation engine.\n","\n","Reward function (the function that will gives a reward at each timestep) üí∞:\n","\n","- Moving from the top of the screen to the landing pad and zero speed is about 100~140 points.\n","- Firing main engine is -0.3 each frame\n","- Each leg ground contact is +10 points\n","- Episode finishes if the lander crashes (additional - 100 points) or come to rest (+100 points)"]},{"cell_type":"markdown","metadata":{"id":"dFD9RAFjG8aq"},"source":["#### Vectorized Environment\n","- We create a vectorized environment (method for stacking multiple independent environments into a single environment) of 16 environments, this way, **we'll have more diverse experiences during the training.**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"99hqQ_etEy1N"},"outputs":[],"source":["# Create the environment\n","env = make_vec_env('LunarLander-v2', n_envs=16)"]},{"cell_type":"markdown","metadata":{"id":"VgrE86r5E5IK"},"source":["## Create the Model ü§ñ\n","- Now that we studied our environment and we understood the problem: **being able to land correctly the Lunar Lander to the Landing Pad by controlling left, right and main orientation engine**. Let's build the algorithm we're going to use to solve this Problem üöÄ.\n","\n","- To do so, we're going to use our first Deep RL library, [Stable Baselines3 (SB3)](https://stable-baselines3.readthedocs.io/en/master/).\n","\n","- SB3 is a set of **reliable implementations of reinforcement learning algorithms in PyTorch**.\n","\n","---\n","\n","üí° A good habit when using a new library is to dive first on the documentation: https://stable-baselines3.readthedocs.io/en/master/ and then try some tutorials.\n","\n","----"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4716,"status":"ok","timestamp":1673287672974,"user":{"displayName":"Andrew Johnson (earyzhe)","userId":"17854936619688322601"},"user_tz":-60},"id":"nxI6hT1GE4-A","outputId":"24fe544f-1d56-4d20-ee93-eeb439683067"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using cuda device\n"]}],"source":["# We use MultiLayerPerceptron (MLPPolicy) because the input is a vector,\n","# if we had frames as input we would use CnnPolicy\n","model = PPO(\n","    policy = 'MlpPolicy',\n","    learning_rate=0.0001,\n","    env = env,\n","    n_steps = 1024,\n","    batch_size = 64,\n","    n_epochs = 10,\n","    gamma = 0.999,\n","    gae_lambda = 0.98,\n","    ent_coef = 0.01,\n","    verbose=1)"]},{"cell_type":"markdown","metadata":{"id":"HV4yiUM_9_Ka"},"source":["To solve this problem, we're going to use SB3 **PPO**. [PPO (aka Proximal Policy Optimization) is one of the of the SOTA (state of the art) Deep Reinforcement Learning algorithms that you'll study during this course](https://stable-baselines3.readthedocs.io/en/master/modules/ppo.html#example%5D).\n","\n","PPO is a combination of:\n","- *Value-based reinforcement learning method*: learning an action-value function that will tell us what's the **most valuable action to take given a state and action**.\n","- *Policy-based reinforcement learning method*: learning a policy that will **gives us a probability distribution over actions**.\n"]},{"cell_type":"markdown","metadata":{"id":"5qL_4HeIOrEJ"},"source":["Stable-Baselines3 is easy to set up:\n","\n","1Ô∏è‚É£ You **create your environment** (in our case it was done above)\n","\n","2Ô∏è‚É£ You define the **model you want to use and instantiate this model** `model = PPO(\"MlpPolicy\")`\n","\n","3Ô∏è‚É£ You **train the agent** with `model.learn` and define the number of training timesteps\n","\n","```\n","# Create environment\n","env = gym.make('LunarLander-v2')\n","\n","# Instantiate the agent\n","model = PPO('MlpPolicy', env, verbose=1)\n","# Train the agent\n","model.learn(total_timesteps=int(2e5))\n","```\n","\n"]},{"cell_type":"markdown","metadata":{"id":"QAN7B0_HCVZC"},"source":["#### Solution"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1673189510104,"user":{"displayName":"Andrew Johnson (earyzhe)","userId":"17854936619688322601"},"user_tz":-60},"id":"543OHYDfcjK4","outputId":"13a61f83-7d78-477a-b9aa-7091c2be4f0c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using cuda device\n"]}],"source":["# SOLUTION\n","# We added some parameters to accelerate the training\n","model = PPO(\n","    policy = 'MlpPolicy',\n","    env = env,\n","    n_steps = 1024,\n","    batch_size = 64,\n","    n_epochs = 4,\n","    gamma = 0.999,\n","    gae_lambda = 0.98,\n","    ent_coef = 0.01,\n","    verbose=1)"]},{"cell_type":"markdown","metadata":{"id":"ClJJk88yoBUi"},"source":["## Train the PPO agent üèÉ\n","- Let's train our agent for 1,000,000 timesteps, don't forget to use GPU on Colab. It will take approximately ~20min, but you can use less timesteps if you just want to try it out.\n","- During the training, take a ‚òï break you deserved it ü§ó"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WgrxCrIH4FbC"},"outputs":[],"source":["model_name = \"ppo-LunarLander-v2\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":586584,"status":"ok","timestamp":1673351284390,"user":{"displayName":"Andrew Johnson (earyzhe)","userId":"17854936619688322601"},"user_tz":-60},"id":"qKnYkNiVp89p","outputId":"25b087b2-96b0-4b01-9ce7-3146e3e53ee6"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1;30;43mDie letzten 5000¬†Zeilen der Streamingausgabe wurden abgeschnitten.\u001b[0m\n","|    value_loss           | 53.1         |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 276          |\n","|    ep_rew_mean          | 270          |\n","| time/                   |              |\n","|    fps                  | 692          |\n","|    iterations           | 69           |\n","|    time_elapsed         | 1631         |\n","|    total_timesteps      | 1130496      |\n","| train/                  |              |\n","|    approx_kl            | 0.0034659225 |\n","|    clip_fraction        | 0.0377       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.725       |\n","|    explained_variance   | 0.963        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 3.3          |\n","|    n_updates            | 680          |\n","|    policy_gradient_loss | -0.00178     |\n","|    value_loss           | 81.9         |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 273          |\n","|    ep_rew_mean          | 264          |\n","| time/                   |              |\n","|    fps                  | 694          |\n","|    iterations           | 70           |\n","|    time_elapsed         | 1651         |\n","|    total_timesteps      | 1146880      |\n","| train/                  |              |\n","|    approx_kl            | 0.0041068313 |\n","|    clip_fraction        | 0.0341       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.715       |\n","|    explained_variance   | 0.964        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 10.7         |\n","|    n_updates            | 690          |\n","|    policy_gradient_loss | -0.00178     |\n","|    value_loss           | 86.1         |\n","------------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 254         |\n","|    ep_rew_mean          | 261         |\n","| time/                   |             |\n","|    fps                  | 696         |\n","|    iterations           | 71          |\n","|    time_elapsed         | 1670        |\n","|    total_timesteps      | 1163264     |\n","| train/                  |             |\n","|    approx_kl            | 0.002985883 |\n","|    clip_fraction        | 0.0217      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.722      |\n","|    explained_variance   | 0.901       |\n","|    learning_rate        | 0.0001      |\n","|    loss                 | 14.4        |\n","|    n_updates            | 700         |\n","|    policy_gradient_loss | -0.00048    |\n","|    value_loss           | 271         |\n","-----------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 255          |\n","|    ep_rew_mean          | 271          |\n","| time/                   |              |\n","|    fps                  | 698          |\n","|    iterations           | 72           |\n","|    time_elapsed         | 1689         |\n","|    total_timesteps      | 1179648      |\n","| train/                  |              |\n","|    approx_kl            | 0.0032564532 |\n","|    clip_fraction        | 0.0196       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.679       |\n","|    explained_variance   | 0.889        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 135          |\n","|    n_updates            | 710          |\n","|    policy_gradient_loss | -0.0014      |\n","|    value_loss           | 326          |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 259          |\n","|    ep_rew_mean          | 280          |\n","| time/                   |              |\n","|    fps                  | 700          |\n","|    iterations           | 73           |\n","|    time_elapsed         | 1707         |\n","|    total_timesteps      | 1196032      |\n","| train/                  |              |\n","|    approx_kl            | 0.0033201978 |\n","|    clip_fraction        | 0.0264       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.658       |\n","|    explained_variance   | 0.991        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 4.03         |\n","|    n_updates            | 720          |\n","|    policy_gradient_loss | -0.00164     |\n","|    value_loss           | 13.9         |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 259          |\n","|    ep_rew_mean          | 275          |\n","| time/                   |              |\n","|    fps                  | 702          |\n","|    iterations           | 74           |\n","|    time_elapsed         | 1725         |\n","|    total_timesteps      | 1212416      |\n","| train/                  |              |\n","|    approx_kl            | 0.0025279862 |\n","|    clip_fraction        | 0.0178       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.653       |\n","|    explained_variance   | 0.971        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 7.13         |\n","|    n_updates            | 730          |\n","|    policy_gradient_loss | -0.00192     |\n","|    value_loss           | 84.4         |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 243          |\n","|    ep_rew_mean          | 265          |\n","| time/                   |              |\n","|    fps                  | 704          |\n","|    iterations           | 75           |\n","|    time_elapsed         | 1743         |\n","|    total_timesteps      | 1228800      |\n","| train/                  |              |\n","|    approx_kl            | 0.0032992589 |\n","|    clip_fraction        | 0.0228       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.676       |\n","|    explained_variance   | 0.933        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 338          |\n","|    n_updates            | 740          |\n","|    policy_gradient_loss | -0.00112     |\n","|    value_loss           | 197          |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 260          |\n","|    ep_rew_mean          | 266          |\n","| time/                   |              |\n","|    fps                  | 706          |\n","|    iterations           | 76           |\n","|    time_elapsed         | 1761         |\n","|    total_timesteps      | 1245184      |\n","| train/                  |              |\n","|    approx_kl            | 0.0025601645 |\n","|    clip_fraction        | 0.0229       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.698       |\n","|    explained_variance   | 0.89         |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 375          |\n","|    n_updates            | 750          |\n","|    policy_gradient_loss | -0.002       |\n","|    value_loss           | 325          |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 278          |\n","|    ep_rew_mean          | 267          |\n","| time/                   |              |\n","|    fps                  | 708          |\n","|    iterations           | 77           |\n","|    time_elapsed         | 1781         |\n","|    total_timesteps      | 1261568      |\n","| train/                  |              |\n","|    approx_kl            | 0.0034536505 |\n","|    clip_fraction        | 0.0324       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.655       |\n","|    explained_variance   | 0.932        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 27.6         |\n","|    n_updates            | 760          |\n","|    policy_gradient_loss | -0.00204     |\n","|    value_loss           | 209          |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 293          |\n","|    ep_rew_mean          | 267          |\n","| time/                   |              |\n","|    fps                  | 709          |\n","|    iterations           | 78           |\n","|    time_elapsed         | 1800         |\n","|    total_timesteps      | 1277952      |\n","| train/                  |              |\n","|    approx_kl            | 0.0027198358 |\n","|    clip_fraction        | 0.029        |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.666       |\n","|    explained_variance   | 0.961        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 20.7         |\n","|    n_updates            | 770          |\n","|    policy_gradient_loss | -0.00076     |\n","|    value_loss           | 102          |\n","------------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 279         |\n","|    ep_rew_mean          | 262         |\n","| time/                   |             |\n","|    fps                  | 711         |\n","|    iterations           | 79          |\n","|    time_elapsed         | 1819        |\n","|    total_timesteps      | 1294336     |\n","| train/                  |             |\n","|    approx_kl            | 0.003579842 |\n","|    clip_fraction        | 0.0334      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.681      |\n","|    explained_variance   | 0.95        |\n","|    learning_rate        | 0.0001      |\n","|    loss                 | 3.43        |\n","|    n_updates            | 780         |\n","|    policy_gradient_loss | -0.00167    |\n","|    value_loss           | 136         |\n","-----------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 256          |\n","|    ep_rew_mean          | 270          |\n","| time/                   |              |\n","|    fps                  | 713          |\n","|    iterations           | 80           |\n","|    time_elapsed         | 1837         |\n","|    total_timesteps      | 1310720      |\n","| train/                  |              |\n","|    approx_kl            | 0.0035617016 |\n","|    clip_fraction        | 0.0181       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.678       |\n","|    explained_variance   | 0.924        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 57.6         |\n","|    n_updates            | 790          |\n","|    policy_gradient_loss | -0.00126     |\n","|    value_loss           | 261          |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 253          |\n","|    ep_rew_mean          | 281          |\n","| time/                   |              |\n","|    fps                  | 715          |\n","|    iterations           | 81           |\n","|    time_elapsed         | 1855         |\n","|    total_timesteps      | 1327104      |\n","| train/                  |              |\n","|    approx_kl            | 0.0026191552 |\n","|    clip_fraction        | 0.0244       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.607       |\n","|    explained_variance   | 0.987        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 2.38         |\n","|    n_updates            | 800          |\n","|    policy_gradient_loss | -0.000703    |\n","|    value_loss           | 22.9         |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 252          |\n","|    ep_rew_mean          | 278          |\n","| time/                   |              |\n","|    fps                  | 717          |\n","|    iterations           | 82           |\n","|    time_elapsed         | 1873         |\n","|    total_timesteps      | 1343488      |\n","| train/                  |              |\n","|    approx_kl            | 0.0032083634 |\n","|    clip_fraction        | 0.0334       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.643       |\n","|    explained_variance   | 0.995        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 4.06         |\n","|    n_updates            | 810          |\n","|    policy_gradient_loss | -0.00146     |\n","|    value_loss           | 9.38         |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 266          |\n","|    ep_rew_mean          | 268          |\n","| time/                   |              |\n","|    fps                  | 718          |\n","|    iterations           | 83           |\n","|    time_elapsed         | 1892         |\n","|    total_timesteps      | 1359872      |\n","| train/                  |              |\n","|    approx_kl            | 0.0022151289 |\n","|    clip_fraction        | 0.0202       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.639       |\n","|    explained_variance   | 0.975        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 3.54         |\n","|    n_updates            | 820          |\n","|    policy_gradient_loss | -0.00123     |\n","|    value_loss           | 72.5         |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 264          |\n","|    ep_rew_mean          | 265          |\n","| time/                   |              |\n","|    fps                  | 720          |\n","|    iterations           | 84           |\n","|    time_elapsed         | 1910         |\n","|    total_timesteps      | 1376256      |\n","| train/                  |              |\n","|    approx_kl            | 0.0046857074 |\n","|    clip_fraction        | 0.0352       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.688       |\n","|    explained_variance   | 0.932        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 96.2         |\n","|    n_updates            | 830          |\n","|    policy_gradient_loss | -0.002       |\n","|    value_loss           | 200          |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 256          |\n","|    ep_rew_mean          | 274          |\n","| time/                   |              |\n","|    fps                  | 722          |\n","|    iterations           | 85           |\n","|    time_elapsed         | 1928         |\n","|    total_timesteps      | 1392640      |\n","| train/                  |              |\n","|    approx_kl            | 0.0018677773 |\n","|    clip_fraction        | 0.0129       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.641       |\n","|    explained_variance   | 0.933        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 26.2         |\n","|    n_updates            | 840          |\n","|    policy_gradient_loss | -0.000397    |\n","|    value_loss           | 207          |\n","------------------------------------------\n","----------------------------------------\n","| rollout/                |            |\n","|    ep_len_mean          | 244        |\n","|    ep_rew_mean          | 274        |\n","| time/                   |            |\n","|    fps                  | 723        |\n","|    iterations           | 86         |\n","|    time_elapsed         | 1948       |\n","|    total_timesteps      | 1409024    |\n","| train/                  |            |\n","|    approx_kl            | 0.00485959 |\n","|    clip_fraction        | 0.055      |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -0.651     |\n","|    explained_variance   | 0.972      |\n","|    learning_rate        | 0.0001     |\n","|    loss                 | 260        |\n","|    n_updates            | 850        |\n","|    policy_gradient_loss | -0.00265   |\n","|    value_loss           | 84.6       |\n","----------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 260          |\n","|    ep_rew_mean          | 272          |\n","| time/                   |              |\n","|    fps                  | 724          |\n","|    iterations           | 87           |\n","|    time_elapsed         | 1967         |\n","|    total_timesteps      | 1425408      |\n","| train/                  |              |\n","|    approx_kl            | 0.0027219993 |\n","|    clip_fraction        | 0.0225       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.641       |\n","|    explained_variance   | 0.977        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 35.4         |\n","|    n_updates            | 860          |\n","|    policy_gradient_loss | -0.00147     |\n","|    value_loss           | 50.9         |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 260          |\n","|    ep_rew_mean          | 276          |\n","| time/                   |              |\n","|    fps                  | 726          |\n","|    iterations           | 88           |\n","|    time_elapsed         | 1985         |\n","|    total_timesteps      | 1441792      |\n","| train/                  |              |\n","|    approx_kl            | 0.0029837687 |\n","|    clip_fraction        | 0.0197       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.663       |\n","|    explained_variance   | 0.971        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 3.13         |\n","|    n_updates            | 870          |\n","|    policy_gradient_loss | -0.00038     |\n","|    value_loss           | 86.5         |\n","------------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 250         |\n","|    ep_rew_mean          | 273         |\n","| time/                   |             |\n","|    fps                  | 727         |\n","|    iterations           | 89          |\n","|    time_elapsed         | 2004        |\n","|    total_timesteps      | 1458176     |\n","| train/                  |             |\n","|    approx_kl            | 0.002776542 |\n","|    clip_fraction        | 0.0267      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.656      |\n","|    explained_variance   | 0.977       |\n","|    learning_rate        | 0.0001      |\n","|    loss                 | 6.06        |\n","|    n_updates            | 880         |\n","|    policy_gradient_loss | -0.00112    |\n","|    value_loss           | 74.6        |\n","-----------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 256         |\n","|    ep_rew_mean          | 266         |\n","| time/                   |             |\n","|    fps                  | 729         |\n","|    iterations           | 90          |\n","|    time_elapsed         | 2022        |\n","|    total_timesteps      | 1474560     |\n","| train/                  |             |\n","|    approx_kl            | 0.003194426 |\n","|    clip_fraction        | 0.0184      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.67       |\n","|    explained_variance   | 0.961       |\n","|    learning_rate        | 0.0001      |\n","|    loss                 | 2.34        |\n","|    n_updates            | 890         |\n","|    policy_gradient_loss | -0.000354   |\n","|    value_loss           | 119         |\n","-----------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 264          |\n","|    ep_rew_mean          | 271          |\n","| time/                   |              |\n","|    fps                  | 730          |\n","|    iterations           | 91           |\n","|    time_elapsed         | 2040         |\n","|    total_timesteps      | 1490944      |\n","| train/                  |              |\n","|    approx_kl            | 0.0025771046 |\n","|    clip_fraction        | 0.031        |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.644       |\n","|    explained_variance   | 0.977        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 15           |\n","|    n_updates            | 900          |\n","|    policy_gradient_loss | -0.000739    |\n","|    value_loss           | 76.2         |\n","------------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 259         |\n","|    ep_rew_mean          | 277         |\n","| time/                   |             |\n","|    fps                  | 732         |\n","|    iterations           | 92          |\n","|    time_elapsed         | 2058        |\n","|    total_timesteps      | 1507328     |\n","| train/                  |             |\n","|    approx_kl            | 0.002349741 |\n","|    clip_fraction        | 0.0197      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.627      |\n","|    explained_variance   | 0.996       |\n","|    learning_rate        | 0.0001      |\n","|    loss                 | 1.76        |\n","|    n_updates            | 910         |\n","|    policy_gradient_loss | -0.000807   |\n","|    value_loss           | 7.95        |\n","-----------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 241         |\n","|    ep_rew_mean          | 278         |\n","| time/                   |             |\n","|    fps                  | 733         |\n","|    iterations           | 93          |\n","|    time_elapsed         | 2076        |\n","|    total_timesteps      | 1523712     |\n","| train/                  |             |\n","|    approx_kl            | 0.002720767 |\n","|    clip_fraction        | 0.0178      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.651      |\n","|    explained_variance   | 0.997       |\n","|    learning_rate        | 0.0001      |\n","|    loss                 | 4.94        |\n","|    n_updates            | 920         |\n","|    policy_gradient_loss | -0.000997   |\n","|    value_loss           | 7.18        |\n","-----------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 257          |\n","|    ep_rew_mean          | 278          |\n","| time/                   |              |\n","|    fps                  | 735          |\n","|    iterations           | 94           |\n","|    time_elapsed         | 2094         |\n","|    total_timesteps      | 1540096      |\n","| train/                  |              |\n","|    approx_kl            | 0.0031539267 |\n","|    clip_fraction        | 0.0321       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.617       |\n","|    explained_variance   | 0.977        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 8.67         |\n","|    n_updates            | 930          |\n","|    policy_gradient_loss | -0.00151     |\n","|    value_loss           | 80.8         |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 242          |\n","|    ep_rew_mean          | 274          |\n","| time/                   |              |\n","|    fps                  | 736          |\n","|    iterations           | 95           |\n","|    time_elapsed         | 2112         |\n","|    total_timesteps      | 1556480      |\n","| train/                  |              |\n","|    approx_kl            | 0.0033814951 |\n","|    clip_fraction        | 0.0282       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.652       |\n","|    explained_variance   | 0.976        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 2.34         |\n","|    n_updates            | 940          |\n","|    policy_gradient_loss | -0.00117     |\n","|    value_loss           | 80.8         |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 239          |\n","|    ep_rew_mean          | 275          |\n","| time/                   |              |\n","|    fps                  | 738          |\n","|    iterations           | 96           |\n","|    time_elapsed         | 2130         |\n","|    total_timesteps      | 1572864      |\n","| train/                  |              |\n","|    approx_kl            | 0.0029573832 |\n","|    clip_fraction        | 0.0201       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.615       |\n","|    explained_variance   | 0.945        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 9.01         |\n","|    n_updates            | 950          |\n","|    policy_gradient_loss | -0.00118     |\n","|    value_loss           | 154          |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 251          |\n","|    ep_rew_mean          | 278          |\n","| time/                   |              |\n","|    fps                  | 739          |\n","|    iterations           | 97           |\n","|    time_elapsed         | 2148         |\n","|    total_timesteps      | 1589248      |\n","| train/                  |              |\n","|    approx_kl            | 0.0033536882 |\n","|    clip_fraction        | 0.0294       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.596       |\n","|    explained_variance   | 0.969        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 4.74         |\n","|    n_updates            | 960          |\n","|    policy_gradient_loss | -0.000487    |\n","|    value_loss           | 99.4         |\n","------------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 257         |\n","|    ep_rew_mean          | 262         |\n","| time/                   |             |\n","|    fps                  | 740         |\n","|    iterations           | 98          |\n","|    time_elapsed         | 2166        |\n","|    total_timesteps      | 1605632     |\n","| train/                  |             |\n","|    approx_kl            | 0.001974773 |\n","|    clip_fraction        | 0.016       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.582      |\n","|    explained_variance   | 0.953       |\n","|    learning_rate        | 0.0001      |\n","|    loss                 | 7.43        |\n","|    n_updates            | 970         |\n","|    policy_gradient_loss | -0.000272   |\n","|    value_loss           | 106         |\n","-----------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 259          |\n","|    ep_rew_mean          | 273          |\n","| time/                   |              |\n","|    fps                  | 741          |\n","|    iterations           | 99           |\n","|    time_elapsed         | 2186         |\n","|    total_timesteps      | 1622016      |\n","| train/                  |              |\n","|    approx_kl            | 0.0020925405 |\n","|    clip_fraction        | 0.0176       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.625       |\n","|    explained_variance   | 0.925        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 196          |\n","|    n_updates            | 980          |\n","|    policy_gradient_loss | -0.00102     |\n","|    value_loss           | 266          |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 227          |\n","|    ep_rew_mean          | 265          |\n","| time/                   |              |\n","|    fps                  | 743          |\n","|    iterations           | 100          |\n","|    time_elapsed         | 2204         |\n","|    total_timesteps      | 1638400      |\n","| train/                  |              |\n","|    approx_kl            | 0.0032188888 |\n","|    clip_fraction        | 0.0321       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.599       |\n","|    explained_variance   | 0.996        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 2.83         |\n","|    n_updates            | 990          |\n","|    policy_gradient_loss | -0.00112     |\n","|    value_loss           | 6.45         |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 247          |\n","|    ep_rew_mean          | 264          |\n","| time/                   |              |\n","|    fps                  | 744          |\n","|    iterations           | 101          |\n","|    time_elapsed         | 2222         |\n","|    total_timesteps      | 1654784      |\n","| train/                  |              |\n","|    approx_kl            | 0.0028276932 |\n","|    clip_fraction        | 0.0214       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.609       |\n","|    explained_variance   | 0.882        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 94.2         |\n","|    n_updates            | 1000         |\n","|    policy_gradient_loss | -0.0023      |\n","|    value_loss           | 396          |\n","------------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 264         |\n","|    ep_rew_mean          | 271         |\n","| time/                   |             |\n","|    fps                  | 745         |\n","|    iterations           | 102         |\n","|    time_elapsed         | 2241        |\n","|    total_timesteps      | 1671168     |\n","| train/                  |             |\n","|    approx_kl            | 0.002992451 |\n","|    clip_fraction        | 0.0299      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.598      |\n","|    explained_variance   | 0.969       |\n","|    learning_rate        | 0.0001      |\n","|    loss                 | 22.4        |\n","|    n_updates            | 1010        |\n","|    policy_gradient_loss | -0.000352   |\n","|    value_loss           | 87.3        |\n","-----------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 288         |\n","|    ep_rew_mean          | 271         |\n","| time/                   |             |\n","|    fps                  | 746         |\n","|    iterations           | 103         |\n","|    time_elapsed         | 2260        |\n","|    total_timesteps      | 1687552     |\n","| train/                  |             |\n","|    approx_kl            | 0.002785636 |\n","|    clip_fraction        | 0.0239      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.605      |\n","|    explained_variance   | 0.975       |\n","|    learning_rate        | 0.0001      |\n","|    loss                 | 4.54        |\n","|    n_updates            | 1020        |\n","|    policy_gradient_loss | -0.00143    |\n","|    value_loss           | 82.2        |\n","-----------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 253         |\n","|    ep_rew_mean          | 275         |\n","| time/                   |             |\n","|    fps                  | 747         |\n","|    iterations           | 104         |\n","|    time_elapsed         | 2278        |\n","|    total_timesteps      | 1703936     |\n","| train/                  |             |\n","|    approx_kl            | 0.003163786 |\n","|    clip_fraction        | 0.0221      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.615      |\n","|    explained_variance   | 0.994       |\n","|    learning_rate        | 0.0001      |\n","|    loss                 | 7.56        |\n","|    n_updates            | 1030        |\n","|    policy_gradient_loss | -0.00103    |\n","|    value_loss           | 12.2        |\n","-----------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 236          |\n","|    ep_rew_mean          | 272          |\n","| time/                   |              |\n","|    fps                  | 749          |\n","|    iterations           | 105          |\n","|    time_elapsed         | 2295         |\n","|    total_timesteps      | 1720320      |\n","| train/                  |              |\n","|    approx_kl            | 0.0022485661 |\n","|    clip_fraction        | 0.0125       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.586       |\n","|    explained_variance   | 0.98         |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 7.52         |\n","|    n_updates            | 1040         |\n","|    policy_gradient_loss | -0.00021     |\n","|    value_loss           | 66.9         |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 245          |\n","|    ep_rew_mean          | 267          |\n","| time/                   |              |\n","|    fps                  | 750          |\n","|    iterations           | 106          |\n","|    time_elapsed         | 2313         |\n","|    total_timesteps      | 1736704      |\n","| train/                  |              |\n","|    approx_kl            | 0.0033975886 |\n","|    clip_fraction        | 0.018        |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.592       |\n","|    explained_variance   | 0.953        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 5.25         |\n","|    n_updates            | 1050         |\n","|    policy_gradient_loss | -0.000646    |\n","|    value_loss           | 163          |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 236          |\n","|    ep_rew_mean          | 273          |\n","| time/                   |              |\n","|    fps                  | 752          |\n","|    iterations           | 107          |\n","|    time_elapsed         | 2331         |\n","|    total_timesteps      | 1753088      |\n","| train/                  |              |\n","|    approx_kl            | 0.0023241774 |\n","|    clip_fraction        | 0.0256       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.593       |\n","|    explained_variance   | 0.949        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 120          |\n","|    n_updates            | 1060         |\n","|    policy_gradient_loss | -0.000214    |\n","|    value_loss           | 161          |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 224          |\n","|    ep_rew_mean          | 278          |\n","| time/                   |              |\n","|    fps                  | 753          |\n","|    iterations           | 108          |\n","|    time_elapsed         | 2348         |\n","|    total_timesteps      | 1769472      |\n","| train/                  |              |\n","|    approx_kl            | 0.0028500252 |\n","|    clip_fraction        | 0.0243       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.587       |\n","|    explained_variance   | 0.937        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 15           |\n","|    n_updates            | 1070         |\n","|    policy_gradient_loss | -0.000806    |\n","|    value_loss           | 200          |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 236          |\n","|    ep_rew_mean          | 270          |\n","| time/                   |              |\n","|    fps                  | 754          |\n","|    iterations           | 109          |\n","|    time_elapsed         | 2367         |\n","|    total_timesteps      | 1785856      |\n","| train/                  |              |\n","|    approx_kl            | 0.0025790844 |\n","|    clip_fraction        | 0.0264       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.602       |\n","|    explained_variance   | 0.98         |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 4.03         |\n","|    n_updates            | 1080         |\n","|    policy_gradient_loss | -0.000113    |\n","|    value_loss           | 56           |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 247          |\n","|    ep_rew_mean          | 271          |\n","| time/                   |              |\n","|    fps                  | 755          |\n","|    iterations           | 110          |\n","|    time_elapsed         | 2384         |\n","|    total_timesteps      | 1802240      |\n","| train/                  |              |\n","|    approx_kl            | 0.0018710998 |\n","|    clip_fraction        | 0.0146       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.606       |\n","|    explained_variance   | 0.966        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 9.96         |\n","|    n_updates            | 1090         |\n","|    policy_gradient_loss | 8.8e-05      |\n","|    value_loss           | 143          |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 234          |\n","|    ep_rew_mean          | 276          |\n","| time/                   |              |\n","|    fps                  | 756          |\n","|    iterations           | 111          |\n","|    time_elapsed         | 2403         |\n","|    total_timesteps      | 1818624      |\n","| train/                  |              |\n","|    approx_kl            | 0.0033478872 |\n","|    clip_fraction        | 0.0349       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.611       |\n","|    explained_variance   | 0.994        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 4.17         |\n","|    n_updates            | 1100         |\n","|    policy_gradient_loss | -0.00109     |\n","|    value_loss           | 10.1         |\n","------------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 223         |\n","|    ep_rew_mean          | 270         |\n","| time/                   |             |\n","|    fps                  | 757         |\n","|    iterations           | 112         |\n","|    time_elapsed         | 2421        |\n","|    total_timesteps      | 1835008     |\n","| train/                  |             |\n","|    approx_kl            | 0.002123284 |\n","|    clip_fraction        | 0.016       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.597      |\n","|    explained_variance   | 0.97        |\n","|    learning_rate        | 0.0001      |\n","|    loss                 | 15.9        |\n","|    n_updates            | 1110        |\n","|    policy_gradient_loss | -0.00124    |\n","|    value_loss           | 87.1        |\n","-----------------------------------------\n","----------------------------------------\n","| rollout/                |            |\n","|    ep_len_mean          | 233        |\n","|    ep_rew_mean          | 271        |\n","| time/                   |            |\n","|    fps                  | 758        |\n","|    iterations           | 113        |\n","|    time_elapsed         | 2439       |\n","|    total_timesteps      | 1851392    |\n","| train/                  |            |\n","|    approx_kl            | 0.00253351 |\n","|    clip_fraction        | 0.0231     |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -0.589     |\n","|    explained_variance   | 0.951      |\n","|    learning_rate        | 0.0001     |\n","|    loss                 | 4.02       |\n","|    n_updates            | 1120       |\n","|    policy_gradient_loss | -0.0012    |\n","|    value_loss           | 146        |\n","----------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 251          |\n","|    ep_rew_mean          | 270          |\n","| time/                   |              |\n","|    fps                  | 759          |\n","|    iterations           | 114          |\n","|    time_elapsed         | 2457         |\n","|    total_timesteps      | 1867776      |\n","| train/                  |              |\n","|    approx_kl            | 0.0025955646 |\n","|    clip_fraction        | 0.0207       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.609       |\n","|    explained_variance   | 0.964        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 8.21         |\n","|    n_updates            | 1130         |\n","|    policy_gradient_loss | -0.000653    |\n","|    value_loss           | 129          |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 234          |\n","|    ep_rew_mean          | 274          |\n","| time/                   |              |\n","|    fps                  | 761          |\n","|    iterations           | 115          |\n","|    time_elapsed         | 2475         |\n","|    total_timesteps      | 1884160      |\n","| train/                  |              |\n","|    approx_kl            | 0.0028540357 |\n","|    clip_fraction        | 0.0233       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.564       |\n","|    explained_variance   | 0.968        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 3.56         |\n","|    n_updates            | 1140         |\n","|    policy_gradient_loss | -0.000792    |\n","|    value_loss           | 100          |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 225          |\n","|    ep_rew_mean          | 272          |\n","| time/                   |              |\n","|    fps                  | 762          |\n","|    iterations           | 116          |\n","|    time_elapsed         | 2492         |\n","|    total_timesteps      | 1900544      |\n","| train/                  |              |\n","|    approx_kl            | 0.0034000566 |\n","|    clip_fraction        | 0.0287       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.596       |\n","|    explained_variance   | 0.956        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 73           |\n","|    n_updates            | 1150         |\n","|    policy_gradient_loss | -0.000243    |\n","|    value_loss           | 149          |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 230          |\n","|    ep_rew_mean          | 281          |\n","| time/                   |              |\n","|    fps                  | 763          |\n","|    iterations           | 117          |\n","|    time_elapsed         | 2510         |\n","|    total_timesteps      | 1916928      |\n","| train/                  |              |\n","|    approx_kl            | 0.0029347844 |\n","|    clip_fraction        | 0.0288       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.587       |\n","|    explained_variance   | 0.958        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 13.4         |\n","|    n_updates            | 1160         |\n","|    policy_gradient_loss | 1.35e-05     |\n","|    value_loss           | 145          |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 233          |\n","|    ep_rew_mean          | 278          |\n","| time/                   |              |\n","|    fps                  | 764          |\n","|    iterations           | 118          |\n","|    time_elapsed         | 2527         |\n","|    total_timesteps      | 1933312      |\n","| train/                  |              |\n","|    approx_kl            | 0.0033461186 |\n","|    clip_fraction        | 0.0244       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.595       |\n","|    explained_variance   | 0.979        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 17.7         |\n","|    n_updates            | 1170         |\n","|    policy_gradient_loss | -0.000639    |\n","|    value_loss           | 59.1         |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 242          |\n","|    ep_rew_mean          | 279          |\n","| time/                   |              |\n","|    fps                  | 765          |\n","|    iterations           | 119          |\n","|    time_elapsed         | 2545         |\n","|    total_timesteps      | 1949696      |\n","| train/                  |              |\n","|    approx_kl            | 0.0030070213 |\n","|    clip_fraction        | 0.0235       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.603       |\n","|    explained_variance   | 0.974        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 45.3         |\n","|    n_updates            | 1180         |\n","|    policy_gradient_loss | -0.000497    |\n","|    value_loss           | 86.8         |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 228          |\n","|    ep_rew_mean          | 270          |\n","| time/                   |              |\n","|    fps                  | 767          |\n","|    iterations           | 120          |\n","|    time_elapsed         | 2562         |\n","|    total_timesteps      | 1966080      |\n","| train/                  |              |\n","|    approx_kl            | 0.0033194376 |\n","|    clip_fraction        | 0.0334       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.585       |\n","|    explained_variance   | 0.996        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 1.62         |\n","|    n_updates            | 1190         |\n","|    policy_gradient_loss | -0.000674    |\n","|    value_loss           | 7.15         |\n","------------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 217         |\n","|    ep_rew_mean          | 276         |\n","| time/                   |             |\n","|    fps                  | 768         |\n","|    iterations           | 121         |\n","|    time_elapsed         | 2580        |\n","|    total_timesteps      | 1982464     |\n","| train/                  |             |\n","|    approx_kl            | 0.002458767 |\n","|    clip_fraction        | 0.0182      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.599      |\n","|    explained_variance   | 0.95        |\n","|    learning_rate        | 0.0001      |\n","|    loss                 | 18.9        |\n","|    n_updates            | 1200        |\n","|    policy_gradient_loss | -0.000494   |\n","|    value_loss           | 166         |\n","-----------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 222          |\n","|    ep_rew_mean          | 272          |\n","| time/                   |              |\n","|    fps                  | 769          |\n","|    iterations           | 122          |\n","|    time_elapsed         | 2598         |\n","|    total_timesteps      | 1998848      |\n","| train/                  |              |\n","|    approx_kl            | 0.0025080584 |\n","|    clip_fraction        | 0.0222       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.593       |\n","|    explained_variance   | 0.965        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 13.2         |\n","|    n_updates            | 1210         |\n","|    policy_gradient_loss | -0.000498    |\n","|    value_loss           | 124          |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 218          |\n","|    ep_rew_mean          | 273          |\n","| time/                   |              |\n","|    fps                  | 770          |\n","|    iterations           | 123          |\n","|    time_elapsed         | 2615         |\n","|    total_timesteps      | 2015232      |\n","| train/                  |              |\n","|    approx_kl            | 0.0033675977 |\n","|    clip_fraction        | 0.0294       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.591       |\n","|    explained_variance   | 0.966        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 76.7         |\n","|    n_updates            | 1220         |\n","|    policy_gradient_loss | -0.00211     |\n","|    value_loss           | 144          |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 221          |\n","|    ep_rew_mean          | 280          |\n","| time/                   |              |\n","|    fps                  | 771          |\n","|    iterations           | 124          |\n","|    time_elapsed         | 2634         |\n","|    total_timesteps      | 2031616      |\n","| train/                  |              |\n","|    approx_kl            | 0.0028289915 |\n","|    clip_fraction        | 0.0228       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.565       |\n","|    explained_variance   | 0.937        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 324          |\n","|    n_updates            | 1230         |\n","|    policy_gradient_loss | -0.000951    |\n","|    value_loss           | 241          |\n","------------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 227         |\n","|    ep_rew_mean          | 286         |\n","| time/                   |             |\n","|    fps                  | 772         |\n","|    iterations           | 125         |\n","|    time_elapsed         | 2652        |\n","|    total_timesteps      | 2048000     |\n","| train/                  |             |\n","|    approx_kl            | 0.003788427 |\n","|    clip_fraction        | 0.0275      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.568      |\n","|    explained_variance   | 0.993       |\n","|    learning_rate        | 0.0001      |\n","|    loss                 | 2.66        |\n","|    n_updates            | 1240        |\n","|    policy_gradient_loss | -0.00055    |\n","|    value_loss           | 12.5        |\n","-----------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 213          |\n","|    ep_rew_mean          | 282          |\n","| time/                   |              |\n","|    fps                  | 773          |\n","|    iterations           | 126          |\n","|    time_elapsed         | 2668         |\n","|    total_timesteps      | 2064384      |\n","| train/                  |              |\n","|    approx_kl            | 0.0022376159 |\n","|    clip_fraction        | 0.0201       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.562       |\n","|    explained_variance   | 0.997        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 1.77         |\n","|    n_updates            | 1250         |\n","|    policy_gradient_loss | -0.000399    |\n","|    value_loss           | 7.01         |\n","------------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 223         |\n","|    ep_rew_mean          | 281         |\n","| time/                   |             |\n","|    fps                  | 774         |\n","|    iterations           | 127         |\n","|    time_elapsed         | 2686        |\n","|    total_timesteps      | 2080768     |\n","| train/                  |             |\n","|    approx_kl            | 0.002474217 |\n","|    clip_fraction        | 0.0236      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.564      |\n","|    explained_variance   | 0.981       |\n","|    learning_rate        | 0.0001      |\n","|    loss                 | 122         |\n","|    n_updates            | 1260        |\n","|    policy_gradient_loss | -0.000816   |\n","|    value_loss           | 55.2        |\n","-----------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 235         |\n","|    ep_rew_mean          | 282         |\n","| time/                   |             |\n","|    fps                  | 775         |\n","|    iterations           | 128         |\n","|    time_elapsed         | 2703        |\n","|    total_timesteps      | 2097152     |\n","| train/                  |             |\n","|    approx_kl            | 0.002616378 |\n","|    clip_fraction        | 0.0161      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.562      |\n","|    explained_variance   | 0.991       |\n","|    learning_rate        | 0.0001      |\n","|    loss                 | 23.2        |\n","|    n_updates            | 1270        |\n","|    policy_gradient_loss | -0.000405   |\n","|    value_loss           | 25.8        |\n","-----------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 221          |\n","|    ep_rew_mean          | 276          |\n","| time/                   |              |\n","|    fps                  | 776          |\n","|    iterations           | 129          |\n","|    time_elapsed         | 2721         |\n","|    total_timesteps      | 2113536      |\n","| train/                  |              |\n","|    approx_kl            | 0.0022041001 |\n","|    clip_fraction        | 0.0226       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.565       |\n","|    explained_variance   | 0.99         |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 7.09         |\n","|    n_updates            | 1280         |\n","|    policy_gradient_loss | -0.000364    |\n","|    value_loss           | 29.4         |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 230          |\n","|    ep_rew_mean          | 279          |\n","| time/                   |              |\n","|    fps                  | 777          |\n","|    iterations           | 130          |\n","|    time_elapsed         | 2739         |\n","|    total_timesteps      | 2129920      |\n","| train/                  |              |\n","|    approx_kl            | 0.0025762687 |\n","|    clip_fraction        | 0.0248       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.566       |\n","|    explained_variance   | 0.983        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 10.7         |\n","|    n_updates            | 1290         |\n","|    policy_gradient_loss | -0.000414    |\n","|    value_loss           | 57.8         |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 242          |\n","|    ep_rew_mean          | 275          |\n","| time/                   |              |\n","|    fps                  | 778          |\n","|    iterations           | 131          |\n","|    time_elapsed         | 2756         |\n","|    total_timesteps      | 2146304      |\n","| train/                  |              |\n","|    approx_kl            | 0.0026909322 |\n","|    clip_fraction        | 0.0264       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.59        |\n","|    explained_variance   | 0.996        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 9.8          |\n","|    n_updates            | 1300         |\n","|    policy_gradient_loss | -0.00117     |\n","|    value_loss           | 10.7         |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 230          |\n","|    ep_rew_mean          | 282          |\n","| time/                   |              |\n","|    fps                  | 779          |\n","|    iterations           | 132          |\n","|    time_elapsed         | 2774         |\n","|    total_timesteps      | 2162688      |\n","| train/                  |              |\n","|    approx_kl            | 0.0029211463 |\n","|    clip_fraction        | 0.0206       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.554       |\n","|    explained_variance   | 0.973        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 48.3         |\n","|    n_updates            | 1310         |\n","|    policy_gradient_loss | -0.000659    |\n","|    value_loss           | 61.1         |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 218          |\n","|    ep_rew_mean          | 278          |\n","| time/                   |              |\n","|    fps                  | 780          |\n","|    iterations           | 133          |\n","|    time_elapsed         | 2791         |\n","|    total_timesteps      | 2179072      |\n","| train/                  |              |\n","|    approx_kl            | 0.0019528796 |\n","|    clip_fraction        | 0.0216       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.575       |\n","|    explained_variance   | 0.996        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 3.14         |\n","|    n_updates            | 1320         |\n","|    policy_gradient_loss | -0.000423    |\n","|    value_loss           | 8.39         |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 213          |\n","|    ep_rew_mean          | 279          |\n","| time/                   |              |\n","|    fps                  | 781          |\n","|    iterations           | 134          |\n","|    time_elapsed         | 2808         |\n","|    total_timesteps      | 2195456      |\n","| train/                  |              |\n","|    approx_kl            | 0.0030936676 |\n","|    clip_fraction        | 0.0232       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.565       |\n","|    explained_variance   | 0.984        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 2.82         |\n","|    n_updates            | 1330         |\n","|    policy_gradient_loss | -0.000481    |\n","|    value_loss           | 48.1         |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 230          |\n","|    ep_rew_mean          | 280          |\n","| time/                   |              |\n","|    fps                  | 782          |\n","|    iterations           | 135          |\n","|    time_elapsed         | 2826         |\n","|    total_timesteps      | 2211840      |\n","| train/                  |              |\n","|    approx_kl            | 0.0025541042 |\n","|    clip_fraction        | 0.0226       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.564       |\n","|    explained_variance   | 0.977        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 5.01         |\n","|    n_updates            | 1340         |\n","|    policy_gradient_loss | -0.000778    |\n","|    value_loss           | 77.2         |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 236          |\n","|    ep_rew_mean          | 273          |\n","| time/                   |              |\n","|    fps                  | 783          |\n","|    iterations           | 136          |\n","|    time_elapsed         | 2843         |\n","|    total_timesteps      | 2228224      |\n","| train/                  |              |\n","|    approx_kl            | 0.0033883648 |\n","|    clip_fraction        | 0.0368       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.561       |\n","|    explained_variance   | 0.977        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 5.95         |\n","|    n_updates            | 1350         |\n","|    policy_gradient_loss | -0.000906    |\n","|    value_loss           | 83.2         |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 230          |\n","|    ep_rew_mean          | 278          |\n","| time/                   |              |\n","|    fps                  | 784          |\n","|    iterations           | 137          |\n","|    time_elapsed         | 2861         |\n","|    total_timesteps      | 2244608      |\n","| train/                  |              |\n","|    approx_kl            | 0.0033490187 |\n","|    clip_fraction        | 0.0211       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.565       |\n","|    explained_variance   | 0.95         |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 12.1         |\n","|    n_updates            | 1360         |\n","|    policy_gradient_loss | -0.00075     |\n","|    value_loss           | 156          |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 224          |\n","|    ep_rew_mean          | 278          |\n","| time/                   |              |\n","|    fps                  | 784          |\n","|    iterations           | 138          |\n","|    time_elapsed         | 2880         |\n","|    total_timesteps      | 2260992      |\n","| train/                  |              |\n","|    approx_kl            | 0.0028105222 |\n","|    clip_fraction        | 0.0214       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.551       |\n","|    explained_variance   | 0.949        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 17.2         |\n","|    n_updates            | 1370         |\n","|    policy_gradient_loss | -0.000408    |\n","|    value_loss           | 175          |\n","------------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 211         |\n","|    ep_rew_mean          | 275         |\n","| time/                   |             |\n","|    fps                  | 785         |\n","|    iterations           | 139         |\n","|    time_elapsed         | 2897        |\n","|    total_timesteps      | 2277376     |\n","| train/                  |             |\n","|    approx_kl            | 0.002379443 |\n","|    clip_fraction        | 0.0254      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.539      |\n","|    explained_variance   | 0.957       |\n","|    learning_rate        | 0.0001      |\n","|    loss                 | 35.5        |\n","|    n_updates            | 1380        |\n","|    policy_gradient_loss | -0.00075    |\n","|    value_loss           | 151         |\n","-----------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 218          |\n","|    ep_rew_mean          | 284          |\n","| time/                   |              |\n","|    fps                  | 787          |\n","|    iterations           | 140          |\n","|    time_elapsed         | 2914         |\n","|    total_timesteps      | 2293760      |\n","| train/                  |              |\n","|    approx_kl            | 0.0024892946 |\n","|    clip_fraction        | 0.0283       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.579       |\n","|    explained_variance   | 0.981        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 4.01         |\n","|    n_updates            | 1390         |\n","|    policy_gradient_loss | 0.000252     |\n","|    value_loss           | 56.3         |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 215          |\n","|    ep_rew_mean          | 284          |\n","| time/                   |              |\n","|    fps                  | 788          |\n","|    iterations           | 141          |\n","|    time_elapsed         | 2931         |\n","|    total_timesteps      | 2310144      |\n","| train/                  |              |\n","|    approx_kl            | 0.0022564474 |\n","|    clip_fraction        | 0.0206       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.546       |\n","|    explained_variance   | 0.996        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 2.58         |\n","|    n_updates            | 1400         |\n","|    policy_gradient_loss | -0.00131     |\n","|    value_loss           | 7.21         |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 227          |\n","|    ep_rew_mean          | 276          |\n","| time/                   |              |\n","|    fps                  | 788          |\n","|    iterations           | 142          |\n","|    time_elapsed         | 2949         |\n","|    total_timesteps      | 2326528      |\n","| train/                  |              |\n","|    approx_kl            | 0.0022224193 |\n","|    clip_fraction        | 0.025        |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.564       |\n","|    explained_variance   | 0.961        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 162          |\n","|    n_updates            | 1410         |\n","|    policy_gradient_loss | 7.4e-05      |\n","|    value_loss           | 156          |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 232          |\n","|    ep_rew_mean          | 278          |\n","| time/                   |              |\n","|    fps                  | 789          |\n","|    iterations           | 143          |\n","|    time_elapsed         | 2966         |\n","|    total_timesteps      | 2342912      |\n","| train/                  |              |\n","|    approx_kl            | 0.0024505388 |\n","|    clip_fraction        | 0.0249       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.573       |\n","|    explained_variance   | 0.961        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 4.14         |\n","|    n_updates            | 1420         |\n","|    policy_gradient_loss | -0.000425    |\n","|    value_loss           | 139          |\n","------------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 227         |\n","|    ep_rew_mean          | 274         |\n","| time/                   |             |\n","|    fps                  | 790         |\n","|    iterations           | 144         |\n","|    time_elapsed         | 2983        |\n","|    total_timesteps      | 2359296     |\n","| train/                  |             |\n","|    approx_kl            | 0.002262275 |\n","|    clip_fraction        | 0.0232      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.553      |\n","|    explained_variance   | 0.948       |\n","|    learning_rate        | 0.0001      |\n","|    loss                 | 5.29        |\n","|    n_updates            | 1430        |\n","|    policy_gradient_loss | -0.000548   |\n","|    value_loss           | 175         |\n","-----------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 222          |\n","|    ep_rew_mean          | 276          |\n","| time/                   |              |\n","|    fps                  | 791          |\n","|    iterations           | 145          |\n","|    time_elapsed         | 3001         |\n","|    total_timesteps      | 2375680      |\n","| train/                  |              |\n","|    approx_kl            | 0.0035052705 |\n","|    clip_fraction        | 0.0262       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.554       |\n","|    explained_variance   | 0.971        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 120          |\n","|    n_updates            | 1440         |\n","|    policy_gradient_loss | -0.000271    |\n","|    value_loss           | 63.8         |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 230          |\n","|    ep_rew_mean          | 272          |\n","| time/                   |              |\n","|    fps                  | 792          |\n","|    iterations           | 146          |\n","|    time_elapsed         | 3018         |\n","|    total_timesteps      | 2392064      |\n","| train/                  |              |\n","|    approx_kl            | 0.0027255001 |\n","|    clip_fraction        | 0.0204       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.561       |\n","|    explained_variance   | 0.94         |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 52.9         |\n","|    n_updates            | 1450         |\n","|    policy_gradient_loss | -0.00104     |\n","|    value_loss           | 234          |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 237          |\n","|    ep_rew_mean          | 279          |\n","| time/                   |              |\n","|    fps                  | 793          |\n","|    iterations           | 147          |\n","|    time_elapsed         | 3036         |\n","|    total_timesteps      | 2408448      |\n","| train/                  |              |\n","|    approx_kl            | 0.0022009902 |\n","|    clip_fraction        | 0.0237       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.567       |\n","|    explained_variance   | 0.973        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 7.02         |\n","|    n_updates            | 1460         |\n","|    policy_gradient_loss | -0.000441    |\n","|    value_loss           | 111          |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 209          |\n","|    ep_rew_mean          | 282          |\n","| time/                   |              |\n","|    fps                  | 794          |\n","|    iterations           | 148          |\n","|    time_elapsed         | 3053         |\n","|    total_timesteps      | 2424832      |\n","| train/                  |              |\n","|    approx_kl            | 0.0027916878 |\n","|    clip_fraction        | 0.0321       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.548       |\n","|    explained_variance   | 0.997        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 5.54         |\n","|    n_updates            | 1470         |\n","|    policy_gradient_loss | -0.000973    |\n","|    value_loss           | 7.25         |\n","------------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 226         |\n","|    ep_rew_mean          | 275         |\n","| time/                   |             |\n","|    fps                  | 795         |\n","|    iterations           | 149         |\n","|    time_elapsed         | 3070        |\n","|    total_timesteps      | 2441216     |\n","| train/                  |             |\n","|    approx_kl            | 0.001982009 |\n","|    clip_fraction        | 0.0198      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.558      |\n","|    explained_variance   | 0.997       |\n","|    learning_rate        | 0.0001      |\n","|    loss                 | 3.75        |\n","|    n_updates            | 1480        |\n","|    policy_gradient_loss | -0.000302   |\n","|    value_loss           | 7           |\n","-----------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 218          |\n","|    ep_rew_mean          | 269          |\n","| time/                   |              |\n","|    fps                  | 796          |\n","|    iterations           | 150          |\n","|    time_elapsed         | 3087         |\n","|    total_timesteps      | 2457600      |\n","| train/                  |              |\n","|    approx_kl            | 0.0027090954 |\n","|    clip_fraction        | 0.0131       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.56        |\n","|    explained_variance   | 0.966        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 11.1         |\n","|    n_updates            | 1490         |\n","|    policy_gradient_loss | -0.000187    |\n","|    value_loss           | 141          |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 222          |\n","|    ep_rew_mean          | 281          |\n","| time/                   |              |\n","|    fps                  | 796          |\n","|    iterations           | 151          |\n","|    time_elapsed         | 3104         |\n","|    total_timesteps      | 2473984      |\n","| train/                  |              |\n","|    approx_kl            | 0.0020446412 |\n","|    clip_fraction        | 0.0221       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.567       |\n","|    explained_variance   | 0.95         |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 316          |\n","|    n_updates            | 1500         |\n","|    policy_gradient_loss | -0.000505    |\n","|    value_loss           | 118          |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 221          |\n","|    ep_rew_mean          | 284          |\n","| time/                   |              |\n","|    fps                  | 797          |\n","|    iterations           | 152          |\n","|    time_elapsed         | 3122         |\n","|    total_timesteps      | 2490368      |\n","| train/                  |              |\n","|    approx_kl            | 0.0066142427 |\n","|    clip_fraction        | 0.0336       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.552       |\n","|    explained_variance   | 0.994        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 5.53         |\n","|    n_updates            | 1510         |\n","|    policy_gradient_loss | -0.00101     |\n","|    value_loss           | 10.4         |\n","------------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 232         |\n","|    ep_rew_mean          | 281         |\n","| time/                   |             |\n","|    fps                  | 798         |\n","|    iterations           | 153         |\n","|    time_elapsed         | 3140        |\n","|    total_timesteps      | 2506752     |\n","| train/                  |             |\n","|    approx_kl            | 0.002040787 |\n","|    clip_fraction        | 0.0219      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.56       |\n","|    explained_variance   | 0.991       |\n","|    learning_rate        | 0.0001      |\n","|    loss                 | 17.1        |\n","|    n_updates            | 1520        |\n","|    policy_gradient_loss | -0.00126    |\n","|    value_loss           | 26.3        |\n","-----------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 213          |\n","|    ep_rew_mean          | 283          |\n","| time/                   |              |\n","|    fps                  | 799          |\n","|    iterations           | 154          |\n","|    time_elapsed         | 3157         |\n","|    total_timesteps      | 2523136      |\n","| train/                  |              |\n","|    approx_kl            | 0.0037964801 |\n","|    clip_fraction        | 0.0373       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.581       |\n","|    explained_variance   | 0.995        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 3.67         |\n","|    n_updates            | 1530         |\n","|    policy_gradient_loss | -0.00117     |\n","|    value_loss           | 14.2         |\n","------------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 219         |\n","|    ep_rew_mean          | 280         |\n","| time/                   |             |\n","|    fps                  | 800         |\n","|    iterations           | 155         |\n","|    time_elapsed         | 3174        |\n","|    total_timesteps      | 2539520     |\n","| train/                  |             |\n","|    approx_kl            | 0.002679301 |\n","|    clip_fraction        | 0.0221      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.56       |\n","|    explained_variance   | 0.98        |\n","|    learning_rate        | 0.0001      |\n","|    loss                 | 323         |\n","|    n_updates            | 1540        |\n","|    policy_gradient_loss | -0.000269   |\n","|    value_loss           | 73.4        |\n","-----------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 211          |\n","|    ep_rew_mean          | 286          |\n","| time/                   |              |\n","|    fps                  | 800          |\n","|    iterations           | 156          |\n","|    time_elapsed         | 3193         |\n","|    total_timesteps      | 2555904      |\n","| train/                  |              |\n","|    approx_kl            | 0.0031707599 |\n","|    clip_fraction        | 0.0237       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.553       |\n","|    explained_variance   | 0.979        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 3.31         |\n","|    n_updates            | 1550         |\n","|    policy_gradient_loss | -0.000463    |\n","|    value_loss           | 82.3         |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 214          |\n","|    ep_rew_mean          | 283          |\n","| time/                   |              |\n","|    fps                  | 801          |\n","|    iterations           | 157          |\n","|    time_elapsed         | 3210         |\n","|    total_timesteps      | 2572288      |\n","| train/                  |              |\n","|    approx_kl            | 0.0023087868 |\n","|    clip_fraction        | 0.0259       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.56        |\n","|    explained_variance   | 0.999        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 2.03         |\n","|    n_updates            | 1560         |\n","|    policy_gradient_loss | -0.00115     |\n","|    value_loss           | 2.97         |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 219          |\n","|    ep_rew_mean          | 281          |\n","| time/                   |              |\n","|    fps                  | 802          |\n","|    iterations           | 158          |\n","|    time_elapsed         | 3227         |\n","|    total_timesteps      | 2588672      |\n","| train/                  |              |\n","|    approx_kl            | 0.0029642084 |\n","|    clip_fraction        | 0.0288       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.544       |\n","|    explained_variance   | 0.998        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 1.44         |\n","|    n_updates            | 1570         |\n","|    policy_gradient_loss | -0.00145     |\n","|    value_loss           | 5.95         |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 217          |\n","|    ep_rew_mean          | 280          |\n","| time/                   |              |\n","|    fps                  | 802          |\n","|    iterations           | 159          |\n","|    time_elapsed         | 3244         |\n","|    total_timesteps      | 2605056      |\n","| train/                  |              |\n","|    approx_kl            | 0.0020936448 |\n","|    clip_fraction        | 0.0151       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.554       |\n","|    explained_variance   | 0.96         |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 2.54         |\n","|    n_updates            | 1580         |\n","|    policy_gradient_loss | -0.000483    |\n","|    value_loss           | 146          |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 210          |\n","|    ep_rew_mean          | 277          |\n","| time/                   |              |\n","|    fps                  | 803          |\n","|    iterations           | 160          |\n","|    time_elapsed         | 3260         |\n","|    total_timesteps      | 2621440      |\n","| train/                  |              |\n","|    approx_kl            | 0.0018222342 |\n","|    clip_fraction        | 0.0244       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.527       |\n","|    explained_variance   | 0.978        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 145          |\n","|    n_updates            | 1590         |\n","|    policy_gradient_loss | -0.000442    |\n","|    value_loss           | 76.9         |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 213          |\n","|    ep_rew_mean          | 279          |\n","| time/                   |              |\n","|    fps                  | 804          |\n","|    iterations           | 161          |\n","|    time_elapsed         | 3277         |\n","|    total_timesteps      | 2637824      |\n","| train/                  |              |\n","|    approx_kl            | 0.0022327949 |\n","|    clip_fraction        | 0.0241       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.545       |\n","|    explained_variance   | 0.953        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 19.3         |\n","|    n_updates            | 1600         |\n","|    policy_gradient_loss | -0.000582    |\n","|    value_loss           | 122          |\n","------------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 214         |\n","|    ep_rew_mean          | 280         |\n","| time/                   |             |\n","|    fps                  | 805         |\n","|    iterations           | 162         |\n","|    time_elapsed         | 3294        |\n","|    total_timesteps      | 2654208     |\n","| train/                  |             |\n","|    approx_kl            | 0.002558268 |\n","|    clip_fraction        | 0.0283      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.549      |\n","|    explained_variance   | 0.961       |\n","|    learning_rate        | 0.0001      |\n","|    loss                 | 23.2        |\n","|    n_updates            | 1610        |\n","|    policy_gradient_loss | -0.000788   |\n","|    value_loss           | 150         |\n","-----------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 210          |\n","|    ep_rew_mean          | 281          |\n","| time/                   |              |\n","|    fps                  | 806          |\n","|    iterations           | 163          |\n","|    time_elapsed         | 3311         |\n","|    total_timesteps      | 2670592      |\n","| train/                  |              |\n","|    approx_kl            | 0.0032546439 |\n","|    clip_fraction        | 0.0349       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.556       |\n","|    explained_variance   | 0.966        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 139          |\n","|    n_updates            | 1620         |\n","|    policy_gradient_loss | -0.000557    |\n","|    value_loss           | 106          |\n","------------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 218         |\n","|    ep_rew_mean          | 282         |\n","| time/                   |             |\n","|    fps                  | 807         |\n","|    iterations           | 164         |\n","|    time_elapsed         | 3328        |\n","|    total_timesteps      | 2686976     |\n","| train/                  |             |\n","|    approx_kl            | 0.002850088 |\n","|    clip_fraction        | 0.0309      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.558      |\n","|    explained_variance   | 0.982       |\n","|    learning_rate        | 0.0001      |\n","|    loss                 | 1.95        |\n","|    n_updates            | 1630        |\n","|    policy_gradient_loss | -0.000522   |\n","|    value_loss           | 69.2        |\n","-----------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 211          |\n","|    ep_rew_mean          | 279          |\n","| time/                   |              |\n","|    fps                  | 807          |\n","|    iterations           | 165          |\n","|    time_elapsed         | 3345         |\n","|    total_timesteps      | 2703360      |\n","| train/                  |              |\n","|    approx_kl            | 0.0030264063 |\n","|    clip_fraction        | 0.0272       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.543       |\n","|    explained_variance   | 0.999        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 1.48         |\n","|    n_updates            | 1640         |\n","|    policy_gradient_loss | -0.00103     |\n","|    value_loss           | 3.71         |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 229          |\n","|    ep_rew_mean          | 275          |\n","| time/                   |              |\n","|    fps                  | 808          |\n","|    iterations           | 166          |\n","|    time_elapsed         | 3363         |\n","|    total_timesteps      | 2719744      |\n","| train/                  |              |\n","|    approx_kl            | 0.0030527255 |\n","|    clip_fraction        | 0.0315       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.544       |\n","|    explained_variance   | 0.96         |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 2.19         |\n","|    n_updates            | 1650         |\n","|    policy_gradient_loss | -0.000615    |\n","|    value_loss           | 134          |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 222          |\n","|    ep_rew_mean          | 275          |\n","| time/                   |              |\n","|    fps                  | 809          |\n","|    iterations           | 167          |\n","|    time_elapsed         | 3381         |\n","|    total_timesteps      | 2736128      |\n","| train/                  |              |\n","|    approx_kl            | 0.0032331483 |\n","|    clip_fraction        | 0.0352       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.555       |\n","|    explained_variance   | 0.952        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 323          |\n","|    n_updates            | 1660         |\n","|    policy_gradient_loss | -0.001       |\n","|    value_loss           | 182          |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 215          |\n","|    ep_rew_mean          | 272          |\n","| time/                   |              |\n","|    fps                  | 810          |\n","|    iterations           | 168          |\n","|    time_elapsed         | 3398         |\n","|    total_timesteps      | 2752512      |\n","| train/                  |              |\n","|    approx_kl            | 0.0024794692 |\n","|    clip_fraction        | 0.0369       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.545       |\n","|    explained_variance   | 0.98         |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 5.07         |\n","|    n_updates            | 1670         |\n","|    policy_gradient_loss | -0.000719    |\n","|    value_loss           | 66.3         |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 217          |\n","|    ep_rew_mean          | 279          |\n","| time/                   |              |\n","|    fps                  | 810          |\n","|    iterations           | 169          |\n","|    time_elapsed         | 3415         |\n","|    total_timesteps      | 2768896      |\n","| train/                  |              |\n","|    approx_kl            | 0.0027701887 |\n","|    clip_fraction        | 0.0267       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.532       |\n","|    explained_variance   | 0.931        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 35.6         |\n","|    n_updates            | 1680         |\n","|    policy_gradient_loss | -0.00112     |\n","|    value_loss           | 245          |\n","------------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 208         |\n","|    ep_rew_mean          | 286         |\n","| time/                   |             |\n","|    fps                  | 811         |\n","|    iterations           | 170         |\n","|    time_elapsed         | 3432        |\n","|    total_timesteps      | 2785280     |\n","| train/                  |             |\n","|    approx_kl            | 0.002416231 |\n","|    clip_fraction        | 0.0239      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.513      |\n","|    explained_variance   | 0.978       |\n","|    learning_rate        | 0.0001      |\n","|    loss                 | 2.36        |\n","|    n_updates            | 1690        |\n","|    policy_gradient_loss | 0.000126    |\n","|    value_loss           | 78.2        |\n","-----------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 214          |\n","|    ep_rew_mean          | 280          |\n","| time/                   |              |\n","|    fps                  | 812          |\n","|    iterations           | 171          |\n","|    time_elapsed         | 3448         |\n","|    total_timesteps      | 2801664      |\n","| train/                  |              |\n","|    approx_kl            | 0.0025652242 |\n","|    clip_fraction        | 0.0255       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.548       |\n","|    explained_variance   | 0.997        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 1.43         |\n","|    n_updates            | 1700         |\n","|    policy_gradient_loss | -0.000712    |\n","|    value_loss           | 7.1          |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 206          |\n","|    ep_rew_mean          | 281          |\n","| time/                   |              |\n","|    fps                  | 813          |\n","|    iterations           | 172          |\n","|    time_elapsed         | 3465         |\n","|    total_timesteps      | 2818048      |\n","| train/                  |              |\n","|    approx_kl            | 0.0027085328 |\n","|    clip_fraction        | 0.0245       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.555       |\n","|    explained_variance   | 0.98         |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 16.1         |\n","|    n_updates            | 1710         |\n","|    policy_gradient_loss | -0.000295    |\n","|    value_loss           | 80           |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 215          |\n","|    ep_rew_mean          | 276          |\n","| time/                   |              |\n","|    fps                  | 813          |\n","|    iterations           | 173          |\n","|    time_elapsed         | 3483         |\n","|    total_timesteps      | 2834432      |\n","| train/                  |              |\n","|    approx_kl            | 0.0038445957 |\n","|    clip_fraction        | 0.0359       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.549       |\n","|    explained_variance   | 0.981        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 2.44         |\n","|    n_updates            | 1720         |\n","|    policy_gradient_loss | -0.00105     |\n","|    value_loss           | 80.3         |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 215          |\n","|    ep_rew_mean          | 274          |\n","| time/                   |              |\n","|    fps                  | 813          |\n","|    iterations           | 174          |\n","|    time_elapsed         | 3502         |\n","|    total_timesteps      | 2850816      |\n","| train/                  |              |\n","|    approx_kl            | 0.0025890523 |\n","|    clip_fraction        | 0.0227       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.545       |\n","|    explained_variance   | 0.961        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 19.2         |\n","|    n_updates            | 1730         |\n","|    policy_gradient_loss | -0.000248    |\n","|    value_loss           | 146          |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 211          |\n","|    ep_rew_mean          | 274          |\n","| time/                   |              |\n","|    fps                  | 814          |\n","|    iterations           | 175          |\n","|    time_elapsed         | 3520         |\n","|    total_timesteps      | 2867200      |\n","| train/                  |              |\n","|    approx_kl            | 0.0032145958 |\n","|    clip_fraction        | 0.0238       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.529       |\n","|    explained_variance   | 0.936        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 41.8         |\n","|    n_updates            | 1740         |\n","|    policy_gradient_loss | -0.001       |\n","|    value_loss           | 226          |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 230          |\n","|    ep_rew_mean          | 282          |\n","| time/                   |              |\n","|    fps                  | 815          |\n","|    iterations           | 176          |\n","|    time_elapsed         | 3537         |\n","|    total_timesteps      | 2883584      |\n","| train/                  |              |\n","|    approx_kl            | 0.0021738599 |\n","|    clip_fraction        | 0.0201       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.532       |\n","|    explained_variance   | 0.983        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 4.38         |\n","|    n_updates            | 1750         |\n","|    policy_gradient_loss | -0.000546    |\n","|    value_loss           | 53.4         |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 216          |\n","|    ep_rew_mean          | 281          |\n","| time/                   |              |\n","|    fps                  | 815          |\n","|    iterations           | 177          |\n","|    time_elapsed         | 3554         |\n","|    total_timesteps      | 2899968      |\n","| train/                  |              |\n","|    approx_kl            | 0.0023699342 |\n","|    clip_fraction        | 0.0276       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.503       |\n","|    explained_variance   | 0.984        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 33.6         |\n","|    n_updates            | 1760         |\n","|    policy_gradient_loss | -0.00123     |\n","|    value_loss           | 45.5         |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 207          |\n","|    ep_rew_mean          | 285          |\n","| time/                   |              |\n","|    fps                  | 816          |\n","|    iterations           | 178          |\n","|    time_elapsed         | 3571         |\n","|    total_timesteps      | 2916352      |\n","| train/                  |              |\n","|    approx_kl            | 0.0027313523 |\n","|    clip_fraction        | 0.0229       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.523       |\n","|    explained_variance   | 0.973        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 32.1         |\n","|    n_updates            | 1770         |\n","|    policy_gradient_loss | -0.000381    |\n","|    value_loss           | 69.4         |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 209          |\n","|    ep_rew_mean          | 281          |\n","| time/                   |              |\n","|    fps                  | 817          |\n","|    iterations           | 179          |\n","|    time_elapsed         | 3588         |\n","|    total_timesteps      | 2932736      |\n","| train/                  |              |\n","|    approx_kl            | 0.0020015643 |\n","|    clip_fraction        | 0.0247       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.526       |\n","|    explained_variance   | 0.974        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 8.72         |\n","|    n_updates            | 1780         |\n","|    policy_gradient_loss | 0.000134     |\n","|    value_loss           | 89.9         |\n","------------------------------------------\n","---------------------------------------\n","| rollout/                |           |\n","|    ep_len_mean          | 226       |\n","|    ep_rew_mean          | 283       |\n","| time/                   |           |\n","|    fps                  | 817       |\n","|    iterations           | 180       |\n","|    time_elapsed         | 3605      |\n","|    total_timesteps      | 2949120   |\n","| train/                  |           |\n","|    approx_kl            | 0.0030787 |\n","|    clip_fraction        | 0.0331    |\n","|    clip_range           | 0.2       |\n","|    entropy_loss         | -0.523    |\n","|    explained_variance   | 0.969     |\n","|    learning_rate        | 0.0001    |\n","|    loss                 | 12.6      |\n","|    n_updates            | 1790      |\n","|    policy_gradient_loss | -0.000754 |\n","|    value_loss           | 81.8      |\n","---------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 222          |\n","|    ep_rew_mean          | 281          |\n","| time/                   |              |\n","|    fps                  | 818          |\n","|    iterations           | 181          |\n","|    time_elapsed         | 3623         |\n","|    total_timesteps      | 2965504      |\n","| train/                  |              |\n","|    approx_kl            | 0.0030037104 |\n","|    clip_fraction        | 0.0283       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.529       |\n","|    explained_variance   | 0.995        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 2.98         |\n","|    n_updates            | 1800         |\n","|    policy_gradient_loss | -0.00108     |\n","|    value_loss           | 11.8         |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 208          |\n","|    ep_rew_mean          | 286          |\n","| time/                   |              |\n","|    fps                  | 819          |\n","|    iterations           | 182          |\n","|    time_elapsed         | 3639         |\n","|    total_timesteps      | 2981888      |\n","| train/                  |              |\n","|    approx_kl            | 0.0030571872 |\n","|    clip_fraction        | 0.0278       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.524       |\n","|    explained_variance   | 0.966        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 21.4         |\n","|    n_updates            | 1810         |\n","|    policy_gradient_loss | -0.000391    |\n","|    value_loss           | 123          |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 209          |\n","|    ep_rew_mean          | 279          |\n","| time/                   |              |\n","|    fps                  | 819          |\n","|    iterations           | 183          |\n","|    time_elapsed         | 3656         |\n","|    total_timesteps      | 2998272      |\n","| train/                  |              |\n","|    approx_kl            | 0.0020251605 |\n","|    clip_fraction        | 0.0217       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.504       |\n","|    explained_variance   | 0.995        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 11.2         |\n","|    n_updates            | 1820         |\n","|    policy_gradient_loss | 0.000406     |\n","|    value_loss           | 11.8         |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 209          |\n","|    ep_rew_mean          | 279          |\n","| time/                   |              |\n","|    fps                  | 820          |\n","|    iterations           | 184          |\n","|    time_elapsed         | 3673         |\n","|    total_timesteps      | 3014656      |\n","| train/                  |              |\n","|    approx_kl            | 0.0028573037 |\n","|    clip_fraction        | 0.0241       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.534       |\n","|    explained_variance   | 0.967        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 32.9         |\n","|    n_updates            | 1830         |\n","|    policy_gradient_loss | -0.000879    |\n","|    value_loss           | 120          |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 216          |\n","|    ep_rew_mean          | 280          |\n","| time/                   |              |\n","|    fps                  | 821          |\n","|    iterations           | 185          |\n","|    time_elapsed         | 3690         |\n","|    total_timesteps      | 3031040      |\n","| train/                  |              |\n","|    approx_kl            | 0.0029890242 |\n","|    clip_fraction        | 0.0304       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.533       |\n","|    explained_variance   | 0.998        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 1.94         |\n","|    n_updates            | 1840         |\n","|    policy_gradient_loss | -0.000756    |\n","|    value_loss           | 3.9          |\n","------------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 220         |\n","|    ep_rew_mean          | 283         |\n","| time/                   |             |\n","|    fps                  | 821         |\n","|    iterations           | 186         |\n","|    time_elapsed         | 3707        |\n","|    total_timesteps      | 3047424     |\n","| train/                  |             |\n","|    approx_kl            | 0.002444181 |\n","|    clip_fraction        | 0.0249      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.515      |\n","|    explained_variance   | 0.965       |\n","|    learning_rate        | 0.0001      |\n","|    loss                 | 148         |\n","|    n_updates            | 1850        |\n","|    policy_gradient_loss | -0.000878   |\n","|    value_loss           | 114         |\n","-----------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 206         |\n","|    ep_rew_mean          | 282         |\n","| time/                   |             |\n","|    fps                  | 822         |\n","|    iterations           | 187         |\n","|    time_elapsed         | 3724        |\n","|    total_timesteps      | 3063808     |\n","| train/                  |             |\n","|    approx_kl            | 0.002476716 |\n","|    clip_fraction        | 0.0259      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.515      |\n","|    explained_variance   | 0.976       |\n","|    learning_rate        | 0.0001      |\n","|    loss                 | 11          |\n","|    n_updates            | 1860        |\n","|    policy_gradient_loss | -0.000258   |\n","|    value_loss           | 93.5        |\n","-----------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 226          |\n","|    ep_rew_mean          | 281          |\n","| time/                   |              |\n","|    fps                  | 823          |\n","|    iterations           | 188          |\n","|    time_elapsed         | 3741         |\n","|    total_timesteps      | 3080192      |\n","| train/                  |              |\n","|    approx_kl            | 0.0020471576 |\n","|    clip_fraction        | 0.0187       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.512       |\n","|    explained_variance   | 0.955        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 482          |\n","|    n_updates            | 1870         |\n","|    policy_gradient_loss | -0.000353    |\n","|    value_loss           | 179          |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 227          |\n","|    ep_rew_mean          | 284          |\n","| time/                   |              |\n","|    fps                  | 823          |\n","|    iterations           | 189          |\n","|    time_elapsed         | 3758         |\n","|    total_timesteps      | 3096576      |\n","| train/                  |              |\n","|    approx_kl            | 0.0029397728 |\n","|    clip_fraction        | 0.0289       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.499       |\n","|    explained_variance   | 0.998        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 2.33         |\n","|    n_updates            | 1880         |\n","|    policy_gradient_loss | -0.00119     |\n","|    value_loss           | 3.9          |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 212          |\n","|    ep_rew_mean          | 280          |\n","| time/                   |              |\n","|    fps                  | 824          |\n","|    iterations           | 190          |\n","|    time_elapsed         | 3775         |\n","|    total_timesteps      | 3112960      |\n","| train/                  |              |\n","|    approx_kl            | 0.0022808823 |\n","|    clip_fraction        | 0.0255       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.515       |\n","|    explained_variance   | 0.994        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 1.2          |\n","|    n_updates            | 1890         |\n","|    policy_gradient_loss | -0.000664    |\n","|    value_loss           | 8.53         |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 209          |\n","|    ep_rew_mean          | 278          |\n","| time/                   |              |\n","|    fps                  | 825          |\n","|    iterations           | 191          |\n","|    time_elapsed         | 3792         |\n","|    total_timesteps      | 3129344      |\n","| train/                  |              |\n","|    approx_kl            | 0.0035231728 |\n","|    clip_fraction        | 0.0281       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.507       |\n","|    explained_variance   | 0.981        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 1.14         |\n","|    n_updates            | 1900         |\n","|    policy_gradient_loss | -0.000626    |\n","|    value_loss           | 78.2         |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 205          |\n","|    ep_rew_mean          | 285          |\n","| time/                   |              |\n","|    fps                  | 825          |\n","|    iterations           | 192          |\n","|    time_elapsed         | 3811         |\n","|    total_timesteps      | 3145728      |\n","| train/                  |              |\n","|    approx_kl            | 0.0025917839 |\n","|    clip_fraction        | 0.0262       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.509       |\n","|    explained_variance   | 0.948        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 127          |\n","|    n_updates            | 1910         |\n","|    policy_gradient_loss | -0.00108     |\n","|    value_loss           | 193          |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 225          |\n","|    ep_rew_mean          | 280          |\n","| time/                   |              |\n","|    fps                  | 825          |\n","|    iterations           | 193          |\n","|    time_elapsed         | 3828         |\n","|    total_timesteps      | 3162112      |\n","| train/                  |              |\n","|    approx_kl            | 0.0030240333 |\n","|    clip_fraction        | 0.0337       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.504       |\n","|    explained_variance   | 0.996        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 4.57         |\n","|    n_updates            | 1920         |\n","|    policy_gradient_loss | -0.000634    |\n","|    value_loss           | 10           |\n","------------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 219         |\n","|    ep_rew_mean          | 277         |\n","| time/                   |             |\n","|    fps                  | 826         |\n","|    iterations           | 194         |\n","|    time_elapsed         | 3846        |\n","|    total_timesteps      | 3178496     |\n","| train/                  |             |\n","|    approx_kl            | 0.002626481 |\n","|    clip_fraction        | 0.0234      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.506      |\n","|    explained_variance   | 0.973       |\n","|    learning_rate        | 0.0001      |\n","|    loss                 | 2.27        |\n","|    n_updates            | 1930        |\n","|    policy_gradient_loss | -0.000376   |\n","|    value_loss           | 94.1        |\n","-----------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 203          |\n","|    ep_rew_mean          | 283          |\n","| time/                   |              |\n","|    fps                  | 827          |\n","|    iterations           | 195          |\n","|    time_elapsed         | 3862         |\n","|    total_timesteps      | 3194880      |\n","| train/                  |              |\n","|    approx_kl            | 0.0021893973 |\n","|    clip_fraction        | 0.0209       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.505       |\n","|    explained_variance   | 0.952        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 1.5          |\n","|    n_updates            | 1940         |\n","|    policy_gradient_loss | 5.35e-05     |\n","|    value_loss           | 195          |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 211          |\n","|    ep_rew_mean          | 281          |\n","| time/                   |              |\n","|    fps                  | 827          |\n","|    iterations           | 196          |\n","|    time_elapsed         | 3879         |\n","|    total_timesteps      | 3211264      |\n","| train/                  |              |\n","|    approx_kl            | 0.0028831498 |\n","|    clip_fraction        | 0.0338       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.528       |\n","|    explained_variance   | 0.997        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 1.54         |\n","|    n_updates            | 1950         |\n","|    policy_gradient_loss | -0.00104     |\n","|    value_loss           | 5.52         |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 214          |\n","|    ep_rew_mean          | 281          |\n","| time/                   |              |\n","|    fps                  | 828          |\n","|    iterations           | 197          |\n","|    time_elapsed         | 3896         |\n","|    total_timesteps      | 3227648      |\n","| train/                  |              |\n","|    approx_kl            | 0.0023708383 |\n","|    clip_fraction        | 0.0196       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.506       |\n","|    explained_variance   | 0.967        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 78.1         |\n","|    n_updates            | 1960         |\n","|    policy_gradient_loss | -0.000137    |\n","|    value_loss           | 122          |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 213          |\n","|    ep_rew_mean          | 278          |\n","| time/                   |              |\n","|    fps                  | 828          |\n","|    iterations           | 198          |\n","|    time_elapsed         | 3913         |\n","|    total_timesteps      | 3244032      |\n","| train/                  |              |\n","|    approx_kl            | 0.0027193052 |\n","|    clip_fraction        | 0.0244       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.516       |\n","|    explained_variance   | 0.998        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 2.18         |\n","|    n_updates            | 1970         |\n","|    policy_gradient_loss | -0.000525    |\n","|    value_loss           | 5.59         |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 213          |\n","|    ep_rew_mean          | 275          |\n","| time/                   |              |\n","|    fps                  | 829          |\n","|    iterations           | 199          |\n","|    time_elapsed         | 3930         |\n","|    total_timesteps      | 3260416      |\n","| train/                  |              |\n","|    approx_kl            | 0.0029359306 |\n","|    clip_fraction        | 0.0208       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.496       |\n","|    explained_variance   | 0.937        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 11           |\n","|    n_updates            | 1980         |\n","|    policy_gradient_loss | -0.00128     |\n","|    value_loss           | 226          |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 220          |\n","|    ep_rew_mean          | 276          |\n","| time/                   |              |\n","|    fps                  | 830          |\n","|    iterations           | 200          |\n","|    time_elapsed         | 3947         |\n","|    total_timesteps      | 3276800      |\n","| train/                  |              |\n","|    approx_kl            | 0.0028267445 |\n","|    clip_fraction        | 0.0281       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.509       |\n","|    explained_variance   | 0.965        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 19.8         |\n","|    n_updates            | 1990         |\n","|    policy_gradient_loss | 0.000188     |\n","|    value_loss           | 110          |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 214          |\n","|    ep_rew_mean          | 283          |\n","| time/                   |              |\n","|    fps                  | 830          |\n","|    iterations           | 201          |\n","|    time_elapsed         | 3964         |\n","|    total_timesteps      | 3293184      |\n","| train/                  |              |\n","|    approx_kl            | 0.0034019835 |\n","|    clip_fraction        | 0.0337       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.507       |\n","|    explained_variance   | 0.946        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 175          |\n","|    n_updates            | 2000         |\n","|    policy_gradient_loss | -0.00131     |\n","|    value_loss           | 207          |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 202          |\n","|    ep_rew_mean          | 284          |\n","| time/                   |              |\n","|    fps                  | 831          |\n","|    iterations           | 202          |\n","|    time_elapsed         | 3981         |\n","|    total_timesteps      | 3309568      |\n","| train/                  |              |\n","|    approx_kl            | 0.0034601414 |\n","|    clip_fraction        | 0.0473       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.519       |\n","|    explained_variance   | 0.987        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 2.97         |\n","|    n_updates            | 2010         |\n","|    policy_gradient_loss | -0.00122     |\n","|    value_loss           | 18.1         |\n","------------------------------------------\n","----------------------------------------\n","| rollout/                |            |\n","|    ep_len_mean          | 215        |\n","|    ep_rew_mean          | 278        |\n","| time/                   |            |\n","|    fps                  | 831        |\n","|    iterations           | 203        |\n","|    time_elapsed         | 3998       |\n","|    total_timesteps      | 3325952    |\n","| train/                  |            |\n","|    approx_kl            | 0.00322486 |\n","|    clip_fraction        | 0.036      |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -0.529     |\n","|    explained_variance   | 0.997      |\n","|    learning_rate        | 0.0001     |\n","|    loss                 | 2.19       |\n","|    n_updates            | 2020       |\n","|    policy_gradient_loss | -0.000907  |\n","|    value_loss           | 4.81       |\n","----------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 216          |\n","|    ep_rew_mean          | 279          |\n","| time/                   |              |\n","|    fps                  | 832          |\n","|    iterations           | 204          |\n","|    time_elapsed         | 4015         |\n","|    total_timesteps      | 3342336      |\n","| train/                  |              |\n","|    approx_kl            | 0.0023428248 |\n","|    clip_fraction        | 0.0172       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.513       |\n","|    explained_variance   | 0.986        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 5.02         |\n","|    n_updates            | 2030         |\n","|    policy_gradient_loss | -0.000413    |\n","|    value_loss           | 46.8         |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 201          |\n","|    ep_rew_mean          | 280          |\n","| time/                   |              |\n","|    fps                  | 833          |\n","|    iterations           | 205          |\n","|    time_elapsed         | 4031         |\n","|    total_timesteps      | 3358720      |\n","| train/                  |              |\n","|    approx_kl            | 0.0023285234 |\n","|    clip_fraction        | 0.0277       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.521       |\n","|    explained_variance   | 0.981        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 1.71         |\n","|    n_updates            | 2040         |\n","|    policy_gradient_loss | -0.000107    |\n","|    value_loss           | 74.8         |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 204          |\n","|    ep_rew_mean          | 281          |\n","| time/                   |              |\n","|    fps                  | 833          |\n","|    iterations           | 206          |\n","|    time_elapsed         | 4048         |\n","|    total_timesteps      | 3375104      |\n","| train/                  |              |\n","|    approx_kl            | 0.0032933387 |\n","|    clip_fraction        | 0.0408       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.541       |\n","|    explained_variance   | 0.98         |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 1.91         |\n","|    n_updates            | 2050         |\n","|    policy_gradient_loss | -0.000957    |\n","|    value_loss           | 70           |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 212          |\n","|    ep_rew_mean          | 278          |\n","| time/                   |              |\n","|    fps                  | 834          |\n","|    iterations           | 207          |\n","|    time_elapsed         | 4065         |\n","|    total_timesteps      | 3391488      |\n","| train/                  |              |\n","|    approx_kl            | 0.0021958463 |\n","|    clip_fraction        | 0.0251       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.507       |\n","|    explained_variance   | 0.998        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 1.66         |\n","|    n_updates            | 2060         |\n","|    policy_gradient_loss | -0.000659    |\n","|    value_loss           | 4.96         |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 214          |\n","|    ep_rew_mean          | 280          |\n","| time/                   |              |\n","|    fps                  | 834          |\n","|    iterations           | 208          |\n","|    time_elapsed         | 4082         |\n","|    total_timesteps      | 3407872      |\n","| train/                  |              |\n","|    approx_kl            | 0.0021684505 |\n","|    clip_fraction        | 0.0161       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.509       |\n","|    explained_variance   | 0.944        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 22.7         |\n","|    n_updates            | 2070         |\n","|    policy_gradient_loss | -0.000402    |\n","|    value_loss           | 179          |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 212          |\n","|    ep_rew_mean          | 276          |\n","| time/                   |              |\n","|    fps                  | 835          |\n","|    iterations           | 209          |\n","|    time_elapsed         | 4099         |\n","|    total_timesteps      | 3424256      |\n","| train/                  |              |\n","|    approx_kl            | 0.0020508831 |\n","|    clip_fraction        | 0.0297       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.542       |\n","|    explained_variance   | 0.993        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 2.06         |\n","|    n_updates            | 2080         |\n","|    policy_gradient_loss | 0.000244     |\n","|    value_loss           | 13.8         |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 215          |\n","|    ep_rew_mean          | 281          |\n","| time/                   |              |\n","|    fps                  | 835          |\n","|    iterations           | 210          |\n","|    time_elapsed         | 4118         |\n","|    total_timesteps      | 3440640      |\n","| train/                  |              |\n","|    approx_kl            | 0.0033212483 |\n","|    clip_fraction        | 0.0302       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.516       |\n","|    explained_variance   | 0.945        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 22.5         |\n","|    n_updates            | 2090         |\n","|    policy_gradient_loss | -0.000376    |\n","|    value_loss           | 202          |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 210          |\n","|    ep_rew_mean          | 280          |\n","| time/                   |              |\n","|    fps                  | 835          |\n","|    iterations           | 211          |\n","|    time_elapsed         | 4135         |\n","|    total_timesteps      | 3457024      |\n","| train/                  |              |\n","|    approx_kl            | 0.0024552282 |\n","|    clip_fraction        | 0.0229       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.508       |\n","|    explained_variance   | 0.987        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 14.3         |\n","|    n_updates            | 2100         |\n","|    policy_gradient_loss | -0.000705    |\n","|    value_loss           | 35.6         |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 202          |\n","|    ep_rew_mean          | 281          |\n","| time/                   |              |\n","|    fps                  | 836          |\n","|    iterations           | 212          |\n","|    time_elapsed         | 4152         |\n","|    total_timesteps      | 3473408      |\n","| train/                  |              |\n","|    approx_kl            | 0.0020300497 |\n","|    clip_fraction        | 0.0259       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.533       |\n","|    explained_variance   | 0.986        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 89.3         |\n","|    n_updates            | 2110         |\n","|    policy_gradient_loss | 0.000148     |\n","|    value_loss           | 41.6         |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 206          |\n","|    ep_rew_mean          | 282          |\n","| time/                   |              |\n","|    fps                  | 837          |\n","|    iterations           | 213          |\n","|    time_elapsed         | 4169         |\n","|    total_timesteps      | 3489792      |\n","| train/                  |              |\n","|    approx_kl            | 0.0023419857 |\n","|    clip_fraction        | 0.0179       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.51        |\n","|    explained_variance   | 0.995        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 17           |\n","|    n_updates            | 2120         |\n","|    policy_gradient_loss | -0.000451    |\n","|    value_loss           | 14.6         |\n","------------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 213         |\n","|    ep_rew_mean          | 283         |\n","| time/                   |             |\n","|    fps                  | 837         |\n","|    iterations           | 214         |\n","|    time_elapsed         | 4186        |\n","|    total_timesteps      | 3506176     |\n","| train/                  |             |\n","|    approx_kl            | 0.002510884 |\n","|    clip_fraction        | 0.0273      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.527      |\n","|    explained_variance   | 0.985       |\n","|    learning_rate        | 0.0001      |\n","|    loss                 | 3.92        |\n","|    n_updates            | 2130        |\n","|    policy_gradient_loss | -0.000572   |\n","|    value_loss           | 60.3        |\n","-----------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 204          |\n","|    ep_rew_mean          | 283          |\n","| time/                   |              |\n","|    fps                  | 837          |\n","|    iterations           | 215          |\n","|    time_elapsed         | 4203         |\n","|    total_timesteps      | 3522560      |\n","| train/                  |              |\n","|    approx_kl            | 0.0035008476 |\n","|    clip_fraction        | 0.0394       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.539       |\n","|    explained_variance   | 0.999        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 0.759        |\n","|    n_updates            | 2140         |\n","|    policy_gradient_loss | -0.000829    |\n","|    value_loss           | 2.08         |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 203          |\n","|    ep_rew_mean          | 284          |\n","| time/                   |              |\n","|    fps                  | 838          |\n","|    iterations           | 216          |\n","|    time_elapsed         | 4220         |\n","|    total_timesteps      | 3538944      |\n","| train/                  |              |\n","|    approx_kl            | 0.0030945914 |\n","|    clip_fraction        | 0.0203       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.503       |\n","|    explained_variance   | 0.989        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 4.1          |\n","|    n_updates            | 2150         |\n","|    policy_gradient_loss | -0.000709    |\n","|    value_loss           | 34.9         |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 200          |\n","|    ep_rew_mean          | 284          |\n","| time/                   |              |\n","|    fps                  | 839          |\n","|    iterations           | 217          |\n","|    time_elapsed         | 4237         |\n","|    total_timesteps      | 3555328      |\n","| train/                  |              |\n","|    approx_kl            | 0.0028847905 |\n","|    clip_fraction        | 0.026        |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.516       |\n","|    explained_variance   | 0.987        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 66.2         |\n","|    n_updates            | 2160         |\n","|    policy_gradient_loss | -0.000823    |\n","|    value_loss           | 49.1         |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 202          |\n","|    ep_rew_mean          | 287          |\n","| time/                   |              |\n","|    fps                  | 839          |\n","|    iterations           | 218          |\n","|    time_elapsed         | 4254         |\n","|    total_timesteps      | 3571712      |\n","| train/                  |              |\n","|    approx_kl            | 0.0030548337 |\n","|    clip_fraction        | 0.0282       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.517       |\n","|    explained_variance   | 0.983        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 1.32         |\n","|    n_updates            | 2170         |\n","|    policy_gradient_loss | 0.000318     |\n","|    value_loss           | 66.2         |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 213          |\n","|    ep_rew_mean          | 277          |\n","| time/                   |              |\n","|    fps                  | 840          |\n","|    iterations           | 219          |\n","|    time_elapsed         | 4271         |\n","|    total_timesteps      | 3588096      |\n","| train/                  |              |\n","|    approx_kl            | 0.0019541795 |\n","|    clip_fraction        | 0.0204       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.508       |\n","|    explained_variance   | 0.999        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 0.84         |\n","|    n_updates            | 2180         |\n","|    policy_gradient_loss | -0.000832    |\n","|    value_loss           | 3.1          |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 210          |\n","|    ep_rew_mean          | 281          |\n","| time/                   |              |\n","|    fps                  | 840          |\n","|    iterations           | 220          |\n","|    time_elapsed         | 4288         |\n","|    total_timesteps      | 3604480      |\n","| train/                  |              |\n","|    approx_kl            | 0.0030891686 |\n","|    clip_fraction        | 0.0199       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.529       |\n","|    explained_variance   | 0.956        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 414          |\n","|    n_updates            | 2190         |\n","|    policy_gradient_loss | -0.000598    |\n","|    value_loss           | 154          |\n","------------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 204         |\n","|    ep_rew_mean          | 283         |\n","| time/                   |             |\n","|    fps                  | 841         |\n","|    iterations           | 221         |\n","|    time_elapsed         | 4305        |\n","|    total_timesteps      | 3620864     |\n","| train/                  |             |\n","|    approx_kl            | 0.002334643 |\n","|    clip_fraction        | 0.0221      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.488      |\n","|    explained_variance   | 0.986       |\n","|    learning_rate        | 0.0001      |\n","|    loss                 | 2.24        |\n","|    n_updates            | 2200        |\n","|    policy_gradient_loss | -0.00014    |\n","|    value_loss           | 41.7        |\n","-----------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 205         |\n","|    ep_rew_mean          | 285         |\n","| time/                   |             |\n","|    fps                  | 841         |\n","|    iterations           | 222         |\n","|    time_elapsed         | 4321        |\n","|    total_timesteps      | 3637248     |\n","| train/                  |             |\n","|    approx_kl            | 0.002437618 |\n","|    clip_fraction        | 0.0298      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.488      |\n","|    explained_variance   | 0.988       |\n","|    learning_rate        | 0.0001      |\n","|    loss                 | 1.79        |\n","|    n_updates            | 2210        |\n","|    policy_gradient_loss | -0.000192   |\n","|    value_loss           | 35.6        |\n","-----------------------------------------\n","----------------------------------------\n","| rollout/                |            |\n","|    ep_len_mean          | 203        |\n","|    ep_rew_mean          | 286        |\n","| time/                   |            |\n","|    fps                  | 842        |\n","|    iterations           | 223        |\n","|    time_elapsed         | 4338       |\n","|    total_timesteps      | 3653632    |\n","| train/                  |            |\n","|    approx_kl            | 0.00224465 |\n","|    clip_fraction        | 0.0286     |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -0.513     |\n","|    explained_variance   | 0.993      |\n","|    learning_rate        | 0.0001     |\n","|    loss                 | 1.09       |\n","|    n_updates            | 2220       |\n","|    policy_gradient_loss | -0.000264  |\n","|    value_loss           | 11.2       |\n","----------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 213         |\n","|    ep_rew_mean          | 284         |\n","| time/                   |             |\n","|    fps                  | 842         |\n","|    iterations           | 224         |\n","|    time_elapsed         | 4355        |\n","|    total_timesteps      | 3670016     |\n","| train/                  |             |\n","|    approx_kl            | 0.004055963 |\n","|    clip_fraction        | 0.0312      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.519      |\n","|    explained_variance   | 0.995       |\n","|    learning_rate        | 0.0001      |\n","|    loss                 | 1.36        |\n","|    n_updates            | 2230        |\n","|    policy_gradient_loss | -0.000333   |\n","|    value_loss           | 10.8        |\n","-----------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 201         |\n","|    ep_rew_mean          | 285         |\n","| time/                   |             |\n","|    fps                  | 843         |\n","|    iterations           | 225         |\n","|    time_elapsed         | 4372        |\n","|    total_timesteps      | 3686400     |\n","| train/                  |             |\n","|    approx_kl            | 0.002395413 |\n","|    clip_fraction        | 0.0272      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.506      |\n","|    explained_variance   | 0.994       |\n","|    learning_rate        | 0.0001      |\n","|    loss                 | 2.18        |\n","|    n_updates            | 2240        |\n","|    policy_gradient_loss | -0.000501   |\n","|    value_loss           | 24          |\n","-----------------------------------------\n","----------------------------------------\n","| rollout/                |            |\n","|    ep_len_mean          | 204        |\n","|    ep_rew_mean          | 285        |\n","| time/                   |            |\n","|    fps                  | 843        |\n","|    iterations           | 226        |\n","|    time_elapsed         | 4388       |\n","|    total_timesteps      | 3702784    |\n","| train/                  |            |\n","|    approx_kl            | 0.00183964 |\n","|    clip_fraction        | 0.022      |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -0.514     |\n","|    explained_variance   | 0.997      |\n","|    learning_rate        | 0.0001     |\n","|    loss                 | 0.86       |\n","|    n_updates            | 2250       |\n","|    policy_gradient_loss | 1.94e-05   |\n","|    value_loss           | 8.66       |\n","----------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 213          |\n","|    ep_rew_mean          | 287          |\n","| time/                   |              |\n","|    fps                  | 844          |\n","|    iterations           | 227          |\n","|    time_elapsed         | 4405         |\n","|    total_timesteps      | 3719168      |\n","| train/                  |              |\n","|    approx_kl            | 0.0024921931 |\n","|    clip_fraction        | 0.0248       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.514       |\n","|    explained_variance   | 0.985        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 1.26         |\n","|    n_updates            | 2260         |\n","|    policy_gradient_loss | -0.000194    |\n","|    value_loss           | 62.1         |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 213          |\n","|    ep_rew_mean          | 285          |\n","| time/                   |              |\n","|    fps                  | 844          |\n","|    iterations           | 228          |\n","|    time_elapsed         | 4425         |\n","|    total_timesteps      | 3735552      |\n","| train/                  |              |\n","|    approx_kl            | 0.0031622313 |\n","|    clip_fraction        | 0.0389       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.501       |\n","|    explained_variance   | 0.998        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 1.18         |\n","|    n_updates            | 2270         |\n","|    policy_gradient_loss | -0.00116     |\n","|    value_loss           | 5.37         |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 215          |\n","|    ep_rew_mean          | 281          |\n","| time/                   |              |\n","|    fps                  | 844          |\n","|    iterations           | 229          |\n","|    time_elapsed         | 4442         |\n","|    total_timesteps      | 3751936      |\n","| train/                  |              |\n","|    approx_kl            | 0.0034616436 |\n","|    clip_fraction        | 0.0348       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.528       |\n","|    explained_variance   | 0.998        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 1.06         |\n","|    n_updates            | 2280         |\n","|    policy_gradient_loss | -0.000504    |\n","|    value_loss           | 3.48         |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 202          |\n","|    ep_rew_mean          | 287          |\n","| time/                   |              |\n","|    fps                  | 845          |\n","|    iterations           | 230          |\n","|    time_elapsed         | 4459         |\n","|    total_timesteps      | 3768320      |\n","| train/                  |              |\n","|    approx_kl            | 0.0024931761 |\n","|    clip_fraction        | 0.0294       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.527       |\n","|    explained_variance   | 0.998        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 2.71         |\n","|    n_updates            | 2290         |\n","|    policy_gradient_loss | -0.000677    |\n","|    value_loss           | 3.68         |\n","------------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 206         |\n","|    ep_rew_mean          | 282         |\n","| time/                   |             |\n","|    fps                  | 845         |\n","|    iterations           | 231         |\n","|    time_elapsed         | 4476        |\n","|    total_timesteps      | 3784704     |\n","| train/                  |             |\n","|    approx_kl            | 0.002689154 |\n","|    clip_fraction        | 0.0263      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.493      |\n","|    explained_variance   | 0.995       |\n","|    learning_rate        | 0.0001      |\n","|    loss                 | 1.5         |\n","|    n_updates            | 2300        |\n","|    policy_gradient_loss | -0.000975   |\n","|    value_loss           | 8.98        |\n","-----------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 198          |\n","|    ep_rew_mean          | 279          |\n","| time/                   |              |\n","|    fps                  | 846          |\n","|    iterations           | 232          |\n","|    time_elapsed         | 4492         |\n","|    total_timesteps      | 3801088      |\n","| train/                  |              |\n","|    approx_kl            | 0.0028863668 |\n","|    clip_fraction        | 0.0239       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.492       |\n","|    explained_variance   | 0.974        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 1.09         |\n","|    n_updates            | 2310         |\n","|    policy_gradient_loss | -0.00102     |\n","|    value_loss           | 78.6         |\n","------------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 202         |\n","|    ep_rew_mean          | 286         |\n","| time/                   |             |\n","|    fps                  | 846         |\n","|    iterations           | 233         |\n","|    time_elapsed         | 4509        |\n","|    total_timesteps      | 3817472     |\n","| train/                  |             |\n","|    approx_kl            | 0.003598151 |\n","|    clip_fraction        | 0.0339      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.495      |\n","|    explained_variance   | 0.948       |\n","|    learning_rate        | 0.0001      |\n","|    loss                 | 16.1        |\n","|    n_updates            | 2320        |\n","|    policy_gradient_loss | -0.000581   |\n","|    value_loss           | 185         |\n","-----------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 201          |\n","|    ep_rew_mean          | 281          |\n","| time/                   |              |\n","|    fps                  | 846          |\n","|    iterations           | 234          |\n","|    time_elapsed         | 4526         |\n","|    total_timesteps      | 3833856      |\n","| train/                  |              |\n","|    approx_kl            | 0.0033706492 |\n","|    clip_fraction        | 0.038        |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.512       |\n","|    explained_variance   | 0.998        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 1.82         |\n","|    n_updates            | 2330         |\n","|    policy_gradient_loss | -0.00102     |\n","|    value_loss           | 3.56         |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 218          |\n","|    ep_rew_mean          | 282          |\n","| time/                   |              |\n","|    fps                  | 847          |\n","|    iterations           | 235          |\n","|    time_elapsed         | 4543         |\n","|    total_timesteps      | 3850240      |\n","| train/                  |              |\n","|    approx_kl            | 0.0029832884 |\n","|    clip_fraction        | 0.0182       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.506       |\n","|    explained_variance   | 0.957        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 75.5         |\n","|    n_updates            | 2340         |\n","|    policy_gradient_loss | -0.00033     |\n","|    value_loss           | 157          |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 204          |\n","|    ep_rew_mean          | 280          |\n","| time/                   |              |\n","|    fps                  | 847          |\n","|    iterations           | 236          |\n","|    time_elapsed         | 4560         |\n","|    total_timesteps      | 3866624      |\n","| train/                  |              |\n","|    approx_kl            | 0.0035220592 |\n","|    clip_fraction        | 0.0328       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.513       |\n","|    explained_variance   | 0.994        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 5.9          |\n","|    n_updates            | 2350         |\n","|    policy_gradient_loss | -0.00064     |\n","|    value_loss           | 11.3         |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 212          |\n","|    ep_rew_mean          | 275          |\n","| time/                   |              |\n","|    fps                  | 848          |\n","|    iterations           | 237          |\n","|    time_elapsed         | 4577         |\n","|    total_timesteps      | 3883008      |\n","| train/                  |              |\n","|    approx_kl            | 0.0020504745 |\n","|    clip_fraction        | 0.0222       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.476       |\n","|    explained_variance   | 0.959        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 12.4         |\n","|    n_updates            | 2360         |\n","|    policy_gradient_loss | -0.000623    |\n","|    value_loss           | 155          |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 201          |\n","|    ep_rew_mean          | 282          |\n","| time/                   |              |\n","|    fps                  | 848          |\n","|    iterations           | 238          |\n","|    time_elapsed         | 4594         |\n","|    total_timesteps      | 3899392      |\n","| train/                  |              |\n","|    approx_kl            | 0.0021709825 |\n","|    clip_fraction        | 0.0224       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.473       |\n","|    explained_variance   | 0.975        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 5.71         |\n","|    n_updates            | 2370         |\n","|    policy_gradient_loss | -6.87e-05    |\n","|    value_loss           | 94           |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 202          |\n","|    ep_rew_mean          | 283          |\n","| time/                   |              |\n","|    fps                  | 849          |\n","|    iterations           | 239          |\n","|    time_elapsed         | 4611         |\n","|    total_timesteps      | 3915776      |\n","| train/                  |              |\n","|    approx_kl            | 0.0023502714 |\n","|    clip_fraction        | 0.0291       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.494       |\n","|    explained_variance   | 0.982        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 2.88         |\n","|    n_updates            | 2380         |\n","|    policy_gradient_loss | -6.14e-05    |\n","|    value_loss           | 64.8         |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 200          |\n","|    ep_rew_mean          | 287          |\n","| time/                   |              |\n","|    fps                  | 849          |\n","|    iterations           | 240          |\n","|    time_elapsed         | 4627         |\n","|    total_timesteps      | 3932160      |\n","| train/                  |              |\n","|    approx_kl            | 0.0024976374 |\n","|    clip_fraction        | 0.0261       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.468       |\n","|    explained_variance   | 0.972        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 2.58         |\n","|    n_updates            | 2390         |\n","|    policy_gradient_loss | 0.000121     |\n","|    value_loss           | 125          |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 207          |\n","|    ep_rew_mean          | 286          |\n","| time/                   |              |\n","|    fps                  | 850          |\n","|    iterations           | 241          |\n","|    time_elapsed         | 4644         |\n","|    total_timesteps      | 3948544      |\n","| train/                  |              |\n","|    approx_kl            | 0.0025664745 |\n","|    clip_fraction        | 0.0277       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.481       |\n","|    explained_variance   | 0.982        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 4.24         |\n","|    n_updates            | 2400         |\n","|    policy_gradient_loss | -0.00031     |\n","|    value_loss           | 74.9         |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 208          |\n","|    ep_rew_mean          | 284          |\n","| time/                   |              |\n","|    fps                  | 850          |\n","|    iterations           | 242          |\n","|    time_elapsed         | 4661         |\n","|    total_timesteps      | 3964928      |\n","| train/                  |              |\n","|    approx_kl            | 0.0013376526 |\n","|    clip_fraction        | 0.0185       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.482       |\n","|    explained_variance   | 0.996        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 4.52         |\n","|    n_updates            | 2410         |\n","|    policy_gradient_loss | -0.000196    |\n","|    value_loss           | 7.86         |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 223          |\n","|    ep_rew_mean          | 280          |\n","| time/                   |              |\n","|    fps                  | 850          |\n","|    iterations           | 243          |\n","|    time_elapsed         | 4678         |\n","|    total_timesteps      | 3981312      |\n","| train/                  |              |\n","|    approx_kl            | 0.0049143443 |\n","|    clip_fraction        | 0.0336       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.519       |\n","|    explained_variance   | 0.998        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 0.898        |\n","|    n_updates            | 2420         |\n","|    policy_gradient_loss | -0.00243     |\n","|    value_loss           | 3.86         |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 206          |\n","|    ep_rew_mean          | 283          |\n","| time/                   |              |\n","|    fps                  | 851          |\n","|    iterations           | 244          |\n","|    time_elapsed         | 4695         |\n","|    total_timesteps      | 3997696      |\n","| train/                  |              |\n","|    approx_kl            | 0.0023183883 |\n","|    clip_fraction        | 0.0196       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.5         |\n","|    explained_variance   | 0.98         |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 21.4         |\n","|    n_updates            | 2430         |\n","|    policy_gradient_loss | -0.000322    |\n","|    value_loss           | 72.7         |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 204          |\n","|    ep_rew_mean          | 281          |\n","| time/                   |              |\n","|    fps                  | 851          |\n","|    iterations           | 245          |\n","|    time_elapsed         | 4712         |\n","|    total_timesteps      | 4014080      |\n","| train/                  |              |\n","|    approx_kl            | 0.0030329083 |\n","|    clip_fraction        | 0.027        |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.511       |\n","|    explained_variance   | 0.999        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 2.07         |\n","|    n_updates            | 2440         |\n","|    policy_gradient_loss | -0.001       |\n","|    value_loss           | 3.02         |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 200          |\n","|    ep_rew_mean          | 286          |\n","| time/                   |              |\n","|    fps                  | 851          |\n","|    iterations           | 246          |\n","|    time_elapsed         | 4731         |\n","|    total_timesteps      | 4030464      |\n","| train/                  |              |\n","|    approx_kl            | 0.0028301706 |\n","|    clip_fraction        | 0.0269       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.513       |\n","|    explained_variance   | 0.98         |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 0.837        |\n","|    n_updates            | 2450         |\n","|    policy_gradient_loss | -0.000233    |\n","|    value_loss           | 85           |\n","------------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 199         |\n","|    ep_rew_mean          | 284         |\n","| time/                   |             |\n","|    fps                  | 852         |\n","|    iterations           | 247         |\n","|    time_elapsed         | 4748        |\n","|    total_timesteps      | 4046848     |\n","| train/                  |             |\n","|    approx_kl            | 0.002800886 |\n","|    clip_fraction        | 0.0301      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.5        |\n","|    explained_variance   | 0.999       |\n","|    learning_rate        | 0.0001      |\n","|    loss                 | 0.845       |\n","|    n_updates            | 2460        |\n","|    policy_gradient_loss | -0.000645   |\n","|    value_loss           | 2           |\n","-----------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 208          |\n","|    ep_rew_mean          | 284          |\n","| time/                   |              |\n","|    fps                  | 852          |\n","|    iterations           | 248          |\n","|    time_elapsed         | 4764         |\n","|    total_timesteps      | 4063232      |\n","| train/                  |              |\n","|    approx_kl            | 0.0021935985 |\n","|    clip_fraction        | 0.0242       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.475       |\n","|    explained_variance   | 0.984        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 2.02         |\n","|    n_updates            | 2470         |\n","|    policy_gradient_loss | -0.000963    |\n","|    value_loss           | 50.6         |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 198          |\n","|    ep_rew_mean          | 278          |\n","| time/                   |              |\n","|    fps                  | 853          |\n","|    iterations           | 249          |\n","|    time_elapsed         | 4780         |\n","|    total_timesteps      | 4079616      |\n","| train/                  |              |\n","|    approx_kl            | 0.0023201506 |\n","|    clip_fraction        | 0.0278       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.491       |\n","|    explained_variance   | 0.999        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 1.21         |\n","|    n_updates            | 2480         |\n","|    policy_gradient_loss | -0.000568    |\n","|    value_loss           | 3.69         |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 199          |\n","|    ep_rew_mean          | 287          |\n","| time/                   |              |\n","|    fps                  | 853          |\n","|    iterations           | 250          |\n","|    time_elapsed         | 4797         |\n","|    total_timesteps      | 4096000      |\n","| train/                  |              |\n","|    approx_kl            | 0.0022412345 |\n","|    clip_fraction        | 0.0132       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.483       |\n","|    explained_variance   | 0.938        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 23.3         |\n","|    n_updates            | 2490         |\n","|    policy_gradient_loss | -0.000773    |\n","|    value_loss           | 278          |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 204          |\n","|    ep_rew_mean          | 282          |\n","| time/                   |              |\n","|    fps                  | 854          |\n","|    iterations           | 251          |\n","|    time_elapsed         | 4814         |\n","|    total_timesteps      | 4112384      |\n","| train/                  |              |\n","|    approx_kl            | 0.0029551545 |\n","|    clip_fraction        | 0.0289       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.462       |\n","|    explained_variance   | 0.98         |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 1.5          |\n","|    n_updates            | 2500         |\n","|    policy_gradient_loss | -0.000265    |\n","|    value_loss           | 94.6         |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 205          |\n","|    ep_rew_mean          | 281          |\n","| time/                   |              |\n","|    fps                  | 854          |\n","|    iterations           | 252          |\n","|    time_elapsed         | 4830         |\n","|    total_timesteps      | 4128768      |\n","| train/                  |              |\n","|    approx_kl            | 0.0024412996 |\n","|    clip_fraction        | 0.0276       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.49        |\n","|    explained_variance   | 0.985        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 2.58         |\n","|    n_updates            | 2510         |\n","|    policy_gradient_loss | -0.000415    |\n","|    value_loss           | 68.2         |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 198          |\n","|    ep_rew_mean          | 283          |\n","| time/                   |              |\n","|    fps                  | 855          |\n","|    iterations           | 253          |\n","|    time_elapsed         | 4847         |\n","|    total_timesteps      | 4145152      |\n","| train/                  |              |\n","|    approx_kl            | 0.0025500678 |\n","|    clip_fraction        | 0.0248       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.482       |\n","|    explained_variance   | 0.969        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 1.9          |\n","|    n_updates            | 2520         |\n","|    policy_gradient_loss | -0.000541    |\n","|    value_loss           | 136          |\n","------------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 201         |\n","|    ep_rew_mean          | 285         |\n","| time/                   |             |\n","|    fps                  | 855         |\n","|    iterations           | 254         |\n","|    time_elapsed         | 4863        |\n","|    total_timesteps      | 4161536     |\n","| train/                  |             |\n","|    approx_kl            | 0.002032926 |\n","|    clip_fraction        | 0.0385      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.461      |\n","|    explained_variance   | 0.968       |\n","|    learning_rate        | 0.0001      |\n","|    loss                 | 1.34        |\n","|    n_updates            | 2530        |\n","|    policy_gradient_loss | -3.41e-05   |\n","|    value_loss           | 140         |\n","-----------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 197         |\n","|    ep_rew_mean          | 279         |\n","| time/                   |             |\n","|    fps                  | 856         |\n","|    iterations           | 255         |\n","|    time_elapsed         | 4879        |\n","|    total_timesteps      | 4177920     |\n","| train/                  |             |\n","|    approx_kl            | 0.003885189 |\n","|    clip_fraction        | 0.0352      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.474      |\n","|    explained_variance   | 0.978       |\n","|    learning_rate        | 0.0001      |\n","|    loss                 | 5.45        |\n","|    n_updates            | 2540        |\n","|    policy_gradient_loss | -0.000431   |\n","|    value_loss           | 89.7        |\n","-----------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 198          |\n","|    ep_rew_mean          | 289          |\n","| time/                   |              |\n","|    fps                  | 856          |\n","|    iterations           | 256          |\n","|    time_elapsed         | 4896         |\n","|    total_timesteps      | 4194304      |\n","| train/                  |              |\n","|    approx_kl            | 0.0023150945 |\n","|    clip_fraction        | 0.0326       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.476       |\n","|    explained_variance   | 0.954        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 7.46         |\n","|    n_updates            | 2550         |\n","|    policy_gradient_loss | -0.00102     |\n","|    value_loss           | 172          |\n","------------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 198         |\n","|    ep_rew_mean          | 281         |\n","| time/                   |             |\n","|    fps                  | 857         |\n","|    iterations           | 257         |\n","|    time_elapsed         | 4912        |\n","|    total_timesteps      | 4210688     |\n","| train/                  |             |\n","|    approx_kl            | 0.002105129 |\n","|    clip_fraction        | 0.0328      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.468      |\n","|    explained_variance   | 0.997       |\n","|    learning_rate        | 0.0001      |\n","|    loss                 | 1.49        |\n","|    n_updates            | 2560        |\n","|    policy_gradient_loss | -9.89e-05   |\n","|    value_loss           | 6.04        |\n","-----------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 197          |\n","|    ep_rew_mean          | 279          |\n","| time/                   |              |\n","|    fps                  | 857          |\n","|    iterations           | 258          |\n","|    time_elapsed         | 4928         |\n","|    total_timesteps      | 4227072      |\n","| train/                  |              |\n","|    approx_kl            | 0.0026871334 |\n","|    clip_fraction        | 0.0169       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.458       |\n","|    explained_variance   | 0.968        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 323          |\n","|    n_updates            | 2570         |\n","|    policy_gradient_loss | -0.000239    |\n","|    value_loss           | 146          |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 197          |\n","|    ep_rew_mean          | 277          |\n","| time/                   |              |\n","|    fps                  | 858          |\n","|    iterations           | 259          |\n","|    time_elapsed         | 4945         |\n","|    total_timesteps      | 4243456      |\n","| train/                  |              |\n","|    approx_kl            | 0.0020593414 |\n","|    clip_fraction        | 0.0264       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.483       |\n","|    explained_variance   | 0.984        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 0.723        |\n","|    n_updates            | 2580         |\n","|    policy_gradient_loss | -0.000196    |\n","|    value_loss           | 70           |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 206          |\n","|    ep_rew_mean          | 283          |\n","| time/                   |              |\n","|    fps                  | 858          |\n","|    iterations           | 260          |\n","|    time_elapsed         | 4962         |\n","|    total_timesteps      | 4259840      |\n","| train/                  |              |\n","|    approx_kl            | 0.0043582236 |\n","|    clip_fraction        | 0.0281       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.458       |\n","|    explained_variance   | 0.959        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 120          |\n","|    n_updates            | 2590         |\n","|    policy_gradient_loss | -0.00131     |\n","|    value_loss           | 196          |\n","------------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 204         |\n","|    ep_rew_mean          | 279         |\n","| time/                   |             |\n","|    fps                  | 858         |\n","|    iterations           | 261         |\n","|    time_elapsed         | 4978        |\n","|    total_timesteps      | 4276224     |\n","| train/                  |             |\n","|    approx_kl            | 0.003965983 |\n","|    clip_fraction        | 0.0298      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.466      |\n","|    explained_variance   | 0.976       |\n","|    learning_rate        | 0.0001      |\n","|    loss                 | 3.17        |\n","|    n_updates            | 2600        |\n","|    policy_gradient_loss | 0.000168    |\n","|    value_loss           | 109         |\n","-----------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 198          |\n","|    ep_rew_mean          | 281          |\n","| time/                   |              |\n","|    fps                  | 859          |\n","|    iterations           | 262          |\n","|    time_elapsed         | 4995         |\n","|    total_timesteps      | 4292608      |\n","| train/                  |              |\n","|    approx_kl            | 0.0021259657 |\n","|    clip_fraction        | 0.0281       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.489       |\n","|    explained_variance   | 0.971        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 27.4         |\n","|    n_updates            | 2610         |\n","|    policy_gradient_loss | -0.000399    |\n","|    value_loss           | 134          |\n","------------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 200         |\n","|    ep_rew_mean          | 286         |\n","| time/                   |             |\n","|    fps                  | 859         |\n","|    iterations           | 263         |\n","|    time_elapsed         | 5011        |\n","|    total_timesteps      | 4308992     |\n","| train/                  |             |\n","|    approx_kl            | 0.002465169 |\n","|    clip_fraction        | 0.029       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.475      |\n","|    explained_variance   | 0.962       |\n","|    learning_rate        | 0.0001      |\n","|    loss                 | 369         |\n","|    n_updates            | 2620        |\n","|    policy_gradient_loss | -2.04e-06   |\n","|    value_loss           | 174         |\n","-----------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 196          |\n","|    ep_rew_mean          | 280          |\n","| time/                   |              |\n","|    fps                  | 860          |\n","|    iterations           | 264          |\n","|    time_elapsed         | 5027         |\n","|    total_timesteps      | 4325376      |\n","| train/                  |              |\n","|    approx_kl            | 0.0031675117 |\n","|    clip_fraction        | 0.0355       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.473       |\n","|    explained_variance   | 0.981        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 1.06         |\n","|    n_updates            | 2630         |\n","|    policy_gradient_loss | -0.000627    |\n","|    value_loss           | 81.7         |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 195          |\n","|    ep_rew_mean          | 276          |\n","| time/                   |              |\n","|    fps                  | 860          |\n","|    iterations           | 265          |\n","|    time_elapsed         | 5046         |\n","|    total_timesteps      | 4341760      |\n","| train/                  |              |\n","|    approx_kl            | 0.0026385747 |\n","|    clip_fraction        | 0.0313       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.471       |\n","|    explained_variance   | 0.979        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 2.48         |\n","|    n_updates            | 2640         |\n","|    policy_gradient_loss | -0.000437    |\n","|    value_loss           | 50.4         |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 203          |\n","|    ep_rew_mean          | 284          |\n","| time/                   |              |\n","|    fps                  | 860          |\n","|    iterations           | 266          |\n","|    time_elapsed         | 5063         |\n","|    total_timesteps      | 4358144      |\n","| train/                  |              |\n","|    approx_kl            | 0.0009702245 |\n","|    clip_fraction        | 0.0106       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.457       |\n","|    explained_variance   | 0.936        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 354          |\n","|    n_updates            | 2650         |\n","|    policy_gradient_loss | -0.000799    |\n","|    value_loss           | 258          |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 197          |\n","|    ep_rew_mean          | 282          |\n","| time/                   |              |\n","|    fps                  | 861          |\n","|    iterations           | 267          |\n","|    time_elapsed         | 5079         |\n","|    total_timesteps      | 4374528      |\n","| train/                  |              |\n","|    approx_kl            | 0.0034533667 |\n","|    clip_fraction        | 0.0457       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.474       |\n","|    explained_variance   | 0.98         |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 3.61         |\n","|    n_updates            | 2660         |\n","|    policy_gradient_loss | -0.00151     |\n","|    value_loss           | 82.3         |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 196          |\n","|    ep_rew_mean          | 282          |\n","| time/                   |              |\n","|    fps                  | 861          |\n","|    iterations           | 268          |\n","|    time_elapsed         | 5096         |\n","|    total_timesteps      | 4390912      |\n","| train/                  |              |\n","|    approx_kl            | 0.0031833553 |\n","|    clip_fraction        | 0.0458       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.483       |\n","|    explained_variance   | 0.963        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 380          |\n","|    n_updates            | 2670         |\n","|    policy_gradient_loss | -0.000592    |\n","|    value_loss           | 163          |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 201          |\n","|    ep_rew_mean          | 279          |\n","| time/                   |              |\n","|    fps                  | 861          |\n","|    iterations           | 269          |\n","|    time_elapsed         | 5112         |\n","|    total_timesteps      | 4407296      |\n","| train/                  |              |\n","|    approx_kl            | 0.0037428893 |\n","|    clip_fraction        | 0.0334       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.458       |\n","|    explained_variance   | 0.97         |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 255          |\n","|    n_updates            | 2680         |\n","|    policy_gradient_loss | -0.000229    |\n","|    value_loss           | 148          |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 197          |\n","|    ep_rew_mean          | 289          |\n","| time/                   |              |\n","|    fps                  | 862          |\n","|    iterations           | 270          |\n","|    time_elapsed         | 5129         |\n","|    total_timesteps      | 4423680      |\n","| train/                  |              |\n","|    approx_kl            | 0.0026582042 |\n","|    clip_fraction        | 0.026        |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.468       |\n","|    explained_variance   | 0.956        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 6.29         |\n","|    n_updates            | 2690         |\n","|    policy_gradient_loss | 0.000128     |\n","|    value_loss           | 186          |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 196          |\n","|    ep_rew_mean          | 283          |\n","| time/                   |              |\n","|    fps                  | 862          |\n","|    iterations           | 271          |\n","|    time_elapsed         | 5145         |\n","|    total_timesteps      | 4440064      |\n","| train/                  |              |\n","|    approx_kl            | 0.0027036637 |\n","|    clip_fraction        | 0.0331       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.462       |\n","|    explained_variance   | 0.992        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 6.22         |\n","|    n_updates            | 2700         |\n","|    policy_gradient_loss | -0.00077     |\n","|    value_loss           | 10.1         |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 192          |\n","|    ep_rew_mean          | 281          |\n","| time/                   |              |\n","|    fps                  | 863          |\n","|    iterations           | 272          |\n","|    time_elapsed         | 5162         |\n","|    total_timesteps      | 4456448      |\n","| train/                  |              |\n","|    approx_kl            | 0.0025737104 |\n","|    clip_fraction        | 0.0211       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.452       |\n","|    explained_variance   | 0.966        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 6.84         |\n","|    n_updates            | 2710         |\n","|    policy_gradient_loss | -0.000232    |\n","|    value_loss           | 143          |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 196          |\n","|    ep_rew_mean          | 288          |\n","| time/                   |              |\n","|    fps                  | 863          |\n","|    iterations           | 273          |\n","|    time_elapsed         | 5178         |\n","|    total_timesteps      | 4472832      |\n","| train/                  |              |\n","|    approx_kl            | 0.0028294227 |\n","|    clip_fraction        | 0.0368       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.462       |\n","|    explained_variance   | 0.967        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 59.2         |\n","|    n_updates            | 2720         |\n","|    policy_gradient_loss | -0.001       |\n","|    value_loss           | 155          |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 197          |\n","|    ep_rew_mean          | 283          |\n","| time/                   |              |\n","|    fps                  | 864          |\n","|    iterations           | 274          |\n","|    time_elapsed         | 5194         |\n","|    total_timesteps      | 4489216      |\n","| train/                  |              |\n","|    approx_kl            | 0.0025476224 |\n","|    clip_fraction        | 0.0348       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.461       |\n","|    explained_variance   | 0.999        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 1.49         |\n","|    n_updates            | 2730         |\n","|    policy_gradient_loss | -0.000977    |\n","|    value_loss           | 2.22         |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 203          |\n","|    ep_rew_mean          | 292          |\n","| time/                   |              |\n","|    fps                  | 864          |\n","|    iterations           | 275          |\n","|    time_elapsed         | 5211         |\n","|    total_timesteps      | 4505600      |\n","| train/                  |              |\n","|    approx_kl            | 0.0020049084 |\n","|    clip_fraction        | 0.0171       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.453       |\n","|    explained_variance   | 0.966        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 1.04         |\n","|    n_updates            | 2740         |\n","|    policy_gradient_loss | -0.000411    |\n","|    value_loss           | 161          |\n","------------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 194         |\n","|    ep_rew_mean          | 290         |\n","| time/                   |             |\n","|    fps                  | 864         |\n","|    iterations           | 276         |\n","|    time_elapsed         | 5227        |\n","|    total_timesteps      | 4521984     |\n","| train/                  |             |\n","|    approx_kl            | 0.002316819 |\n","|    clip_fraction        | 0.0247      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.446      |\n","|    explained_variance   | 0.998       |\n","|    learning_rate        | 0.0001      |\n","|    loss                 | 1.6         |\n","|    n_updates            | 2750        |\n","|    policy_gradient_loss | -0.000485   |\n","|    value_loss           | 6.48        |\n","-----------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 192         |\n","|    ep_rew_mean          | 284         |\n","| time/                   |             |\n","|    fps                  | 865         |\n","|    iterations           | 277         |\n","|    time_elapsed         | 5244        |\n","|    total_timesteps      | 4538368     |\n","| train/                  |             |\n","|    approx_kl            | 0.002581276 |\n","|    clip_fraction        | 0.0316      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.449      |\n","|    explained_variance   | 0.986       |\n","|    learning_rate        | 0.0001      |\n","|    loss                 | 1.07        |\n","|    n_updates            | 2760        |\n","|    policy_gradient_loss | -0.000546   |\n","|    value_loss           | 66.6        |\n","-----------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 193          |\n","|    ep_rew_mean          | 287          |\n","| time/                   |              |\n","|    fps                  | 865          |\n","|    iterations           | 278          |\n","|    time_elapsed         | 5260         |\n","|    total_timesteps      | 4554752      |\n","| train/                  |              |\n","|    approx_kl            | 0.0029177573 |\n","|    clip_fraction        | 0.0286       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.465       |\n","|    explained_variance   | 0.955        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 3.01         |\n","|    n_updates            | 2770         |\n","|    policy_gradient_loss | -0.00075     |\n","|    value_loss           | 217          |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 191          |\n","|    ep_rew_mean          | 280          |\n","| time/                   |              |\n","|    fps                  | 866          |\n","|    iterations           | 279          |\n","|    time_elapsed         | 5276         |\n","|    total_timesteps      | 4571136      |\n","| train/                  |              |\n","|    approx_kl            | 0.0031446663 |\n","|    clip_fraction        | 0.0383       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.463       |\n","|    explained_variance   | 0.999        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 7.11         |\n","|    n_updates            | 2780         |\n","|    policy_gradient_loss | -0.00111     |\n","|    value_loss           | 3.92         |\n","------------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 189         |\n","|    ep_rew_mean          | 280         |\n","| time/                   |             |\n","|    fps                  | 866         |\n","|    iterations           | 280         |\n","|    time_elapsed         | 5293        |\n","|    total_timesteps      | 4587520     |\n","| train/                  |             |\n","|    approx_kl            | 0.002733692 |\n","|    clip_fraction        | 0.0199      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.458      |\n","|    explained_variance   | 0.944       |\n","|    learning_rate        | 0.0001      |\n","|    loss                 | 382         |\n","|    n_updates            | 2790        |\n","|    policy_gradient_loss | -0.0013     |\n","|    value_loss           | 267         |\n","-----------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 197         |\n","|    ep_rew_mean          | 282         |\n","| time/                   |             |\n","|    fps                  | 867         |\n","|    iterations           | 281         |\n","|    time_elapsed         | 5310        |\n","|    total_timesteps      | 4603904     |\n","| train/                  |             |\n","|    approx_kl            | 0.004709103 |\n","|    clip_fraction        | 0.0531      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.466      |\n","|    explained_variance   | 0.947       |\n","|    learning_rate        | 0.0001      |\n","|    loss                 | 148         |\n","|    n_updates            | 2800        |\n","|    policy_gradient_loss | -0.00148    |\n","|    value_loss           | 247         |\n","-----------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 219          |\n","|    ep_rew_mean          | 281          |\n","| time/                   |              |\n","|    fps                  | 867          |\n","|    iterations           | 282          |\n","|    time_elapsed         | 5327         |\n","|    total_timesteps      | 4620288      |\n","| train/                  |              |\n","|    approx_kl            | 0.0027564927 |\n","|    clip_fraction        | 0.024        |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.461       |\n","|    explained_variance   | 0.989        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 4.92         |\n","|    n_updates            | 2810         |\n","|    policy_gradient_loss | -0.000429    |\n","|    value_loss           | 40.4         |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 195          |\n","|    ep_rew_mean          | 281          |\n","| time/                   |              |\n","|    fps                  | 867          |\n","|    iterations           | 283          |\n","|    time_elapsed         | 5343         |\n","|    total_timesteps      | 4636672      |\n","| train/                  |              |\n","|    approx_kl            | 0.0039376253 |\n","|    clip_fraction        | 0.0217       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.473       |\n","|    explained_variance   | 0.948        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 9.02         |\n","|    n_updates            | 2820         |\n","|    policy_gradient_loss | -0.000585    |\n","|    value_loss           | 208          |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 199          |\n","|    ep_rew_mean          | 287          |\n","| time/                   |              |\n","|    fps                  | 867          |\n","|    iterations           | 284          |\n","|    time_elapsed         | 5362         |\n","|    total_timesteps      | 4653056      |\n","| train/                  |              |\n","|    approx_kl            | 0.0030011244 |\n","|    clip_fraction        | 0.0364       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.458       |\n","|    explained_variance   | 0.985        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 3.45         |\n","|    n_updates            | 2830         |\n","|    policy_gradient_loss | -0.00075     |\n","|    value_loss           | 58.3         |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 192          |\n","|    ep_rew_mean          | 290          |\n","| time/                   |              |\n","|    fps                  | 868          |\n","|    iterations           | 285          |\n","|    time_elapsed         | 5379         |\n","|    total_timesteps      | 4669440      |\n","| train/                  |              |\n","|    approx_kl            | 0.0026346424 |\n","|    clip_fraction        | 0.0305       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.483       |\n","|    explained_variance   | 0.998        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 2.29         |\n","|    n_updates            | 2840         |\n","|    policy_gradient_loss | -0.000371    |\n","|    value_loss           | 4.63         |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 206          |\n","|    ep_rew_mean          | 284          |\n","| time/                   |              |\n","|    fps                  | 868          |\n","|    iterations           | 286          |\n","|    time_elapsed         | 5395         |\n","|    total_timesteps      | 4685824      |\n","| train/                  |              |\n","|    approx_kl            | 0.0035658483 |\n","|    clip_fraction        | 0.0257       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.462       |\n","|    explained_variance   | 0.985        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 1.15         |\n","|    n_updates            | 2850         |\n","|    policy_gradient_loss | -0.00073     |\n","|    value_loss           | 73.9         |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 198          |\n","|    ep_rew_mean          | 282          |\n","| time/                   |              |\n","|    fps                  | 868          |\n","|    iterations           | 287          |\n","|    time_elapsed         | 5412         |\n","|    total_timesteps      | 4702208      |\n","| train/                  |              |\n","|    approx_kl            | 0.0022013974 |\n","|    clip_fraction        | 0.0224       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.469       |\n","|    explained_variance   | 0.977        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 32.1         |\n","|    n_updates            | 2860         |\n","|    policy_gradient_loss | -0.000791    |\n","|    value_loss           | 82.3         |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 186          |\n","|    ep_rew_mean          | 276          |\n","| time/                   |              |\n","|    fps                  | 869          |\n","|    iterations           | 288          |\n","|    time_elapsed         | 5428         |\n","|    total_timesteps      | 4718592      |\n","| train/                  |              |\n","|    approx_kl            | 0.0024740822 |\n","|    clip_fraction        | 0.0285       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.444       |\n","|    explained_variance   | 0.976        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 128          |\n","|    n_updates            | 2870         |\n","|    policy_gradient_loss | -0.000338    |\n","|    value_loss           | 115          |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 189          |\n","|    ep_rew_mean          | 281          |\n","| time/                   |              |\n","|    fps                  | 869          |\n","|    iterations           | 289          |\n","|    time_elapsed         | 5444         |\n","|    total_timesteps      | 4734976      |\n","| train/                  |              |\n","|    approx_kl            | 0.0024997424 |\n","|    clip_fraction        | 0.0207       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.451       |\n","|    explained_variance   | 0.937        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 33.3         |\n","|    n_updates            | 2880         |\n","|    policy_gradient_loss | -0.000683    |\n","|    value_loss           | 283          |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 186          |\n","|    ep_rew_mean          | 283          |\n","| time/                   |              |\n","|    fps                  | 870          |\n","|    iterations           | 290          |\n","|    time_elapsed         | 5460         |\n","|    total_timesteps      | 4751360      |\n","| train/                  |              |\n","|    approx_kl            | 0.0031947736 |\n","|    clip_fraction        | 0.0389       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.455       |\n","|    explained_variance   | 0.982        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 4.21         |\n","|    n_updates            | 2890         |\n","|    policy_gradient_loss | -0.00108     |\n","|    value_loss           | 81.4         |\n","------------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 191         |\n","|    ep_rew_mean          | 277         |\n","| time/                   |             |\n","|    fps                  | 870         |\n","|    iterations           | 291         |\n","|    time_elapsed         | 5477        |\n","|    total_timesteps      | 4767744     |\n","| train/                  |             |\n","|    approx_kl            | 0.002324064 |\n","|    clip_fraction        | 0.0208      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.467      |\n","|    explained_variance   | 0.957       |\n","|    learning_rate        | 0.0001      |\n","|    loss                 | 23.8        |\n","|    n_updates            | 2900        |\n","|    policy_gradient_loss | 0.000241    |\n","|    value_loss           | 177         |\n","-----------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 193          |\n","|    ep_rew_mean          | 285          |\n","| time/                   |              |\n","|    fps                  | 870          |\n","|    iterations           | 292          |\n","|    time_elapsed         | 5493         |\n","|    total_timesteps      | 4784128      |\n","| train/                  |              |\n","|    approx_kl            | 0.0028180731 |\n","|    clip_fraction        | 0.0273       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.464       |\n","|    explained_variance   | 0.971        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 77.4         |\n","|    n_updates            | 2910         |\n","|    policy_gradient_loss | 0.000154     |\n","|    value_loss           | 131          |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 195          |\n","|    ep_rew_mean          | 291          |\n","| time/                   |              |\n","|    fps                  | 871          |\n","|    iterations           | 293          |\n","|    time_elapsed         | 5510         |\n","|    total_timesteps      | 4800512      |\n","| train/                  |              |\n","|    approx_kl            | 0.0032880083 |\n","|    clip_fraction        | 0.029        |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.451       |\n","|    explained_variance   | 0.964        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 6.47         |\n","|    n_updates            | 2920         |\n","|    policy_gradient_loss | -0.00121     |\n","|    value_loss           | 162          |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 206          |\n","|    ep_rew_mean          | 281          |\n","| time/                   |              |\n","|    fps                  | 871          |\n","|    iterations           | 294          |\n","|    time_elapsed         | 5527         |\n","|    total_timesteps      | 4816896      |\n","| train/                  |              |\n","|    approx_kl            | 0.0028847484 |\n","|    clip_fraction        | 0.0337       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.456       |\n","|    explained_variance   | 0.996        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 3.03         |\n","|    n_updates            | 2930         |\n","|    policy_gradient_loss | -0.000834    |\n","|    value_loss           | 7.09         |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 195          |\n","|    ep_rew_mean          | 285          |\n","| time/                   |              |\n","|    fps                  | 871          |\n","|    iterations           | 295          |\n","|    time_elapsed         | 5543         |\n","|    total_timesteps      | 4833280      |\n","| train/                  |              |\n","|    approx_kl            | 0.0015773296 |\n","|    clip_fraction        | 0.0212       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.475       |\n","|    explained_variance   | 0.949        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 24.1         |\n","|    n_updates            | 2940         |\n","|    policy_gradient_loss | -0.00015     |\n","|    value_loss           | 176          |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 188          |\n","|    ep_rew_mean          | 279          |\n","| time/                   |              |\n","|    fps                  | 872          |\n","|    iterations           | 296          |\n","|    time_elapsed         | 5559         |\n","|    total_timesteps      | 4849664      |\n","| train/                  |              |\n","|    approx_kl            | 0.0032288353 |\n","|    clip_fraction        | 0.0318       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.454       |\n","|    explained_variance   | 0.971        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 45.9         |\n","|    n_updates            | 2950         |\n","|    policy_gradient_loss | -0.000869    |\n","|    value_loss           | 111          |\n","------------------------------------------\n","----------------------------------------\n","| rollout/                |            |\n","|    ep_len_mean          | 190        |\n","|    ep_rew_mean          | 285        |\n","| time/                   |            |\n","|    fps                  | 872        |\n","|    iterations           | 297        |\n","|    time_elapsed         | 5576       |\n","|    total_timesteps      | 4866048    |\n","| train/                  |            |\n","|    approx_kl            | 0.00244369 |\n","|    clip_fraction        | 0.0182     |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -0.458     |\n","|    explained_variance   | 0.945      |\n","|    learning_rate        | 0.0001     |\n","|    loss                 | 32.3       |\n","|    n_updates            | 2960       |\n","|    policy_gradient_loss | -0.000214  |\n","|    value_loss           | 208        |\n","----------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 188          |\n","|    ep_rew_mean          | 282          |\n","| time/                   |              |\n","|    fps                  | 873          |\n","|    iterations           | 298          |\n","|    time_elapsed         | 5592         |\n","|    total_timesteps      | 4882432      |\n","| train/                  |              |\n","|    approx_kl            | 0.0031937116 |\n","|    clip_fraction        | 0.036        |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.461       |\n","|    explained_variance   | 0.995        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 3.3          |\n","|    n_updates            | 2970         |\n","|    policy_gradient_loss | -0.00081     |\n","|    value_loss           | 6.02         |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 187          |\n","|    ep_rew_mean          | 286          |\n","| time/                   |              |\n","|    fps                  | 873          |\n","|    iterations           | 299          |\n","|    time_elapsed         | 5608         |\n","|    total_timesteps      | 4898816      |\n","| train/                  |              |\n","|    approx_kl            | 0.0026586922 |\n","|    clip_fraction        | 0.0277       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.475       |\n","|    explained_variance   | 0.976        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 3.66         |\n","|    n_updates            | 2980         |\n","|    policy_gradient_loss | -0.000726    |\n","|    value_loss           | 90.8         |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 212          |\n","|    ep_rew_mean          | 278          |\n","| time/                   |              |\n","|    fps                  | 873          |\n","|    iterations           | 300          |\n","|    time_elapsed         | 5626         |\n","|    total_timesteps      | 4915200      |\n","| train/                  |              |\n","|    approx_kl            | 0.0033451836 |\n","|    clip_fraction        | 0.0272       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.461       |\n","|    explained_variance   | 0.968        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 78.2         |\n","|    n_updates            | 2990         |\n","|    policy_gradient_loss | -0.000651    |\n","|    value_loss           | 147          |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 205          |\n","|    ep_rew_mean          | 278          |\n","| time/                   |              |\n","|    fps                  | 873          |\n","|    iterations           | 301          |\n","|    time_elapsed         | 5642         |\n","|    total_timesteps      | 4931584      |\n","| train/                  |              |\n","|    approx_kl            | 0.0032812972 |\n","|    clip_fraction        | 0.0277       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.499       |\n","|    explained_variance   | 0.967        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 14.6         |\n","|    n_updates            | 3000         |\n","|    policy_gradient_loss | -0.000725    |\n","|    value_loss           | 152          |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 191          |\n","|    ep_rew_mean          | 282          |\n","| time/                   |              |\n","|    fps                  | 874          |\n","|    iterations           | 302          |\n","|    time_elapsed         | 5659         |\n","|    total_timesteps      | 4947968      |\n","| train/                  |              |\n","|    approx_kl            | 0.0021461123 |\n","|    clip_fraction        | 0.0301       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.458       |\n","|    explained_variance   | 0.97         |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 5.09         |\n","|    n_updates            | 3010         |\n","|    policy_gradient_loss | -0.000185    |\n","|    value_loss           | 97.7         |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 188          |\n","|    ep_rew_mean          | 285          |\n","| time/                   |              |\n","|    fps                  | 874          |\n","|    iterations           | 303          |\n","|    time_elapsed         | 5677         |\n","|    total_timesteps      | 4964352      |\n","| train/                  |              |\n","|    approx_kl            | 0.0037413605 |\n","|    clip_fraction        | 0.0412       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.47        |\n","|    explained_variance   | 0.972        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 390          |\n","|    n_updates            | 3020         |\n","|    policy_gradient_loss | -0.000469    |\n","|    value_loss           | 128          |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 192          |\n","|    ep_rew_mean          | 289          |\n","| time/                   |              |\n","|    fps                  | 874          |\n","|    iterations           | 304          |\n","|    time_elapsed         | 5694         |\n","|    total_timesteps      | 4980736      |\n","| train/                  |              |\n","|    approx_kl            | 0.0027898555 |\n","|    clip_fraction        | 0.0313       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.49        |\n","|    explained_variance   | 0.998        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 1.85         |\n","|    n_updates            | 3030         |\n","|    policy_gradient_loss | -0.000263    |\n","|    value_loss           | 5.08         |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 191          |\n","|    ep_rew_mean          | 288          |\n","| time/                   |              |\n","|    fps                  | 875          |\n","|    iterations           | 305          |\n","|    time_elapsed         | 5710         |\n","|    total_timesteps      | 4997120      |\n","| train/                  |              |\n","|    approx_kl            | 0.0022385074 |\n","|    clip_fraction        | 0.0227       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.458       |\n","|    explained_variance   | 0.998        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 1.35         |\n","|    n_updates            | 3040         |\n","|    policy_gradient_loss | -0.000847    |\n","|    value_loss           | 4.35         |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 190          |\n","|    ep_rew_mean          | 287          |\n","| time/                   |              |\n","|    fps                  | 875          |\n","|    iterations           | 306          |\n","|    time_elapsed         | 5726         |\n","|    total_timesteps      | 5013504      |\n","| train/                  |              |\n","|    approx_kl            | 0.0025862814 |\n","|    clip_fraction        | 0.0278       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.491       |\n","|    explained_variance   | 0.998        |\n","|    learning_rate        | 0.0001       |\n","|    loss                 | 1.65         |\n","|    n_updates            | 3050         |\n","|    policy_gradient_loss | -0.000295    |\n","|    value_loss           | 4.05         |\n","------------------------------------------\n"]}],"source":["# Train it for 1,000,000 timesteps\n","model.learn(total_timesteps=10_000_000)\n","# Save the model\n","model.save(model_name)"]},{"cell_type":"markdown","metadata":{"id":"BY_HuedOoISR"},"source":["## Evaluate the agent üìà\n","- Now that our Lunar Lander agent is trained üöÄ, we need to **check its performance**.\n","- Stable-Baselines3 provides a method to do that: `evaluate_policy`.\n","- To fill that part you need to [check the documentation](https://stable-baselines3.readthedocs.io/en/master/guide/examples.html#basic-usage-training-saving-loading)\n","- In the next step,  we'll see **how to automatically evaluate and share your agent to compete in a leaderboard, but for now let's do it ourselves**\n","\n","\n","üí° When you evaluate your agent, you should not use your training environment but create an evaluation environment."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3584,"status":"ok","timestamp":1673351769296,"user":{"displayName":"Andrew Johnson (earyzhe)","userId":"17854936619688322601"},"user_tz":-60},"id":"yRpno0glsADy","outputId":"4bc8cad9-86e1-4032-fc65-58065ae0f71a"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/stable_baselines3/common/evaluation.py:65: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["mean_reward=284.43 +/- 19.40266362578078\n"]}],"source":["# Create a new environment for evaluation\n","eval_env = gym.make(\"LunarLander-v2\")\n","\n","# Evaluate the model with 10 evaluation episodes and deterministic=True\n","mean_reward, std_reward = evaluate_policy(model, eval_env, n_eval_episodes=10, deterministic=True)\n","\n","# Print the results\n","print(f\"mean_reward={mean_reward:.2f} +/- {std_reward}\")\n"]},{"cell_type":"markdown","metadata":{"id":"reBhoODwcXfr"},"source":["- In my case, I got a mean reward is `200.20 +/- 20.80` after training for 1 million steps, which means that our lunar lander agent is ready to land on the moon üåõü•≥."]},{"cell_type":"markdown","metadata":{"id":"IK_kR78NoNb2"},"source":["## Publish our trained model on the Hub üî•\n","Now that we saw we got good results after the training, we can publish our trained model on the hub ü§ó with one line of code.\n","\n","üìö The libraries documentation üëâ https://github.com/huggingface/huggingface_sb3/tree/main#hugging-face--x-stable-baselines3-v20\n","\n","Here's an example of a Model Card (with Space Invaders):"]},{"cell_type":"markdown","metadata":{"id":"Gs-Ew7e1gXN3"},"source":["By using `package_to_hub` **you evaluate, record a replay, generate a model card of your agent and push it to the hub**.\n","\n","This way:\n","- You can **showcase our work** üî•\n","- You can **visualize your agent playing** üëÄ\n","- You can **share with the community an agent that others can use** üíæ\n","- You can **access a leaderboard üèÜ to see how well your agent is performing compared to your classmates** üëâ https://huggingface.co/spaces/huggingface-projects/Deep-Reinforcement-Learning-Leaderboard\n"]},{"cell_type":"markdown","metadata":{"id":"JquRrWytA6eo"},"source":["To be able to share your model with the community there are three more steps to follow:\n","\n","1Ô∏è‚É£ (If it's not already done) create an account to HF ‚û° https://huggingface.co/join\n","\n","2Ô∏è‚É£ Sign in and then, you need to store your authentication token from the Hugging Face website.\n","- Create a new token (https://huggingface.co/settings/tokens) **with write role**\n","\n","<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/create-token.jpg\" alt=\"Create HF Token\">\n","\n","- Copy the token \n","- Run the cell below and paste the token"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":304,"referenced_widgets":["eb9be4469f3341ae8bf7d6628b5577e3","4cc3cf3dc83749318a926b63f4661678","ce793d3058e54a349583db46fc64e602","e0efb1bac5b4487b83101af7c428efeb","4b2a9333aab34d4fbcd535627b921046","00fd112e5bdf4e95bdf286c1412a671c","4e31b33fc86e45ff9d97f26157f27854","d98fae36831341619938199ef903aa3c","ecbbb08a0e4d4ee8adab7dc9a8d63d4e","cc44899055fb4d6eae7a947fab2f0f19","87c22291d46c4fb4a674552c43dd23b6","26cb2a5529804a4b91c35045fd0a83b7","55fe15e98dd3476f978daf6aef7420c7","e8ddf01a5a8a4d2a8829d5d5a1b8c944","18dd8df6c97e4a25894ddaf27a432591","74e537e570814d89aba35c178b4db94d","d389b1814b4246a8a70fa8ecbb0349bd"]},"executionInfo":{"elapsed":402,"status":"ok","timestamp":1673351838401,"user":{"displayName":"Andrew Johnson (earyzhe)","userId":"17854936619688322601"},"user_tz":-60},"id":"GZiFBBlzxzxY","outputId":"a3a09284-dd4a-44b2-eb12-bec3414076d0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Token is valid.\n","Your token has been saved in your configured git credential helpers (store).\n","Your token has been saved to /root/.huggingface/token\n","Login successful\n"]}],"source":["notebook_login()\n","!git config --global credential.helper store"]},{"cell_type":"markdown","metadata":{"id":"_tsf2uv0g_4p"},"source":["If you don't want to use a Google Colab or a Jupyter Notebook, you need to use this command instead: `huggingface-cli login`"]},{"cell_type":"markdown","metadata":{"id":"FGNh9VsZok0i"},"source":["3Ô∏è‚É£ We're now ready to push our trained agent to the ü§ó Hub üî• using `package_to_hub()` function"]},{"cell_type":"markdown","metadata":{"id":"Ay24l6bqFF18"},"source":["Let's fill the `package_to_hub` function:\n","- `model`: our trained model.\n","- `model_name`: the name of the trained model that we defined in `model_save`\n","- `model_architecture`: the model architecture we used: in our case PPO\n","- `env_id`: the name of the environment, in our case `LunarLander-v2`\n","- `eval_env`: the evaluation environment defined in eval_env\n","- `repo_id`: the name of the Hugging Face Hub Repository that will be created/updated `(repo_id = {username}/{repo_name})`\n","\n","üí° **A good name is {username}/{model_architecture}-{env_id}**\n","\n","- `commit_message`: message of the commit"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":227},"executionInfo":{"elapsed":26582,"status":"ok","timestamp":1673351873677,"user":{"displayName":"Andrew Johnson (earyzhe)","userId":"17854936619688322601"},"user_tz":-60},"id":"JPG7ofdGIHN8","outputId":"ef0d35d9-ea12-492a-8f5b-d5696c2f12ea"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[38;5;4m‚Ñπ This function will save, evaluate, generate a video of your agent,\n","create a model card and push everything to the hub. It might take up to 1min.\n","This is a work in progress: if you encounter a bug, please open an issue.\u001b[0m\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/stable_baselines3/common/evaluation.py:65: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Saving video to /tmp/tmp1hlxazhk/-step-0-to-step-1000.mp4\n","\u001b[38;5;4m‚Ñπ Pushing repo aj555/ppo-LunarLander-v2-first-run to the Hugging Face\n","Hub\u001b[0m\n","\u001b[38;5;4m‚Ñπ Your model is pushed to the Hub. You can view your model here:\n","https://huggingface.co/aj555/ppo-LunarLander-v2-first-run/tree/main/\u001b[0m\n"]},{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'https://huggingface.co/aj555/ppo-LunarLander-v2-first-run/tree/main/'"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["import gym\n","from stable_baselines3.common.vec_env import DummyVecEnv\n","from stable_baselines3.common.env_util import make_vec_env\n","\n","from huggingface_sb3 import package_to_hub\n","\n","## TODO: Define a repo_id\n","## repo_id is the id of the model repository from the Hugging Face Hub (repo_id = {organization}/{repo_name} for instance ThomasSimonini/ppo-LunarLander-v2\n","repo_id = \"aj555/ppo-LunarLander-v2-run-2\"\n","\n","# TODO: Define the name of the environment\n","env_id = \"LunarLander-v2\"\n","\n","# Create the evaluation env\n","eval_env = DummyVecEnv([lambda: gym.make(env_id)])\n","\n","\n","# TODO: Define the model architecture we used\n","model_architecture = \"PPO\"\n","\n","## TODO: Define the commit message\n","commit_message = \"Upload PPO LunarLander-v2 trained agent\"\n","\n","# method save, evaluate, generate a model card and record a replay video of your agent before pushing the repo to the hub\n","package_to_hub(model=model, # Our trained model\n","               model_name=model_name, # The name of our trained model \n","               model_architecture=model_architecture, # The model architecture we used: in our case PPO\n","               env_id=env_id, # Name of the environment\n","               eval_env=eval_env, # Evaluation Environment\n","               repo_id=repo_id, # id of the model repository from the Hugging Face Hub (repo_id = {organization}/{repo_name} for instance ThomasSimonini/ppo-LunarLander-v2\n","               commit_message=commit_message)\n","\n","# Note: if after running the package_to_hub function and it gives an issue of rebasing, please run the following code\n","# cd <path_to_repo> && git add . && git commit -m \"Add message\" && git pull \n","# And don't forget to do a \"git push\" at the end to push the change to the hub."]},{"cell_type":"markdown","metadata":{"id":"9nWnuQHRfFRa"},"source":["## Load a saved LunarLander model from the Hub ü§ó\n","Thanks to [ironbar](https://github.com/ironbar) for the contribution.\n","\n","Loading a saved model from the Hub is really easy. \n","\n","You go https://huggingface.co/models?library=stable-baselines3 to see the list of all the Stable-baselines3 saved models.\n","1. You select one and copy its repo_id\n","\n","<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/unit1/copy-id.png\" alt=\"Copy-id\"/>"]},{"cell_type":"markdown","metadata":{"id":"hNPLJF2bfiUw"},"source":["2. Then we just need to use load_from_hub with:\n","- The repo_id\n","- The filename: the saved model inside the repo and its extension (*.zip)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oj8PSGHJfwz3"},"outputs":[],"source":["from huggingface_sb3 import load_from_hub\n","# repo_id = \"Classroom-workshop/assignment2-omar\" # The repo_id\n","filename = \"ppo-LunarLander-v2.zip\" # The model filename.zip\n","\n","# When the model was trained on Python 3.8 the pickle protocol is 5\n","# But Python 3.6, 3.7 use protocol 4\n","# In order to get compatibility we need to:\n","# 1. Install pickle5 (we done it at the beginning of the colab)\n","# 2. Create a custom empty object we pass as parameter to PPO.load()\n","custom_objects = {\n","            \"learning_rate\": 0.0,\n","            \"lr_schedule\": lambda _: 0.0,\n","            \"clip_range\": lambda _: 0.0,\n","}\n","\n","checkpoint = load_from_hub(repo_id, filename)\n","model = PPO.load(checkpoint, custom_objects=custom_objects, print_system_info=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PAEVwK-aahfx"},"outputs":[],"source":["#@title\n","eval_env = gym.make(\"LunarLander-v2\")\n","mean_reward, std_reward = evaluate_policy(model, eval_env, n_eval_episodes=10, deterministic=True)\n","print(f\"mean_reward={mean_reward:.2f} +/- {std_reward}\")"]},{"cell_type":"markdown","metadata":{"id":"Fs0Y-qgPgLUf"},"source":["Let's evaluate this agent:"]},{"cell_type":"markdown","metadata":{"id":"BQAwLnYFPk-s"},"source":["## Some additional challenges üèÜ\n","The best way to learn **is to try things by your own**! As you saw, the current agent is not doing great. As a first suggestion, you can train for more steps. With 1,000,000 steps, we saw some great results! \n","\n","In the [Leaderboard](https://huggingface.co/spaces/huggingface-projects/Deep-Reinforcement-Learning-Leaderboard) you will find your agents. Can you get to the top?\n","\n","Here are some ideas to achieve so:\n","* Train more steps\n","* Try different hyperparameters of `PPO`. You can see them at https://stable-baselines3.readthedocs.io/en/master/modules/ppo.html#parameters. \n","* Check the [Stable-Baselines3 documentation](https://stable-baselines3.readthedocs.io/en/master/modules/dqn.html) and try another models such as DQN.\n","* **Push your new trained model** on the Hub üî•\n","\n","**Compare the results of your LunarLander-v2 with your classmates** using the [leaderboard](https://huggingface.co/spaces/huggingface-projects/Deep-Reinforcement-Learning-Leaderboard) üèÜ\n","\n","Is moon landing too boring to you? Try to **change the environment**, why not using MountainCar-v0, CartPole-v1 or CarRacing-v0? Check how they works [using the gym documentation](https://www.gymlibrary.dev/) and have fun üéâ."]},{"cell_type":"markdown","metadata":{"id":"9lM95-dvmif8"},"source":["________________________________________________________________________\n","Congrats on finishing this chapter! That was the biggest one, **and there was a lot of information.**\n","\n","If you‚Äôre still feel confused with all these elements...it's totally normal! **This was the same for me and for all people who studied RL.**\n","\n","Take time to really **grasp the material before continuing and try the additional challenges**. It‚Äôs important to master these elements and having a solid foundations.\n","\n","Naturally, during the course, we‚Äôre going to use and deeper explain again these terms but **it‚Äôs better to have a good understanding of them now before diving into the next chapters.**\n"]},{"cell_type":"markdown","metadata":{"id":"BjLhT70TEZIn"},"source":["Next time, in the bonus unit 1, you'll train Huggy the Dog to fetch the stick.\n","\n","<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/unit1/huggy.jpg\" alt=\"Huggy\"/>\n","\n","## Keep learning, stay awesome ü§ó"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VjZmJh4bt8ES"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["QAN7B0_HCVZC","1bQzQ-QcE3zo","BqPKw3jt_pG5","Avf6gufJBGMw"],"provenance":[{"file_id":"https://github.com/huggingface/deep-rl-class/blob/master/notebooks/unit1/unit1.ipynb","timestamp":1673178275678}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.6 (v3.10.6:9c7b4bd164, Aug  1 2022, 17:13:48) [Clang 13.0.0 (clang-1300.0.29.30)]"},"vscode":{"interpreter":{"hash":"aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"}},"widgets":{"application/vnd.jupyter.widget-state+json":{"00fd112e5bdf4e95bdf286c1412a671c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_74e537e570814d89aba35c178b4db94d","placeholder":"‚Äã","style":"IPY_MODEL_d389b1814b4246a8a70fa8ecbb0349bd","value":"\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"}},"18dd8df6c97e4a25894ddaf27a432591":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ButtonStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","button_color":null,"font_weight":""}},"26cb2a5529804a4b91c35045fd0a83b7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4b2a9333aab34d4fbcd535627b921046":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ButtonModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ButtonView","button_style":"","description":"Login","disabled":false,"icon":"","layout":"IPY_MODEL_e8ddf01a5a8a4d2a8829d5d5a1b8c944","style":"IPY_MODEL_18dd8df6c97e4a25894ddaf27a432591","tooltip":""}},"4cc3cf3dc83749318a926b63f4661678":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d98fae36831341619938199ef903aa3c","placeholder":"‚Äã","style":"IPY_MODEL_ecbbb08a0e4d4ee8adab7dc9a8d63d4e","value":"<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"}},"4e31b33fc86e45ff9d97f26157f27854":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":"center","align_self":null,"border":null,"bottom":null,"display":"flex","flex":null,"flex_flow":"column","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"50%"}},"55fe15e98dd3476f978daf6aef7420c7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"74e537e570814d89aba35c178b4db94d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"87c22291d46c4fb4a674552c43dd23b6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cc44899055fb4d6eae7a947fab2f0f19":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ce793d3058e54a349583db46fc64e602":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"PasswordModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"PasswordModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"PasswordView","continuous_update":true,"description":"Token:","description_tooltip":null,"disabled":false,"layout":"IPY_MODEL_cc44899055fb4d6eae7a947fab2f0f19","placeholder":"‚Äã","style":"IPY_MODEL_87c22291d46c4fb4a674552c43dd23b6","value":""}},"d389b1814b4246a8a70fa8ecbb0349bd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d98fae36831341619938199ef903aa3c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e0efb1bac5b4487b83101af7c428efeb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"CheckboxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"CheckboxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"CheckboxView","description":"Add token as git credential?","description_tooltip":null,"disabled":false,"indent":true,"layout":"IPY_MODEL_26cb2a5529804a4b91c35045fd0a83b7","style":"IPY_MODEL_55fe15e98dd3476f978daf6aef7420c7","value":true}},"e8ddf01a5a8a4d2a8829d5d5a1b8c944":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eb9be4469f3341ae8bf7d6628b5577e3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"VBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_4cc3cf3dc83749318a926b63f4661678","IPY_MODEL_ce793d3058e54a349583db46fc64e602","IPY_MODEL_e0efb1bac5b4487b83101af7c428efeb","IPY_MODEL_4b2a9333aab34d4fbcd535627b921046","IPY_MODEL_00fd112e5bdf4e95bdf286c1412a671c"],"layout":"IPY_MODEL_4e31b33fc86e45ff9d97f26157f27854"}},"ecbbb08a0e4d4ee8adab7dc9a8d63d4e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}
